# backend/classifier/langchain_integration.py

"""
LangChainì„ ì‚¬ìš©í•œ PARA ë¶„ë¥˜ í†µí•© ëª¨ë“ˆ (ë©”íƒ€ë°ì´í„° ëŒ€ë¹„)
GPT-4o-minië¥¼ ì‚¬ìš©í•œ AI ê¸°ë°˜ ë¶„ë¥˜
- ìƒëŒ€ê²½ë¡œ + ë™ì  ë²„ì „
- ì •ê·œí‘œí˜„ì‹ ì‚¬ìš©
- metadata_classification_prompt ì½ê¸° ì¶”ê°€ 
"""

import json
import logging
import os
import sys
import re
from typing import Dict, Any, Optional, List
from pathlib import Path
from dotenv import load_dotenv

# ìƒëŒ€ê²½ë¡œ + ë™ì  ê³„ì‚°
CURRENT_FILE = Path(__file__)
CLASSIFIER_DIR = CURRENT_FILE.parent
BACKEND_DIR = CLASSIFIER_DIR.parent
PROJECT_ROOT = BACKEND_DIR.parent

# 1. .env íŒŒì¼ ë¡œë“œ
ENV_FILE = PROJECT_ROOT / ".env"
load_dotenv(str(ENV_FILE))

# 2. sys.pathì— ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, str(BACKEND_DIR))
sys.path.insert(0, str(PROJECT_ROOT))

from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from pydantic import BaseModel, Field

# 3. config import (3ë‹¨ê³„ fallback)
try:
    # 1ë²ˆì§¸ ì‹œë„: ì ˆëŒ€ import
    from backend.config import ModelConfig
    print("âœ… ModelConfig loaded from backend.config")
except ImportError:
    try:
        # 2ë²ˆì§¸ ì‹œë„: ìƒëŒ€ import
        from config import ModelConfig
        print("âœ… ModelConfig loaded from config")
    except ImportError:
        # 3ë²ˆì§¸ ì‹œë„: ì§ì ‘ í™˜ê²½ë³€ìˆ˜
        print("âš ï¸ Using os.getenv fallback")
        class ModelConfig:
            GPT4O_MINI_API_KEY = os.getenv("GPT4O_MINI_API_KEY")
            GPT4O_MINI_BASE_URL = os.getenv("GPT4O_MINI_BASE_URL")
            GPT4O_MINI_MODEL = os.getenv("GPT4O_MINI_MODEL", "gpt-4o-mini")


logger = logging.getLogger(__name__)


class PARAClassificationOutput(BaseModel):
    """PARA ë¶„ë¥˜ ê²°ê³¼ ìŠ¤í‚¤ë§ˆ"""
    category: str = Field(description="PARA ì¹´í…Œê³ ë¦¬ (Projects/Areas/Resources/Archives)")
    confidence: float = Field(description="ì‹ ë¢°ë„ ì ìˆ˜ (0.0-1.0)")
    reasoning: str = Field(description="ë¶„ë¥˜ ì´ìœ  (í•œêµ­ì–´)")
    detected_cues: List[str] = Field(description="ê°ì§€ëœ í‚¤ì›Œë“œ ëª©ë¡")


def escape_json_braces_complete(content: str) -> str:
    """ëª¨ë“  JSON í˜•ì‹ì˜ ì¤‘ê´„í˜¸ë¥¼ ì´ìŠ¤ì¼€ì´í”„"""
    
    # 1. ë°±í‹±(```
    # ```
    # {
    #   "key": "value"
    # }
    # ```
    
    # íŒ¨í„´: ```ë¡œ ì‹œì‘í•˜ê³  ```
    def escape_code_block(match):
        code_block = match.group(0)
        # ì½”ë“œ ë¸”ë¡ ë‚´ì˜ { â†’ {{ ì¹˜í™˜
        code_block = code_block.replace('{\n', '{{\n')
        code_block = code_block.replace('\n}', '\n}}')
        code_block = code_block.replace('{ ', '{{ ')
        code_block = code_block.replace(' }', ' }}')
        return code_block
    
    # ```...```
    content = re.sub(r'``````', escape_code_block, content)
    
    # 2. ì¼ë°˜ { } ì²˜ë¦¬ (ë°±í‹± ë°–)
    # {{ â†’ {{{ ë¡œ ì•ˆ ë˜ê²Œ ì¡°ì‹¬í•˜ê¸°
    lines = []
    in_code = False
    
    for line in content.split('\n'):
        if line.strip().startswith('```'):
            in_code = not in_code
            lines.append(line)
        elif not in_code and re.match(r'^\s*\{', line):
            # ë¼ì¸ì´ { ë¡œ ì‹œì‘
            line = re.sub(r'\{\s', '{{ ', line)
            line = re.sub(r'\{$', '{{', line)
            lines.append(line)
        elif not in_code and re.search(r'\}\s*$', line):
            # ë¼ì¸ì´ } ë¡œ ëë‚¨
            line = re.sub(r'\s\}', ' }}', line)
            line = re.sub(r'^}', '}}', line)
            lines.append(line)
        else:
            lines.append(line)
    
    return '\n'.join(lines)


def get_para_classification_prompt() -> str:
    """í”„ë¡¬í”„íŠ¸ íŒŒì¼ ì½ê¸° + ê°„ë‹¨í•œ ì´ìŠ¤ì¼€ì´í”„"""
    
    prompt_path = CLASSIFIER_DIR / "prompts" / "para_classification_prompt.txt"
    
    with open(prompt_path, "r", encoding="utf-8") as f:
        content = f.read()
    
    # âœ… ê°„ë‹¨í•œ ì´ìŠ¤ì¼€ì´í”„
    lines = []
    for line in content.split('\n'):
        # {text}ëŠ” ê±´ë“œë¦¬ì§€ ë§ê³ 
        if '{text}' in line:
            lines.append(line)
        else:
            # ë‚˜ë¨¸ì§€ { } ëŠ” ì´ìŠ¤ì¼€ì´í”„
            line = line.replace('{', '{{').replace('}', '}}')
            # {text}ëŠ” ì›ìƒë³µêµ¬
            line = line.replace('{{text}}', '{text}')
            lines.append(line)
    
    return '\n'.join(lines)


def create_para_prompt(include_metadata: bool = False) -> PromptTemplate:
    """ë©”íƒ€ë°ì´í„° ì˜µì…˜ì´ ìˆëŠ” í”„ë¡¬í”„íŠ¸ ìƒì„±
    
    Args:
        include_metadata: ë©”íƒ€ë°ì´í„° í¬í•¨ ì—¬ë¶€
    
    Returns:
        PromptTemplate: LangChain í”„ë¡¬í”„íŠ¸
    """
    
    # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
    base_prompt = get_para_classification_prompt()
    
    if include_metadata:
        # ë©”íƒ€ë°ì´í„° ì„¹ì…˜ ì¶”ê°€
        metadata_instruction = """
## ğŸ“‹ ì¶”ê°€ íŒŒì¼ ì •ë³´
- íŒŒì¼ëª…: {filename}
- ìƒì„±ì¼: {created_date}
- íƒœê·¸: {tags}

ğŸ’¡ íŒ: ë©”íƒ€ë°ì´í„°ë„ ê³ ë ¤í•˜ë˜, ë³¸ë¬¸ ë‚´ìš©ì´ ëª…í™•í•˜ë©´ ë³¸ë¬¸ì„ ìš°ì„ í•˜ì„¸ìš”.
"""
        full_prompt = base_prompt + metadata_instruction
        input_variables = ["text", "filename", "created_date", "tags"]
    else:
        full_prompt = base_prompt
        input_variables = ["text"]
    
    # í”„ë¡¬í”„íŠ¸ ìƒì„±
    prompt = PromptTemplate(
        input_variables=input_variables,
        template=full_prompt
    )
    
    return prompt


def create_para_chain(include_metadata: bool = False):
    """
    PARA ë¶„ë¥˜ë¥¼ ìœ„í•œ LangChain Chain ìƒì„±
    
    Args:
        include_metadata: ë©”íƒ€ë°ì´í„° í¬í•¨ ì—¬ë¶€
    
    Returns:
        Runnable: LangChain ì‹¤í–‰ ê°€ëŠ¥ ê°ì²´
    """
    
    # âœ… configì˜ ì„¤ì •ìœ¼ë¡œ LLM ì´ˆê¸°í™”
    llm = ChatOpenAI(
        api_key=ModelConfig.GPT4O_MINI_API_KEY,
        base_url=ModelConfig.GPT4O_MINI_BASE_URL,
        model=ModelConfig.GPT4O_MINI_MODEL,
        temperature=0.3,
        max_tokens=500
    )
    
    # í”„ë¡¬í”„íŠ¸ ìƒì„±
    prompt = create_para_prompt(include_metadata=include_metadata)
    
    # JSON ì¶œë ¥ íŒŒì„œ
    parser = JsonOutputParser(pydantic_object=PARAClassificationOutput)
    
    # Chain êµ¬ì„±: Prompt â†’ LLM â†’ Parser
    chain = prompt | llm | parser
    
    return chain


def classify_with_langchain(
    text: str,
    metadata: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """
    LangChainì„ ì‚¬ìš©í•´ í…ìŠ¤íŠ¸ë¥¼ PARAë¡œ ë¶„ë¥˜
    ë©”íƒ€ë°ì´í„° ì˜µì…˜ìœ¼ë¡œ ë¯¸ë˜ í™•ì¥ ëŒ€ë¹„
    
    Args:
        text (str): ë¶„ë¥˜í•  í…ìŠ¤íŠ¸
        metadata (Optional[Dict]): ì˜µì…˜ ë©”íƒ€ë°ì´í„°
            {
                "filename": str,
                "created_date": str,
                "tags": List[str]
            }
    
    Returns:
        Dict: ë¶„ë¥˜ ê²°ê³¼
            {
                "category": str,
                "confidence": float,
                "reasoning": str,
                "detected_cues": List[str],
                "source": str,
                "has_metadata": bool
            }
    """
    
    try:
        # ë©”íƒ€ë°ì´í„° í¬í•¨ ì—¬ë¶€ ê²°ì •
        include_metadata = metadata is not None
        
        # Chain ìƒì„±
        chain = create_para_chain(include_metadata=include_metadata)
        
        # ì…ë ¥ ë°ì´í„° êµ¬ì„±
        input_data = {"text": text}
        
        if include_metadata:
            input_data.update({
                "filename": metadata.get("filename", "N/A"),
                "created_date": metadata.get("created_date", "N/A"),
                "tags": ", ".join(metadata.get("tags", [])) or "None"
            })
        
        # ë¶„ë¥˜ ì‹¤í–‰
        result = chain.invoke(input_data)
        
        logger.info(
            f"ë¶„ë¥˜ ì™„ë£Œ: {result['category']} "
            f"(confidence: {result['confidence']:.2%}, "
            f"metadata: {include_metadata})"
        )
        
        return {
            "category": result["category"],
            "confidence": result["confidence"],
            "reasoning": result["reasoning"],
            "detected_cues": result.get("detected_cues", []),
            "source": "langchain",
            "has_metadata": include_metadata
        }
    
    except Exception as e:
        logger.error(f"LangChain ë¶„ë¥˜ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        raise


# ============================================================
# ë©”íƒ€ë°ì´í„° ê¸°ë°˜ PARA ë¶„ë¥˜ (ìƒˆë¡œ ì¶”ê°€)
# ============================================================

def get_metadata_classification_prompt() -> str:
    """ë©”íƒ€ë°ì´í„° ë¶„ë¥˜ í”„ë¡¬í”„íŠ¸ íŒŒì¼ ì½ê¸°"""
    prompt_path = CLASSIFIER_DIR / "prompts" / "metadata_classification_prompt.txt"
    try:
        with open(prompt_path, "r", encoding="utf-8") as f:
            content = f.read()
        
        # ê°„ë‹¨í•œ ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬
        lines = []
        for line in content.split('\n'):
            if '{metadata}' in line:
                lines.append(line)
            else:
                line = line.replace('{', '{{').replace('}', '}}')
                line = line.replace('{{metadata}}', '{metadata}')
                lines.append(line)
        
        return '\n'.join(lines)
    except FileNotFoundError:
        logger.error(f"ë©”íƒ€ë°ì´í„° í”„ë¡¬í”„íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {prompt_path}")
        raise


def create_metadata_classification_chain():
    """ë©”íƒ€ë°ì´í„° ê¸°ë°˜ PARA ë¶„ë¥˜ Chain ìƒì„±"""
    prompt_content = get_metadata_classification_prompt()
    
    prompt = PromptTemplate(
        input_variables=["metadata"],
        template=prompt_content
    )
    
    llm = ChatOpenAI(
        api_key=ModelConfig.GPT4O_MINI_API_KEY,
        base_url=ModelConfig.GPT4O_MINI_BASE_URL,
        model=ModelConfig.GPT4O_MINI_MODEL,
        temperature=0.0,  # ë©”íƒ€ë°ì´í„°ëŠ” deterministic
        max_tokens=500
    )
    
    parser = JsonOutputParser(pydantic_object=PARAClassificationOutput)
    return prompt | llm | parser


def classify_with_metadata(
    metadata: Dict[str, Any]
) -> Dict[str, Any]:
    """
    ë©”íƒ€ë°ì´í„°ë§Œì„ ì‚¬ìš©í•´ PARAë¡œ ë¶„ë¥˜
    
    Args:
        metadata: ë©”íƒ€ë°ì´í„° ë”•ì…”ë„ˆë¦¬ (JSON í˜•ì‹)
        {
            "basic_info": {...},
            "temporal_info": {...},
            ...
        }
    
    Returns:
        Dict: ë¶„ë¥˜ ê²°ê³¼
        {
            "category": str,
            "confidence": float,
            "reasoning": str,
            "detected_cues": List[str],
            "source": str,
            "metadata_used": bool
        }
    """
    try:
        # Chain ìƒì„±
        chain = create_metadata_classification_chain()
        
        # ë©”íƒ€ë°ì´í„°ë¥¼ JSON ë¬¸ìì—´ë¡œ ë³€í™˜
        metadata_json = json.dumps(metadata, ensure_ascii=False, indent=2)
        
        # ë¶„ë¥˜ ì‹¤í–‰
        result = chain.invoke({"metadata": metadata_json})
        
        logger.info(
            f"ë©”íƒ€ë°ì´í„° ë¶„ë¥˜ ì™„ë£Œ: {result['category']} "
            f"(confidence: {result['confidence']:.2%})"
        )
        
        return {
            "category": result["category"],
            "confidence": result["confidence"],
            "reasoning": result["reasoning"],
            "detected_cues": result.get("detected_cues", []),
            "source": "metadata",
            "metadata_used": True
        }
    
    except Exception as e:
        logger.error(f"ë©”íƒ€ë°ì´í„° ë¶„ë¥˜ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        raise


def hybrid_classify(
    text: str,
    metadata: Dict[str, Any]
) -> Dict[str, Any]:
    """
    í…ìŠ¤íŠ¸ì™€ ë©”íƒ€ë°ì´í„° ëª¨ë‘ë¥¼ ì‚¬ìš©í•´ í•˜ì´ë¸Œë¦¬ë“œ ë¶„ë¥˜
    
    Args:
        text: ë¶„ë¥˜í•  í…ìŠ¤íŠ¸
        metadata: ë©”íƒ€ë°ì´í„° ë”•ì…”ë„ˆë¦¬
    
    Returns:
        Dict: í†µí•© ë¶„ë¥˜ ê²°ê³¼
        {
            "category": str,
            "confidence": float,
            "reasoning": str,
            "text_result": {...},
            "metadata_result": {...},
            "merge_strategy": str,
            "source": str
        }
    """
    try:
        # 1. í…ìŠ¤íŠ¸ ë¶„ë¥˜
        text_result = classify_with_langchain(text)
        
        # 2. ë©”íƒ€ë°ì´í„° ë¶„ë¥˜
        metadata_result = classify_with_metadata(metadata)
        
        # 3. ì‹ ë¢°ë„ ê¸°ë°˜ ë³‘í•©
        text_conf = text_result["confidence"]
        meta_conf = metadata_result["confidence"]
        
        if text_conf >= 0.7:
            # í…ìŠ¤íŠ¸ 70% + ë©”íƒ€ 30%
            merge_strategy = "text_dominant (0.7:0.3)"
            # í…ìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ì£¼ë¡œ ì‚¬ìš©í•˜ë˜ ì‹ ë¢°ë„ ì¡°ì •
            final_category = text_result["category"]
            final_confidence = min(
                text_conf * 0.7 + meta_conf * 0.3,
                1.0
            )
        elif text_conf >= 0.5:
            # í…ìŠ¤íŠ¸ 50% + ë©”íƒ€ 50%
            merge_strategy = "balanced (0.5:0.5)"
            # ë™ì˜í•˜ë©´ ë†’ì€ ì‹ ë¢°ë„, ë¶ˆì¼ì¹˜í•˜ë©´ ë‚®ì€ ì‹ ë¢°ë„
            if text_result["category"] == metadata_result["category"]:
                final_category = text_result["category"]
                final_confidence = max(text_conf, meta_conf)
            else:
                # ë¶ˆì¼ì¹˜ ì‹œ ë©”íƒ€ë°ì´í„° ìš°ì„  (ë©”íƒ€ê°€ ë” ëª…ì‹œì )
                final_category = metadata_result["category"]
                final_confidence = min(
                    text_conf * 0.5 + meta_conf * 0.5,
                    1.0
                )
        else:
            # ë©”íƒ€ë°ì´í„° ìš°ì„  (70% ì´ìƒ)
            merge_strategy = "metadata_dominant (0.3:0.7)"
            final_category = metadata_result["category"]
            final_confidence = min(
                text_conf * 0.3 + meta_conf * 0.7,
                1.0
            )
        
        logger.info(
            f"í•˜ì´ë¸Œë¦¬ë“œ ë¶„ë¥˜: {final_category} "
            f"(strategy: {merge_strategy}, confidence: {final_confidence:.2%})"
        )
        
        return {
            "category": final_category,
            "confidence": final_confidence,
            "reasoning": f"í…ìŠ¤íŠ¸: {text_result['reasoning']} | ë©”íƒ€: {metadata_result['reasoning']}",
            "text_result": text_result,
            "metadata_result": metadata_result,
            "merge_strategy": merge_strategy,
            "source": "hybrid"
        }
    
    except Exception as e:
        logger.error(f"í•˜ì´ë¸Œë¦¬ë“œ ë¶„ë¥˜ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        raise



# í…ŒìŠ¤íŠ¸ìš©
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)

    print("=" * 60)
    print("Config ê¸°ë°˜ LangChain í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    print(f"API Key: {ModelConfig.GPT4O_MINI_API_KEY[:3]}..." if ModelConfig.GPT4O_MINI_API_KEY else "âŒ API Key ì—†ìŒ")
    print(f"API Base: {ModelConfig.GPT4O_MINI_BASE_URL[:3]}..................." if ModelConfig.GPT4O_MINI_BASE_URL else "âŒ API Base ëª»ì°¾ìŒ")
    print(f"Model: {ModelConfig.GPT4O_MINI_MODEL}" if ModelConfig.GPT4O_MINI_MODEL else "âŒ Model ì—†ìŒ")
    print("=" * 60)


    # í…ŒìŠ¤íŠ¸ 1: í…ìŠ¤íŠ¸ë§Œ
    test_text_1 = "11ì›” 30ì¼ê¹Œì§€ ì™„ì„±í•´ì•¼ í•˜ëŠ” í”„ë¡œì íŠ¸ ì œì•ˆì„œ"
    
    print("=" * 60)
    print("í…ŒìŠ¤íŠ¸ 1: í…ìŠ¤íŠ¸ë§Œ ë¶„ë¥˜")
    print("=" * 60)
    
    try:
        result = classify_with_langchain(test_text_1)
        print(json.dumps(result, indent=2, ensure_ascii=False))
    except Exception as e:
        print(f"ì˜¤ë¥˜: {e}")
    
    # í…ŒìŠ¤íŠ¸ 2: ë©”íƒ€ë°ì´í„° í¬í•¨
    print("\ní…ŒìŠ¤íŠ¸ 2: ë©”íƒ€ë°ì´í„° í¬í•¨ ë¶„ë¥˜\n")
    test_text_2 = "ë§ˆì¼€íŒ… ì „ëµ"
    test_metadata = {
        "filename": "marketing_strategy_2025.md",
        "created_date": "2025-01-01",
        "tags": ["work", "important"]
    }
    
    print("\n" + "=" * 60)
    print("í…ŒìŠ¤íŠ¸ 2: ë©”íƒ€ë°ì´í„° í¬í•¨ ë¶„ë¥˜")
    print("=" * 60)
    
    try:
        result = classify_with_langchain(test_text_2, metadata=test_metadata)
        print(json.dumps(result, indent=2, ensure_ascii=False))
    except Exception as e:
        print(f"ì˜¤ë¥˜: {e}")

    # ì¶”ê°€
    # í…ŒìŠ¤íŠ¸ 3: ë©”íƒ€ë°ì´í„°ë§Œ ë¶„ë¥˜ (ìƒˆë¡œìš´ í•¨ìˆ˜)
    print("\n" + "="*60)
    print("í…ŒìŠ¤íŠ¸ 3: ë©”íƒ€ë°ì´í„°ë§Œ ë¶„ë¥˜")
    print("="*60)

    test_metadata = {
        "basic_info": {
            "title": "2024ë…„ ì™„ë£Œëœ í”„ë¡œì íŠ¸ ë³´ê³ ì„œ",
            "summary": "ì§€ë‚œí•´ í”„ë¡œì íŠ¸ë“¤ì˜ ìµœì¢… ê²°ê³¼",
            "content_type": "report"
        },
        "temporal_info": {
            "created_date": "2024-12-31",
            "deadline": None,
            "status": "completed"
        }
    }

    try:
        result = classify_with_metadata(test_metadata)
        print(json.dumps(result, indent=2, ensure_ascii=False))
    except Exception as e:
        print(f"ì˜¤ë¥˜: {e}")

    # í…ŒìŠ¤íŠ¸ 4: í•˜ì´ë¸Œë¦¬ë“œ ë¶„ë¥˜ (ìƒˆë¡œìš´ í•¨ìˆ˜)
    print("\n" + "="*60)
    print("í…ŒìŠ¤íŠ¸ 4: í•˜ì´ë¸Œë¦¬ë“œ ë¶„ë¥˜ (í…ìŠ¤íŠ¸ + ë©”íƒ€ë°ì´í„°)")
    print("="*60)

    test_text = "ë‹¤ìŒ ë¶„ê¸° ë§ˆì¼€íŒ… ìº í˜ì¸"
    test_metadata = {
        "basic_info": {
            "title": "Q2_Marketing_Campaign_2025.md",
            "created_date": "2025-11-01"
        },
        "temporal_info": {
            "deadline": "2025-06-30",
            "status": "planning"
        }
    }

    try:
        result = hybrid_classify(test_text, test_metadata)
        print(json.dumps(result, indent=2, ensure_ascii=False))
    except Exception as e:
        print(f"ì˜¤ë¥˜: {e}")




"""test_result

    âœ… ModelConfig loaded from backend.config
    ============================================================
    Config ê¸°ë°˜ LangChain í…ŒìŠ¤íŠ¸
    ============================================================
    API Key: eyJ...
    API Base: htt...................
    Model: openai/gpt-4o-mini
    ============================================================
    ============================================================
    í…ŒìŠ¤íŠ¸ 1: í…ìŠ¤íŠ¸ë§Œ ë¶„ë¥˜
    ============================================================
    INFO:http****** "HTTP/1.1 200 OK"
    INFO:__main__:ë¶„ë¥˜ ì™„ë£Œ: Projects (confidence: 100.00%, metadata: False)
        {
        "category": "Projects",
        "confidence": 1.0,
        "reasoning": "ê¸°í•œ(11ì›” 30ì¼ê¹Œì§€)ê³¼ êµ¬ì²´ì  ëª©í‘œ(ì™„ì„±í•´ì•¼ í•˜ëŠ” í”„ë¡œì íŠ¸ ì œì•ˆì„œ)ê°€ ëª…ì‹œë˜ì–´ ìˆì–´ Projectsë¡œ ë¶„ë¥˜ë¨.",
        "detected_cues": [
            "11ì›” 30ì¼ê¹Œì§€",
            "ì™„ì„±í•´ì•¼ í•˜ëŠ”",
            "í”„ë¡œì íŠ¸ ì œì•ˆì„œ"
        ],
        "source": "langchain",
        "has_metadata": false
        }

    ============================================================
    í…ŒìŠ¤íŠ¸ 2: ë©”íƒ€ë°ì´í„° í¬í•¨ ë¶„ë¥˜
    ============================================================
    INFO:http****** "HTTP/1.1 200 OK"
    INFO:__main__:ë¶„ë¥˜ ì™„ë£Œ: Areas (confidence: 80.00%, metadata: True)
    {
    "category": "Areas",
    "confidence": 0.8,
    "reasoning": "ì§€ì†ì ì¸ ê´€ì‹¬ ì˜ì—­ì¸ 'ë§ˆì¼€íŒ… ì „ëµ'ìœ¼ë¡œ, êµ¬ì²´ì ì¸ ê¸°í•œì´ë‚˜ ì™„ë£Œ í‘œí˜„ì´ ì—†ì–´ Areasë¡œ ë¶„ë¥˜ë¨.",
    "detected_cues": [],
    "source": "langchain",
    "has_metadata": true
    }

"""



"""test_result_2(metadata_promptìš©)

    âœ… ModelConfig loaded from backend.config
    
    ============================================================
    Config ê¸°ë°˜ LangChain í…ŒìŠ¤íŠ¸
    ============================================================
    API Key: eyJ...
    API Base: htt...................
    Model: openai/gpt-4o-mini
    ============================================================

    ============================================================
    í…ŒìŠ¤íŠ¸ 3: ë©”íƒ€ë°ì´í„°ë§Œ ë¶„ë¥˜
    ============================================================
    INFO:httpx:HTTP Request: POST https:****** "HTTP/1.1 200 OK"
    INFO:__main__:ë©”íƒ€ë°ì´í„° ë¶„ë¥˜ ì™„ë£Œ: Archives (confidence: 95.00%)
    {
        "category": "Archives",
        "confidence": 0.95,
        "reasoning": "statusê°€ 'completed'ë¡œ ëª…ì‹œë˜ì–´ ìˆìœ¼ë©°, action_itemsì´ ì—†ê³ , ê³¼ê±° ë‚ ì§œë¡œ ì„¤ì •ë˜ì–´ ìˆì–´ Archivesë¡œ ë¶„ë¥˜ë©ë‹ˆë‹¤.",
        "detected_cues": [
            "status: completed"
        ],
        "source": "metadata",
        "metadata_used": true
    }

    ============================================================
    í…ŒìŠ¤íŠ¸ 4: í•˜ì´ë¸Œë¦¬ë“œ ë¶„ë¥˜ (í…ìŠ¤íŠ¸ + ë©”íƒ€ë°ì´í„°)
    ============================================================
    INFO:httpx:HTTP Request: POST https:****** "HTTP/1.1 200 OK"
    INFO:__main__:ë¶„ë¥˜ ì™„ë£Œ: Projects (confidence: 90.00%, metadata: False)
    INFO:httpx:HTTP Request: POST https:****** "HTTP/1.1 200 OK"
    INFO:__main__:ë©”íƒ€ë°ì´í„° ë¶„ë¥˜ ì™„ë£Œ: Projects (confidence: 90.00%)
    INFO:__main__:í•˜ì´ë¸Œë¦¬ë“œ ë¶„ë¥˜: Projects (strategy: text_dominant (0.7:0.3), confidence: 90.00%)
    {
        "category": "Projects",
        "confidence": 0.9,
        "reasoning": "í…ìŠ¤íŠ¸: ë‹¤ìŒ ë¶„ê¸°ë¼ëŠ” ì‹œê°„ í‘œí˜„ê³¼ ë§ˆì¼€íŒ… ìº í˜ì¸ì´ë¼ëŠ” êµ¬ì²´ì  ëª©í‘œê°€ ìˆì–´ Projectsë¡œ ë¶„ë¥˜ë¨. | ë©”íƒ€: statusê°€ 'planning'ì´ë©°, deadlineì´ ì¡´ì¬í•˜ì—¬ ëª…í™•í•œ í”„ë¡œì íŠ¸ë¡œ ë¶„ë¥˜ë©ë‹ˆë‹¤.",
        "text_result": {
            "category": "Projects",
            "confidence": 0.9,
            "reasoning": "ë‹¤ìŒ ë¶„ê¸°ë¼ëŠ” ì‹œê°„ í‘œí˜„ê³¼ ë§ˆì¼€íŒ… ìº í˜ì¸ì´ë¼ëŠ” êµ¬ì²´ì  ëª©í‘œê°€ ìˆì–´ Projectsë¡œ ë¶„ë¥˜ë¨.",
            "detected_cues": [
                "ë‹¤ìŒ ë¶„ê¸°",
                "ë§ˆì¼€íŒ… ìº í˜ì¸"
            ],
            "source": "langchain",
            "has_metadata": false
    },
    "metadata_result": {
        "category": "Projects",
        "confidence": 0.9,
        "reasoning": "statusê°€ 'planning'ì´ë©°, deadlineì´ ì¡´ì¬í•˜ì—¬ ëª…í™•í•œ í”„ë¡œì íŠ¸ë¡œ ë¶„ë¥˜ë©ë‹ˆë‹¤.",
        "detected_cues": [
            "status: planning",
            "deadline: 2025-06-30"
        ],
        "source": "metadata",
        "metadata_used": true
    },
    "merge_strategy": "text_dominant (0.7:0.3)",
    "source": "hybrid"
    }

"""