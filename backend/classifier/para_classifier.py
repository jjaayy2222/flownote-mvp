# backend/classifier/para_classifier.py 

"""
PARA ë¶„ë¥˜ê¸° - LangChain ê¸°ë°˜
í…ìŠ¤íŠ¸ë¥¼ Projects, Areas, Resources, Archivesë¡œ ë¶„ë¥˜
ìƒëŒ€ê²½ë¡œ + Fallback ì‹œìŠ¤í…œ í¬í•¨
"""

from typing import Dict, Tuple, Optional, Any
import logging
from datetime import datetime
from pathlib import Path

prompt_path = Path(__file__).parent / "prompts" / "para_system.txt"

#from langchain_integration import classify_with_langchain
from backend.classifier.langchain_integration import classify_with_langchain

logger = logging.getLogger(__name__)


class PARAClassifier:
    """
    PARA ì‹œìŠ¤í…œ ê¸°ë°˜ ìë™ ë¶„ë¥˜ í´ë˜ìŠ¤ (LangChain í†µí•©)
    
    Projects: ëª…í™•í•œ ê¸°í•œê³¼ ëª©í‘œê°€ ìˆëŠ” ì‘ì—…
    Areas: ì§€ì†ì ìœ¼ë¡œ ê´€ì‹¬ìˆëŠ” ì˜ì—­
    Resources: ì°¸ê³ ìš© ìë£Œ/ì •ë³´
    Archives: ì™„ë£Œë˜ì—ˆê±°ë‚˜ ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê²ƒ
    """
    
    CATEGORIES = {
        "Projects": {
            "icon": "ğŸ“‹",
            "color": "#3498db",
            "description": "ëª…í™•í•œ ê¸°í•œê³¼ ëª©í‘œê°€ ìˆëŠ” ì‘ì—…"
        },
        "Areas": {
            "icon": "ğŸ¯",
            "color": "#2ecc71",
            "description": "ì§€ì†ì ìœ¼ë¡œ ê´€ì‹¬ìˆëŠ” ì˜ì—­"
        },
        "Resources": {
            "icon": "ğŸ“š",
            "color": "#f39c12",
            "description": "ì°¸ê³ ìš© ìë£Œ ë° ì •ë³´"
        },
        "Archives": {
            "icon": "ğŸ“¦",
            "color": "#95a5a6",
            "description": "ì™„ë£Œë˜ì—ˆê±°ë‚˜ ë¯¸ì‚¬ìš© í•­ëª©"
        }
    }
    
    def __init__(self, use_langchain: bool = True):
        """
        ë¶„ë¥˜ê¸° ì´ˆê¸°í™”
        
        Args:
            use_langchain: LangChain ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸: True)
        """
        self.categories = self.CATEGORIES
        self.classification_history = []
        self.use_langchain = use_langchain
        logger.info(f"PARAClassifier initialized (LangChain: {use_langchain})")
    
    def classify_text(
        self,
        text: str,
        filename: str = "unknown",
        metadata: Optional[Dict[str, Any]] = None
    ) -> Dict:
        """
        í…ìŠ¤íŠ¸ë¥¼ PARA ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜
        
        Args:
            text (str): ë¶„ë¥˜í•  í…ìŠ¤íŠ¸
            filename (str): íŒŒì¼ëª… (ì°¸ê³ ìš©)
            metadata (Optional[Dict]): ë©”íƒ€ë°ì´í„° (ë¯¸ë˜ ëŒ€ë¹„)
        
        Returns:
            Dict: ë¶„ë¥˜ ê²°ê³¼
        """
        
        if not text or not isinstance(text, str):
            logger.warning(f"Invalid text input for {filename}")
            return {
                "category": "Resources",
                "confidence": 0.0,
                "reason": "Invalid input",
                "filename": filename
            }
        
        try:
            # LangChainìœ¼ë¡œ ë¶„ë¥˜
            if self.use_langchain:
                result = classify_with_langchain(text, metadata=metadata)
                
                classification_result = {
                    "category": result["category"],
                    "confidence": result["confidence"],
                    "reasoning": result["reasoning"],
                    "detected_cues": result.get("detected_cues", []),
                    "timestamp": datetime.now().isoformat(),
                    "filename": filename,
                    "source": "langchain",
                    "has_metadata": result.get("has_metadata", False)
                }
            else:
                # í´ë°±: í‚¤ì›Œë“œ ê¸°ë°˜ (STEP 5.2.1)
                scores = self._calculate_scores_fallback(text.lower(), filename)
                best_category = max(scores.items(), key=lambda x: x[1])
                
                classification_result = {
                    "category": best_category[0],
                    "confidence": min(best_category[1] / 100, 1.0),
                    "scores": scores,
                    "timestamp": datetime.now().isoformat(),
                    "filename": filename,
                    "source": "keyword"
                }
            
            # íˆìŠ¤í† ë¦¬ ì €ì¥
            self._save_to_history(classification_result)
            
            logger.info(
                f"Classified '{filename}' as '{classification_result['category']}' "
                f"(confidence: {classification_result['confidence']:.2%})"
            )
            
            return classification_result
        
        except Exception as e:
            logger.error(f"ë¶„ë¥˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            # ì—ëŸ¬ ì‹œ Resourcesë¡œ í´ë°±
            return {
                "category": "Resources",
                "confidence": 0.0,
                "reason": f"Error: {str(e)}",
                "filename": filename,
                "source": "error"
            }
    
    def _calculate_scores_fallback(self, text: str, filename: str) -> Dict[str, float]:
        """
        í‚¤ì›Œë“œ ê¸°ë°˜ ì ìˆ˜ ê³„ì‚° (LangChain ì‹¤íŒ¨ ì‹œ í´ë°±)
        """
        scores = {
            "Projects": 0.0,
            "Areas": 0.0,
            "Resources": 0.0,
            "Archives": 0.0
        }
        
        # Projects í‚¤ì›Œë“œ
        project_keywords = [
            "deadline", "due date", "goal", "target", "task", "sprint",
            "ë§ˆê°", "ëª©í‘œ", "ê³¼ì œ", "ê³„íš", "ì§„í–‰", "êµ¬í˜„", "ë°°í¬"
        ]
        
        # Areas í‚¤ì›Œë“œ
        area_keywords = [
            "learning", "skill", "development", "improvement", "habit",
            "ê´€ë¦¬", "ìœ ì§€", "ê°œì„ ", "í•™ìŠµ", "ê¸°ìˆ ", "ì§€ì†", "ë°˜ë³µ"
        ]
        
        # Resources í‚¤ì›Œë“œ
        resource_keywords = [
            "reference", "guide", "tutorial", "documentation", "template",
            "ì°¸ê³ ", "ìë£Œ", "ê°€ì´ë“œ", "ì„¤ëª…ì„œ", "ì •ë³´", "ëª¨ìŒ"
        ]
        
        # Archives í‚¤ì›Œë“œ
        archive_keywords = [
            "completed", "finished", "done", "old", "deprecated", "archived",
            "ì™„ë£Œ", "ë", "êµ¬ì‹", "ë³´ê´€", "ë¯¸ì‚¬ìš©", "2024", "2023"
        ]
        
        scores["Projects"] += self._count_keywords(text, project_keywords) * 20
        scores["Areas"] += self._count_keywords(text, area_keywords) * 20
        scores["Resources"] += self._count_keywords(text, resource_keywords) * 20
        scores["Archives"] += self._count_keywords(text, archive_keywords) * 20
        
        # íŒŒì¼ëª… ê¸°ë°˜ ì¶”ê°€
        filename_lower = filename.lower()
        if "archive" in filename_lower or "old" in filename_lower:
            scores["Archives"] += 30
        elif "resource" in filename_lower or "guide" in filename_lower:
            scores["Resources"] += 30
        elif "project" in filename_lower or "task" in filename_lower:
            scores["Projects"] += 30
        
        if sum(scores.values()) == 0:
            scores["Resources"] = 50
        
        return scores
    
    def _count_keywords(self, text: str, keywords: list) -> int:
        """í…ìŠ¤íŠ¸ì— í¬í•¨ëœ í‚¤ì›Œë“œ ê°œìˆ˜ ì¹´ìš´íŠ¸"""
        count = 0
        for keyword in keywords:
            if keyword in text:
                count += text.count(keyword)
        return count
    
    def _save_to_history(self, result: Dict):
        """ë¶„ë¥˜ ê²°ê³¼ë¥¼ íˆìŠ¤í† ë¦¬ì— ì €ì¥"""
        self.classification_history.append(result)
        if len(self.classification_history) > 1000:
            self.classification_history = self.classification_history[-1000:]
    
    def get_category_info(self, category: str) -> Dict:
        """ì¹´í…Œê³ ë¦¬ ì •ë³´ ë°˜í™˜"""
        return self.categories.get(category, self.categories["Resources"])
    
    def get_history(self, limit: int = 10) -> list:
        """ìµœê·¼ ë¶„ë¥˜ íˆìŠ¤í† ë¦¬ ë°˜í™˜"""
        return self.classification_history[-limit:]
    
    def reset(self):
        """ë¶„ë¥˜ê¸° ë¦¬ì…‹"""
        self.classification_history = []
        logger.info("PARAClassifier reset")


# í…ŒìŠ¤íŠ¸ìš©
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    
    classifier = PARAClassifier(use_langchain=True)
    
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤
    test_texts = [
        ("ë§ˆê°ì´ 11ì›” 30ì¼ì¸ í”„ë¡œì íŠ¸ ì œì•ˆì„œ", "project_proposal.txt"),
        ("Python í•™ìŠµ ìë£Œ ë° íŠœí† ë¦¬ì–¼ ëª¨ìŒ", "learning_resources.md"),
        ("ì§€ë‚œí•´ ì™„ë£Œëœ í”„ë¡œì íŠ¸ ì•„ì¹´ì´ë¸Œ", "old_project_2024.txt"),
        ("API ë¬¸ì„œ ë° ì°¸ê³ ìë£Œ", "api_reference.pdf"),
    ]
    
    print("=" * 60)
    print("PARA ë¶„ë¥˜ê¸° í…ŒìŠ¤íŠ¸ (LangChain í†µí•©)")
    print("=" * 60)
    
    for text, filename in test_texts:
        result = classifier.classify_text(text, filename)
        print(f"\nğŸ“„ {filename}")
        print(f"   ë¶„ë¥˜: {result['category']} ({result['confidence']:.0%})")
        print(f"   ê·¼ê±°: {result.get('reasoning', 'N/A')}")
        print(f"   ë‹¨ì„œ: {', '.join(result.get('detected_cues', [])[:3])}")



"""test_result(Phase5.2.1)

    cd backend/classifier
    python para_classifier.py

    ğŸ“„ project_proposal.txt
        ë¶„ë¥˜: Projects (50%)
        ì ìˆ˜: {'Projects': 50.0, 'Areas': 0.0, 'Resources': 0.0, 'Archives': 0.0}

    ğŸ“„ learning_resources.md
        ë¶„ë¥˜: Resources (50%)
        ì ìˆ˜: {'Projects': 0.0, 'Areas': 20.0, 'Resources': 50.0, 'Archives': 0.0}

    ğŸ“„ old_project_2024.txt
        ë¶„ë¥˜: Archives (50%)
        ì ìˆ˜: {'Projects': 0.0, 'Areas': 0.0, 'Resources': 0.0, 'Archives': 50.0}

    ğŸ“„ api_reference.pdf
        ë¶„ë¥˜: Resources (40%)
        ì ìˆ˜: {'Projects': 0.0, 'Areas': 0.0, 'Resources': 40.0, 'Archives': 0.0}

"""


"""test_result(Phase5.2.2)

    python backend/classifier/para_classifier.py
    
    âœ… ModelConfig loaded from backend.config

    INFO:__main__:PARAClassifier initialized (LangChain: True)
    ============================================================
    PARA ë¶„ë¥˜ê¸° í…ŒìŠ¤íŠ¸ (LangChain í†µí•©)
    ============================================================
    
    INFO:httpx:HTTP Request: POST https:**** "HTTP/1.1 200 OK"
    INFO:langchain_integration:ë¶„ë¥˜ ì™„ë£Œ: Projects (confidence: 100.00%, metadata: False)
    INFO:__main__:Classified 'project_proposal.txt' as 'Projects' (confidence: 100.00%)

    ğŸ“„ project_proposal.txt
        ë¶„ë¥˜: Projects (100%)
        ê·¼ê±°: ë§ˆê°ì¼(11ì›” 30ì¼)ê³¼ êµ¬ì²´ì  ëª©í‘œ(í”„ë¡œì íŠ¸ ì œì•ˆì„œ)ë¡œ ì¸í•´ Projectsë¡œ ë¶„ë¥˜ë¨.
        ë‹¨ì„œ: ë§ˆê°, í”„ë¡œì íŠ¸, ì œì•ˆì„œ

    INFO:httpx:HTTP Request: POST https:**** "HTTP/1.1 200 OK"
    INFO:langchain_integration:ë¶„ë¥˜ ì™„ë£Œ: Resources (confidence: 95.00%, metadata: False)
    INFO:__main__:Classified 'learning_resources.md' as 'Resources' (confidence: 95.00%)

    ğŸ“„ learning_resources.md
        ë¶„ë¥˜: Resources (95%)
        ê·¼ê±°: ì°¸ê³  ìë£Œë¡œì„œ 'í•™ìŠµ ìë£Œ'ì™€ 'íŠœí† ë¦¬ì–¼'ì´ë¼ëŠ” í‘œí˜„ì´ í¬í•¨ë˜ì–´ ìˆì–´ Resourcesë¡œ ë¶„ë¥˜ë¨.
        ë‹¨ì„œ: í•™ìŠµ ìë£Œ, íŠœí† ë¦¬ì–¼, ëª¨ìŒ

    INFO:httpx:HTTP Request: POST https:**** "HTTP/1.1 200 OK"
    INFO:langchain_integration:ë¶„ë¥˜ ì™„ë£Œ: Archives (confidence: 100.00%, metadata: False)
    INFO:__main__:Classified 'old_project_2024.txt' as 'Archives' (confidence: 100.00%)

    ğŸ“„ old_project_2024.txt
        ë¶„ë¥˜: Archives (100%)
        ê·¼ê±°: ì™„ë£Œ í‘œí˜„(ì™„ë£Œëœ)ê³¼ ê³¼ê±°í˜• í‘œê¸°(ì§€ë‚œí•´)ë¡œ ì¸í•´ Archivesë¡œ ë¶„ë¥˜ë¨.
        ë‹¨ì„œ: ì™„ë£Œ, ì§€ë‚œí•´, ì•„ì¹´ì´ë¸Œ

    INFO:httpx:HTTP Request: POST https:**** "HTTP/1.1 200 OK"
    INFO:langchain_integration:ë¶„ë¥˜ ì™„ë£Œ: Resources (confidence: 90.00%, metadata: False)
    INFO:__main__:Classified 'api_reference.pdf' as 'Resources' (confidence: 90.00%)

    ğŸ“„ api_reference.pdf
        ë¶„ë¥˜: Resources (90%)
        ê·¼ê±°: ì°¸ê³  ìë£Œì™€ ê´€ë ¨ëœ ë‚´ìš©ìœ¼ë¡œ, 'ë¬¸ì„œ'ì™€ 'ì°¸ê³ ìë£Œ'ë¼ëŠ” í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆì–´ Resourcesë¡œ ë¶„ë¥˜ë¨.
        ë‹¨ì„œ: API ë¬¸ì„œ, ì°¸ê³ ìë£Œ

"""