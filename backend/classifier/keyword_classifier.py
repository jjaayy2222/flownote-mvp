# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# backend/classifier/keyword_classifier.py
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

"""
í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜ê¸° - LLM ê¸°ë°˜ (í”„ë¡ì‹œ API ì§€ì›)
LangChain í†µí•© + ì™„ë²½í•œ JSON ì¶œë ¥ ë³´ì¥

êµ¬ì¡°:
- ë™ì  ê²½ë¡œ ê³„ì‚° (.env ìë™ ë¡œë“œ)
- sys.pathì— ëª…ì‹œì  ì¶”ê°€
- 3-tier fallback import (ì ˆëŒ€ â†’ ìƒëŒ€ â†’ í™˜ê²½ë³€ìˆ˜)
- ê°•í™”ëœ í”„ë¡¬í”„íŠ¸ (JSON ì§€ì‹œ ëª…í™•)
"""

import json
import logging
import os
import sys
import re
from typing import Dict, Any, Optional, List
import time
from datetime import datetime
import uuid

from pathlib import Path
from dotenv import load_dotenv


# ============================================================
# 1. ë™ì  ê²½ë¡œ ê³„ì‚° (ìƒëŒ€ê²½ë¡œ + .env ìë™ë¡œë“œ)
# ============================================================

CURRENT_FILE = Path(__file__)
CLASSIFIER_DIR = CURRENT_FILE.parent
BACKEND_DIR = CLASSIFIER_DIR.parent
PROJECT_ROOT = BACKEND_DIR.parent

# .env íŒŒì¼ ìë™ ë¡œë“œ
ENV_FILE = PROJECT_ROOT / ".env"
load_dotenv(str(ENV_FILE))

# ============================================================
# 2. sys.pathì— ê²½ë¡œ ëª…ì‹œì  ì¶”ê°€
# ============================================================

sys.path.insert(0, str(BACKEND_DIR))
sys.path.insert(0, str(PROJECT_ROOT))

# ============================================================
# 3. ì„í¬íŠ¸
# ============================================================

from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# ============================================================
# 4. Config Import (3-tier Fallback)
# ============================================================

try:
    from backend.config import ModelConfig

    logger_msg = "âœ… ModelConfig loaded from backend.config"
except ImportError:
    try:
        from config import ModelConfig

        logger_msg = "âœ… ModelConfig loaded from config"
    except ImportError:
        logger_msg = "âš ï¸  Using os.getenv fallback"

        class ModelConfig:
            GPT4O_MINI_API_KEY = os.getenv("GPT4O_MINI_API_KEY")
            GPT4O_MINI_BASE_URL = os.getenv("GPT4O_MINI_BASE_URL")
            GPT4O_MINI_MODEL = os.getenv("GPT4O_MINI_MODEL", "gpt-4o-mini")


logger = logging.getLogger(__name__)
logger.info(logger_msg)


# ============================================================
# 5. KeywordClassifier í´ë˜ìŠ¤
# ============================================================


class KeywordClassifier:
    """
    í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜ê¸° (LLM ê¸°ë°˜ - GPT-4o-mini)

    âœ… íŠ¹ì§•:
    - ë¹„ë™ê¸°/ë™ê¸° ë©”ì„œë“œ ëª¨ë‘ ì§€ì›
    - ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ì™„ì „ ì§€ì›
    - UUID ê¸°ë°˜ ì¸ìŠ¤í„´ìŠ¤ ì¶”ì 
    - í”„ë¡¬í”„íŠ¸ íŒŒì¼ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ëª¨ë“  ë³€ìˆ˜ ì „ë‹¬í•˜ê¸°)
    """

    def __init__(self):
        """KeywordClassifier ì´ˆê¸°í™”"""

        # ê³ ìœ  IDë¡œ ì¸ìŠ¤í„´ìŠ¤ ì¶”ì 
        self.instance_id = str(uuid.uuid4())[:8]
        self.created_at = datetime.now().strftime("%H:%M:%S")

        self.llm = None
        self.chain = None
        self._initialize_llm()
        self._load_prompt()

        logger.info(
            f"âœ… KeywordClassifier initialized (ID: {self.instance_id}, Time: {self.created_at})"
        )

    def _initialize_llm(self):
        """LLM ì´ˆê¸°í™” - ìºì‹± ì—†ìŒ"""
        try:
            # ë§¤ë²ˆ ìƒˆë¡œ ì—°ê²°í•˜ê¸°
            api_key = ModelConfig.GPT4O_MINI_API_KEY

            if not api_key:
                raise ValueError("âŒ GPT4O_MINI_API_KEY not set")

            self.llm = ChatOpenAI(
                api_key=api_key,
                base_url=ModelConfig.GPT4O_MINI_BASE_URL,
                model=ModelConfig.GPT4O_MINI_MODEL,
                temperature=0.7,
                max_tokens=600,
            )

            logger.info("âœ… KeywordClassifier LLM ì´ˆê¸°í™” ì„±ê³µ")

        except Exception as e:
            logger.error(f"âŒ LLM ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.llm = None

    def _load_prompt(self):
        """í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë¡œë“œ ë° Chain ìƒì„±

        - í”„ë¡¬í”„íŠ¸ íŒŒì¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ê¸°
        - í…œí”Œë¦¿ ë³€ìˆ˜ ëª¨ë‘ ì „ë‹¬í•˜ê¸°
        """
        try:
            prompt_path = (
                CLASSIFIER_DIR / "prompts" / "keyword_classification_prompt.txt"
            )

            if not prompt_path.exists():
                raise FileNotFoundError(f"í”„ë¡¬í”„íŠ¸ íŒŒì¼ ì—†ìŒ: {prompt_path}")

            with open(prompt_path, "r", encoding="utf-8") as f:
                template_content = f.read()

            # í”„ë¡¬í”„íŠ¸ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ë³€ìˆ˜ ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬)
            escaped_content = self._escape_prompt_braces(template_content)

            # ChatPromptTemplate ìƒì„±
            prompt = ChatPromptTemplate.from_messages(
                [
                    (
                        "system",
                        "You are a keyword extraction and classification expert. Always respond with valid JSON only.",
                    ),
                    ("user", escaped_content),
                ]
            )

            # Chain ìƒì„±: Prompt â†’ LLM â†’ StrOutputParser
            if self.llm:
                self.chain = prompt | self.llm | StrOutputParser()
                logger.info(
                    f"[{self.instance_id}] âœ… Chain ìƒì„± ì„±ê³µ (í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë¡œë“œ ì™„ë£Œ)"
                )
            else:
                logger.warning(
                    f"[{self.instance_id}] âš ï¸  LLM ë¯¸ì´ˆê¸°í™”ë¡œ Chain ìƒì„± ë¶ˆê°€"
                )
        except Exception as e:
            logger.error(f"âŒ í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.chain = None

    def _escape_prompt_braces(self, content: str) -> str:
        """
        í”„ë¡¬í”„íŠ¸ì˜ ì¤‘ê´„í˜¸ ì´ìŠ¤ì¼€ì´í”„

        - {text}, {occupation}, {areas}, {interests}, {context_keywords} ë³€ìˆ˜ ìœ ì§€
        - ë‚˜ë¨¸ì§€ {}ëŠ” {{ }}ë¡œ ì´ìŠ¤ì¼€ì´í”„
        """
        # í…œí”Œë¦¿ ë³€ìˆ˜ ëª©ë¡
        template_vars = [
            "{text}",
            "{occupation}",
            "{areas}",
            "{interests}",
            "{context_keywords}",
        ]

        lines = []

        for line in content.split("\n"):

            # í…œí”Œë¦¿ ë³€ìˆ˜ê°€ ìˆëŠ” ë¼ì¸ì€ ê·¸ëŒ€ë¡œ ìœ ì§€
            if any(var in line for var in template_vars):
                lines.append(line)
            else:
                # ë‚˜ë¨¸ì§€ ë¼ì¸ì˜ { } ë¥¼ {{ }} ë¡œ ë³€í™˜
                # ë‹¨, ì´ë¯¸ ì´ìŠ¤ì¼€ì´í”„ëœ {{ }} ëŠ” ê±´ë“œë¦¬ì§€ ì•ŠìŒ
                escaped_line = line.replace("{", "{{").replace("}", "}}")
                # {{{{ â†’ {{ ë¡œ ì¤‘ë³µ ì´ìŠ¤ì¼€ì´í”„ ë°©ì§€
                escaped_line = escaped_line.replace("{{{{", "{{").replace("}}}}", "}}")
                lines.append(escaped_line)

        return "\n".join(lines)

    # ì¶”ê°€
    def _prepare_prompt_variables(
        self, text: str, user_context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, str]:
        """í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë³€ìˆ˜ ì¤€ë¹„

        - ëª¨ë“  ë³€ìˆ˜ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•´ì„œ ì „ë‹¬!
        """
        # ê¸°ë³¸ê°’ ì„¤ì •
        occupation = "ì¼ë°˜ ì‚¬ìš©ì"
        areas = []
        interests = []
        context_keywords = {}

        # ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œ
        if user_context:
            occupation = user_context.get("occupation", "ì¼ë°˜ ì‚¬ìš©ì")
            areas = user_context.get("areas", [])
            interests = user_context.get("interests", [])

            # context_keywords ìƒì„± (areas ê¸°ë°˜)
            for area in areas:
                context_keywords[area] = [area, f"{area} ê´€ë ¨", f"{area} ì—…ë¬´"]

        # ëª¨ë“  ë³€ìˆ˜ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ê¸°
        return {
            "text": str(text[:1000]),  # ìµœëŒ€ 1000ì
            "occupation": str(occupation),
            "areas": ", ".join(areas) if areas else "ì—†ìŒ",  # ë¦¬ìŠ¤íŠ¸ â†’ ë¬¸ìì—´
            "interests": ", ".join(interests) if interests else "ì—†ìŒ",
            "context_keywords": json.dumps(
                context_keywords, ensure_ascii=False
            ),  # dict â†’ JSON ë¬¸ìì—´
        }

    # ============================================================
    # ë¹„ë™ê¸° ë©”ì„œë“œ (FastAPIì—ì„œ ì‚¬ìš©!)
    # ============================================================
    async def aclassify(
        self, text: str, user_context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """í…ìŠ¤íŠ¸ ë¶„ë¥˜ (ë¹„ë™ê¸° ë²„ì „)

        - ëª¨ë“  í”„ë¡¬í”„íŠ¸ ë³€ìˆ˜ ì „ë‹¬ (context_keywords í¬í•¨!)
        - ë¹„ë™ê¸° LLM í˜¸ì¶œ
        - êµ¬ì¡°í™”ëœ ì¶œë ¥ íŒŒì‹± (JSON)
        - ê²¬ê³ í•œ ì—ëŸ¬ í•¸ë“¤ë§
        """
        start_time = time.time()

        # ë¹ˆ í…ìŠ¤íŠ¸ í™•ì¸
        if not text or not text.strip():
            logger.warning(f"[{self.instance_id}] âš ï¸  ë¹ˆ í…ìŠ¤íŠ¸ ì…ë ¥")
            return self._create_empty_response()

        # Chain ë¯¸ì´ˆê¸°í™” í™•ì¸
        if self.chain is None:
            logger.warning(f"[{self.instance_id}] âš ï¸  Chain ë¯¸ì´ˆê¸°í™”, Fallback")
            return self._fallback_classify(text)

        try:
            # Step 1: ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ ìƒì„±
            context_keywords = []
            if user_context:
                # areasì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
                if user_context.get("areas"):
                    context_keywords.extend(user_context["areas"])
                # interestsì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
                if user_context.get("interests"):
                    context_keywords.extend(user_context["interests"])

            # ì¤‘ë³µ ì œê±° ë° ë¬¸ìì—´ ë³€í™˜
            context_keywords = list(set(context_keywords)) if context_keywords else []
            context_keywords_str = (
                ", ".join(context_keywords) if context_keywords else "ì—†ìŒ"
            )

            # Step 2: í”„ë¡¬í”„íŠ¸ ë³€ìˆ˜ ì¤€ë¹„ (ëª¨ë“  í•„ìˆ˜ ë³€ìˆ˜ í¬í•¨!)
            prompt_vars = {
                "text": text,
                "occupation": (
                    user_context.get("occupation", "ì¼ë°˜ ì‚¬ìš©ì")
                    if user_context
                    else "ì¼ë°˜ ì‚¬ìš©ì"
                ),
                "areas": (
                    ", ".join(user_context.get("areas", []))
                    if user_context and user_context.get("areas")
                    else "ì—†ìŒ"
                ),
                "interests": (
                    ", ".join(user_context.get("interests", []))
                    if user_context and user_context.get("interests")
                    else "ì—†ìŒ"
                ),
                "context_keywords": context_keywords_str,  # âœ… ëˆ„ë½ëœ ë³€ìˆ˜ ì¶”ê°€!
            }

            logger.info(f"[{self.instance_id}] ğŸ” Calling LLM (async)...")
            logger.info(f"[{self.instance_id}]   - Text length: {len(text)}")
            logger.info(
                f"[{self.instance_id}]   - Occupation: {prompt_vars['occupation']}"
            )
            logger.info(f"[{self.instance_id}]   - Areas: {prompt_vars['areas']}")
            logger.info(
                f"[{self.instance_id}]   - Context Keywords: {prompt_vars['context_keywords']}"
            )

            # Step 3: ë¹„ë™ê¸° LLM í˜¸ì¶œ
            response = await self.chain.ainvoke(prompt_vars)

            # Step 4: ì‘ë‹µ íƒ€ì… í™•ì¸ ë° ë¡œê¹…
            logger.info(f"[{self.instance_id}] ğŸ“¦ RAW LLM Response:")
            logger.info(f"[{self.instance_id}]   - Type: {type(response)}")
            logger.info(
                f"[{self.instance_id}]   - Content preview: {str(response)[:200]}"
            )

            # Step 5: ì‘ë‹µ íŒŒì‹± (íƒ€ì…ì— ë”°ë¼ ë¶„ê¸°)
            if isinstance(response, dict):
                # ì´ë¯¸ dict í˜•íƒœë¡œ íŒŒì‹±ëœ ê²½ìš° (StructuredOutputParser ì‚¬ìš© ì‹œ)
                result = response
            elif isinstance(response, str):
                # ë¬¸ìì—´ ì‘ë‹µì¸ ê²½ìš° JSON íŒŒì‹± ì‹œë„
                json_text = self._extract_json_from_response(response)
                result = json.loads(json_text)
            else:
                # ê¸°íƒ€ íƒ€ì… (ì˜ˆ: AIMessage)
                response_text = str(response)
                json_text = self._extract_json_from_response(response_text)
                result = json.loads(json_text)

            # Step 6: tags í•„ë“œ ê²€ì¦ ë° ì •ê·œí™”
            raw_tags = result.get("tags", [])
            logger.info(
                f"[{self.instance_id}] ğŸ“¦ Extracted tags: {raw_tags} (type: {type(raw_tags)})"
            )

            if not raw_tags:
                # logger.warning(f"[{self.instance_id}] âš ï¸  tags ì—†ìŒ, ê¸°ë³¸ê°’ ì„¤ì •")
                # íƒœê·¸ ì—†ìœ¼ë©´ í…ìŠ¤íŠ¸ì—ì„œ ê°•ì œ ì¶”ì¶œ
                logger.warning(
                    f"[{self.instance_id}] âš ï¸  LLMì´ ë¹ˆ íƒœê·¸ ë°˜í™˜, ê°•ì œ ì¶”ì¶œ ì‹œë„"
                )
                raw_tags = self._extract_fallback_tags(text, user_context)

                # íƒ€ì… ê²€ì¦
                if isinstance(raw_tags, str):
                    raw_tags = [
                        tag.strip() for tag in raw_tags.split(",") if tag.strip()
                    ]

                # ìµœì†Œ 1ê°œ ë³´ì¥
                final_tags = [
                    str(tag).strip() for tag in raw_tags if tag and str(tag).strip()
                ]
                if not final_tags:
                    final_tags = self._extract_fallback_tags(text, user_context)

                logger.info(f"[{self.instance_id}] âœ… ê°•ì œ ì¶”ì¶œ ì™„ë£Œ: (async):")
                logger.info(f"[{self.instance_id}]   - Tags: {final_tags}")
                logger.info(
                    f"[{self.instance_id}]   - Confidence: {result.get('confidence', 0.0)}"
                )

                return {
                    "tags": final_tags,
                    "confidence": result.get("confidence", 0.0),
                    "matched_keywords": result.get("matched_keywords", {}),
                    "reasoning": result.get("reasoning", ""),
                    "user_context_matched": result.get("user_context_matched", False),
                    "processing_time": f"{time.time() - start_time:.2f}s",
                    "instance_id": self.instance_id,
                }

            elif isinstance(raw_tags, str):
                # ë¬¸ìì—´ì¸ ê²½ìš° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                if "," in raw_tags:
                    tags = [tag.strip() for tag in raw_tags.split(",") if tag.strip()]
                else:
                    tags = [raw_tags.strip()] if raw_tags.strip() else ["ê¸°íƒ€"]
                logger.info(f"[{self.instance_id}] ğŸ”„ ë¬¸ìì—´ â†’ ë¦¬ìŠ¤íŠ¸ ë³€í™˜: {tags}")

            elif isinstance(raw_tags, list):
                # ë¦¬ìŠ¤íŠ¸ ê²€ì¦ ë° ì •ë¦¬
                tags = [
                    str(tag).strip() for tag in raw_tags if tag and str(tag).strip()
                ]
                if not tags:
                    tags = ["ê¸°íƒ€"]
                logger.info(f"[{self.instance_id}] âœ… ë¦¬ìŠ¤íŠ¸ ê²€ì¦ ì™„ë£Œ: {len(tags)}ê°œ")
            else:
                logger.warning(
                    f"[{self.instance_id}] âš ï¸  ì˜ˆìƒì¹˜ ëª»í•œ íƒ€ì…: {type(raw_tags)}"
                )
                tags = ["ê¸°íƒ€"]

            # Step 7: confidence ê²€ì¦
            confidence = result.get("confidence", 0.5)
            try:
                confidence = float(confidence)
                # 0~1 ë²”ìœ„ë¡œ ì œí•œ
                confidence = max(0.0, min(1.0, confidence))
            except (ValueError, TypeError):
                logger.warning(
                    f"[{self.instance_id}] âš ï¸  ì˜ëª»ëœ confidence ê°’: {confidence}"
                )
                confidence = 0.5

            # Step 8: ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ë§¤ì¹­ í™•ì¸
            user_context_matched = False
            if user_context and user_context.get("areas"):
                matched_areas = [
                    area
                    for area in user_context["areas"]
                    if any(area.lower() in tag.lower() for tag in tags)
                ]
                user_context_matched = len(matched_areas) > 0

            # Step 9: ìµœì¢… ê²°ê³¼ ì¡°ë¦½
            processing_time = round(time.time() - start_time, 2)

            final_result = {
                "tags": tags,
                "confidence": confidence,
                "user_context_matched": user_context_matched,
                "user_areas": user_context.get("areas", []) if user_context else [],
                "instance_id": self.instance_id,
                "processing_time": f"{processing_time}s",
            }

            logger.info(f"[{self.instance_id}] âœ… ë¶„ë¥˜ ì™„ë£Œ (async):")
            logger.info(f"[{self.instance_id}]   - Tags: {tags[:5]}")  # ì²˜ìŒ 5ê°œë§Œ í‘œì‹œ
            logger.info(f"[{self.instance_id}]   - Confidence: {confidence}")
            logger.info(f"[{self.instance_id}]   - Time: {processing_time}s")

            return final_result

        except json.JSONDecodeError as e:
            logger.error(f"[{self.instance_id}] âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            logger.error(
                f"[{self.instance_id}]   - Response preview: {str(response)[:500] if 'response' in locals() else 'N/A'}"
            )
            return self._fallback_classify(text)

        except Exception as e:
            logger.error(
                f"[{self.instance_id}] âŒ ë¶„ë¥˜ ì˜¤ë¥˜ (async): {type(e).__name__}: {e}",
                exc_info=True,
            )
            return self._fallback_classify(text)

    # ============================================================
    # ë™ê¸° ë©”ì„œë“œ (í…ŒìŠ¤íŠ¸ìš©)
    # ============================================================
    def classify(
        self, text: str, user_context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """í‚¤ì›Œë“œ ë¶„ë¥˜ (ë™ê¸° ë²„ì „)"""

        start_time = datetime.now()

        # ë¡œê·¸ë¡œ í˜¸ì¶œ ì¶”ì 
        logger.info(
            f"ğŸ” [{self.instance_id}] CLASSIFY ì‹œì‘: text_len={len(text)}, has_context={bool(user_context)}"
        )

        # ë¹ˆ í…ìŠ¤íŠ¸ í™•ì¸
        if not text or not text.strip():
            logger.warning(f"[{self.instance_id}] âš ï¸  ë¹ˆ í…ìŠ¤íŠ¸ ì…ë ¥")
            return self._create_empty_response()

        # Chain ë¯¸ì´ˆê¸°í™” í™•ì¸
        if self.chain is None:
            logger.warning(f"[{self.instance_id}] âš ï¸  Chain ë¯¸ì´ˆê¸°í™”, Fallback")
            return self._fallback_classify(text)

        try:
            # í”„ë¡¬í”„íŠ¸ ë³€ìˆ˜ ì¤€ë¹„
            prompt_vars = self._prepare_prompt_variables(text, user_context)
            logger.info(f"[{self.instance_id}] ğŸ” Calling LLM (sync)...")

            # ë™ê¸° í˜¸ì¶œ
            response_text = self.chain.invoke(prompt_vars)

            json_text = self._extract_json_from_response(response_text)
            result = json.loads(json_text)

            # tags ë³´ì¥
            if "tags" not in result or not result["tags"]:
                result["tags"] = ["ê¸°íƒ€"]

            if "confidence" not in result:
                result["confidence"] = 0.5

            result["user_context_matched"] = bool(
                user_context and user_context.get("areas")
            )
            result["user_areas"] = user_context.get("areas", []) if user_context else []

            elapsed = (datetime.now() - start_time).total_seconds()
            result["processing_time"] = f"{elapsed:.2f}s"
            result["instance_id"] = self.instance_id

            logger.info(f"[{self.instance_id}] âœ… ë¶„ë¥˜ ì™„ë£Œ (sync):")
            logger.info(f"[{self.instance_id}]   - Tags: {result.get('tags', [])}")

            return result

        except Exception as e:
            logger.error(f"[{self.instance_id}] âŒ ë¶„ë¥˜ ì˜¤ë¥˜ (sync): {e}")
            return self._fallback_classify(text)

    def _extract_json_from_response(self, response_text: str) -> str:
        """LLM ì‘ë‹µì—ì„œ JSON ì¶”ì¶œ"""
        response_text = response_text.strip()

        # Step 1: ```json ... ``` í˜•ì‹
        if "```json" in response_text:
            match = re.search(r"```json\s*(.*?)\s*```", response_text, re.DOTALL)
            if match:
                return match.group(1).strip()

        # Step 2: ``` ... ``` í˜•ì‹
        if "```" in response_text:
            match = re.search(r"```\s*(.*?)\s*```", response_text, re.DOTALL)
            if match:
                return match.group(1).strip()

        # Step 3: { ... } JSON ê°ì²´ ì°¾ê¸°
        match = re.search(r"\{.*\}", response_text, re.DOTALL)
        if match:
            return match.group(0)

        # Step 4: ì‹¤íŒ¨ - ì „ì²´ ë°˜í™˜
        logger.warning(f"[{self.instance_id}] âš ï¸  JSON í¬ë§· ì°¾ê¸° ì‹¤íŒ¨")
        return response_text

    def _fallback_classify(self, text: str) -> Dict[str, Any]:
        """Fallback ë¶„ë¥˜ (LLM ì‹¤íŒ¨ ì‹œ)

        ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ ëŒ€ì²´
        """

        logger.info(f"[{self.instance_id}] ğŸ”„ Fallback ë¶„ë¥˜ ì‹œì‘...")

        try:
            # í…ìŠ¤íŠ¸ ì •ê·œí™”
            normalized_text = text.lower()

            # ê¸°ë³¸ í‚¤ì›Œë“œ ì‚¬ì „ (ì˜ˆì‹œ)
            keyword_dict = {
                "ê°œë°œ": ["ê°œë°œ", "ì½”ë“œ", "í”„ë¡œê·¸ë˜ë°", "api", "ë²„ê·¸", "ë””ë²„ê¹…"],
                "ë””ìì¸": ["ë””ìì¸", "ui", "ux", "figma", "ìƒ‰ìƒ", "ë ˆì´ì•„ì›ƒ"],
                "íšŒì˜": ["íšŒì˜", "ë¯¸íŒ…", "ë…¼ì˜", "ê²°ì •", "ì•ˆê±´"],
                "ê¸°íš": ["ê¸°íš", "ì „ëµ", "ê³„íš", "ëª©í‘œ", "ë°©í–¥ì„±"],
                "ë§ˆì¼€íŒ…": ["ë§ˆì¼€íŒ…", "ê´‘ê³ ", "í™ë³´", "ìº í˜ì¸", "ê³ ê°"],
                "ë°ì´í„°": ["ë°ì´í„°", "ë¶„ì„", "í†µê³„", "ì°¨íŠ¸", "ì§€í‘œ"],
            }

            # í‚¤ì›Œë“œ ë§¤ì¹­
            matched_dict = {}

            for category, keywords in keyword_dict.items():
                match_count = sum(1 for kw in keywords if kw in normalized_text)
                if match_count > 0:
                    matched_dict[category] = match_count

            # ì ìˆ˜ ê¸°ì¤€ ì •ë ¬ ë° ìƒìœ„ 3ê°œ ì„ íƒ
            if matched_dict:
                sorted_categories = sorted(
                    matched_dict.items(), key=lambda x: x[1], reverse=True
                )
                tags = [
                    cat for cat, _ in sorted_categories[:3]
                ]  # ìˆ˜ì •: dict_keys ìŠ¬ë¼ì´ì‹± ì˜¤ë¥˜ í•´ê²°
                confidence = 0.3  # Fallbackì´ë¯€ë¡œ ë‚®ì€ ì‹ ë¢°ë„
            else:
                tags = ["ê¸°íƒ€"]
                confidence = 0.1

            logger.info(f"[{self.instance_id}] ğŸ”„ Fallback ë¶„ë¥˜: {tags}")

            return {
                "tags": tags,  # í•­ìƒ ì¡´ì¬
                "confidence": confidence,  # ì‹ ë¢°ë„
                "user_context_matched": False,
                "user_areas": [],
                "matched_keywords": matched_dict,
                "instance_id": self.instance_id,
                "processing_time": "0.0s",
                "method": "fallback",
                # "para_hints": {},
                # "is_fallback": True,
            }

        except Exception as e:
            logger.error(f"[{self.instance_id}] âŒ Fallback ë¶„ë¥˜ ì‹¤íŒ¨: {e}")
            return {
                "tags": ["ê¸°íƒ€"],
                "confidence": 0.0,
                "user_context_matched": False,
                "user_areas": [],
                "instance_id": self.instance_id,
                "processing_time": "0.0s",
                "error": str(e),
            }

    def _extract_fallback_tags(
        self, text: str, user_context: Optional[Dict[str, Any]] = None
    ) -> List[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ íƒœê·¸ ê°•ì œ ì¶”ì¶œ (Fallback)"""
        try:
            found_tags = []

            # 1. ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ í™œìš©
            if user_context:
                areas = user_context.get("areas", [])
                interests = user_context.get("interests", [])

                # í…ìŠ¤íŠ¸ì— í¬í•¨ëœ area/interest ì°¾ê¸°
                for item in areas + interests:
                    if item and str(item) in text:
                        found_tags.append(str(item))

            # 2. ê¸°ë³¸ í‚¤ì›Œë“œ ë§¤ì¹­
            keyword_dict = {
                "ê°œë°œ": ["ê°œë°œ", "ì½”ë“œ", "í”„ë¡œê·¸ë˜ë°", "api", "ë²„ê·¸", "ë””ë²„ê¹…"],
                "ë””ìì¸": ["ë””ìì¸", "ui", "ux", "figma", "ìƒ‰ìƒ", "ë ˆì´ì•„ì›ƒ"],
                "íšŒì˜": ["íšŒì˜", "ë¯¸íŒ…", "ë…¼ì˜", "ê²°ì •", "ì•ˆê±´"],
                "ê¸°íš": ["ê¸°íš", "ì „ëµ", "ê³„íš", "ëª©í‘œ", "ë°©í–¥ì„±"],
                "ë§ˆì¼€íŒ…": ["ë§ˆì¼€íŒ…", "ê´‘ê³ ", "í™ë³´", "ìº í˜ì¸", "ê³ ê°"],
                "ë°ì´í„°": ["ë°ì´í„°", "ë¶„ì„", "í†µê³„", "ì°¨íŠ¸", "ì§€í‘œ"],
            }

            normalized_text = text.lower()
            for category, keywords in keyword_dict.items():
                if any(kw in normalized_text for kw in keywords):
                    found_tags.append(category)

            # ì¤‘ë³µ ì œê±°
            found_tags = list(set(found_tags))

            return found_tags if found_tags else ["ê¸°íƒ€"]

        except Exception as e:
            logger.warning(f"[{self.instance_id}] âš ï¸ íƒœê·¸ ê°•ì œ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return ["ê¸°íƒ€"]

    def _create_empty_response(self) -> Dict[str, Any]:
        """ë¹ˆ ì‘ë‹µ"""
        return {
            "tags": ["ê¸°íƒ€"],
            "confidence": 0.0,
            "matched_keywords": {},
            "reasoning": "ëª…í™•í•œ í‚¤ì›Œë“œ ì—†ìŒ",
            "para_hints": {},
            "user_context_matched": False,
            "user_areas": [],
            "instance_id": self.instance_id,
            "processing_time": "0.0s",
            "error": "empty_input",
        }

    def get_statistics(self) -> Dict[str, Any]:
        """ë¶„ë¥˜ê¸° í†µê³„"""
        return {
            "instance_id": self.instance_id,
            "created_at": self.created_at,
            "llm_initialized": self.llm is not None,
            "chain_initialized": self.chain is not None,
            "model": ModelConfig.GPT4O_MINI_MODEL if self.llm else "None",
            "api_configured": bool(ModelConfig.GPT4O_MINI_API_KEY),
        }


# ============================================================
# í…ŒìŠ¤íŠ¸ ë©”ì¸ í•¨ìˆ˜
# ============================================================

if __name__ == "__main__":
    import asyncio

    logging.basicConfig(
        level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
    )

    print("\n" + "=" * 70)
    print("KeywordClassifier í…ŒìŠ¤íŠ¸ (í”„ë¡¬í”„íŠ¸ íŒŒì¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©!)")
    print("=" * 70)

    # ë™ê¸° í…ŒìŠ¤íŠ¸
    classifier1 = KeywordClassifier()

    test_texts = [
        "ì˜¤ëŠ˜ íšŒì˜ê°€ ìˆê³ , ì €ë…ì— ìŠ¤í„°ë”” ëª¨ì„ì´ ìˆìŠµë‹ˆë‹¤.",
        "ì¼ê¸°ë¥¼ ì“°ë©´ì„œ ì˜¤ëŠ˜ í•˜ë£¨ë¥¼ ëŒì•„ë´…ë‹ˆë‹¤.",
        "ì˜¤ëŠ˜ í—¬ìŠ¤ì¥ì— ê°€ì„œ ìš´ë™í–ˆìŠµë‹ˆë‹¤.",
    ]

    user_context = {
        "occupation": "ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´",
        "areas": ["ì½”ë“œ í’ˆì§ˆ ê´€ë¦¬", "ê¸°ìˆ  ì—­ëŸ‰ ê°œë°œ"],
        "interests": ["AI", "ë°±ì—”ë“œ ê°œë°œ"],
    }

    print("\n" + "=" * 70)
    print("ë™ê¸° í…ŒìŠ¤íŠ¸ (ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ í¬í•¨)")
    print("=" * 70)

    for i, text in enumerate(test_texts, 1):
        print(f"\nğŸ“ í…ŒìŠ¤íŠ¸ {i}: {text}")
        result = classifier1.classify(text, user_context=user_context)
        print(f"âœ… íƒœê·¸: {result['tags']}")
        print(f"ğŸ“Š ì‹ ë¢°ë„: {result['confidence']}")
        print(f"ğŸ†” Instance: {result.get('instance_id')}")
        print(f"ğŸ‘¤ User matched: {result.get('user_context_matched')}")

    # ë¹„ë™ê¸° í…ŒìŠ¤íŠ¸
    print("\n" + "=" * 70)
    print("ë¹„ë™ê¸° í…ŒìŠ¤íŠ¸")
    print("=" * 70)

    async def async_test():
        classifier2 = KeywordClassifier()  # ìƒˆ ì¸ìŠ¤í„´ìŠ¤!

        for i, text in enumerate(test_texts, 1):
            print(f"\nğŸ“ ë¹„ë™ê¸° í…ŒìŠ¤íŠ¸ {i}: {text}")
            result = await classifier2.aclassify(text, user_context=user_context)
            print(f"âœ… íƒœê·¸: {result['tags']}")
            print(f"ğŸ“Š ì‹ ë¢°ë„: {result['confidence']}")
            print(f"ğŸ†” Instance: {result.get('instance_id')}")
            print(f"â±ï¸  Time: {result.get('processing_time')}")
            print(f"ğŸ‘¤ User areas: {result.get('user_areas')}")

    asyncio.run(async_test())

##############################################################################


"""test_result_1 â†’ âŒ

    `Syntax Error â†’ ë¡œì§ ì™„ì „ ê¼¬ì„ â†’ json íŒŒì‹± ì‹œë„ ì „ ì—ëŸ¬ â†’ ë¡œì§ ì •ë¦¬ í•„ìš”`

    ======================================================================
    KeywordClassifier í…ŒìŠ¤íŠ¸
    ======================================================================
    2025-11-02 12:09:07,834 - __main__ - INFO - âœ… KeywordClassifier LLM ì´ˆê¸°í™” ì„±ê³µ (gpt-4o-mini)
    2025-11-02 12:09:07,834 - __main__ - INFO - âœ… í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë¡œë“œ ì„±ê³µ

    ğŸ“Š ë¶„ë¥˜ê¸° ìƒíƒœ:
        llm_initialized: True
        prompt_loaded: True
        model: openai/gpt-4o-mini
        api_configured: True
        project_root: ***/flownote-mvp/
        classifier_dir: ***/flownote-mvp/backend/classifier/

    ======================================================================
    ë¶„ë¥˜ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    ======================================================================

    ğŸ“ í…ŒìŠ¤íŠ¸ 1:
    ì…ë ¥: ì˜¤ëŠ˜ íšŒì˜ê°€ ìˆê³ , ì €ë…ì— ìŠ¤í„°ë”” ëª¨ì„ì´ ìˆìŠµë‹ˆë‹¤. í”„ë¡œì íŠ¸ ì§„í–‰ ìƒí™©ì„ ê³µìœ í•˜ê³  ìƒˆë¡œìš´ ...
    2025-11-02 12:09:07,834 - __main__ - ERROR - âŒ ì˜¤ë¥˜: '\n  "tags"'
    âœ… íƒœê·¸: ['ê¸°íƒ€']
    ğŸ“Š ì‹ ë¢°ë„: 0.0
    ğŸ”‘ í‚¤ì›Œë“œ: {}

    ğŸ“ í…ŒìŠ¤íŠ¸ 2:
    ì…ë ¥: ì¼ê¸°ë¥¼ ì“°ë©´ì„œ ì˜¤ëŠ˜ í•˜ë£¨ë¥¼ ëŒì•„ë´…ë‹ˆë‹¤. ê°ì •ì„ ì •ë¦¬í•˜ê³  ë‚´ì¼ í•  ì¼ì„ ìƒê°í•´ë´¤ìŠµë‹ˆë‹¤....
    2025-11-02 12:09:07,834 - __main__ - ERROR - âŒ ì˜¤ë¥˜: '\n  "tags"'
    âœ… íƒœê·¸: ['ê¸°íƒ€']
    ğŸ“Š ì‹ ë¢°ë„: 0.0
    ğŸ”‘ í‚¤ì›Œë“œ: {}

    ğŸ“ í…ŒìŠ¤íŠ¸ 3:
    ì…ë ¥: ì˜¤ëŠ˜ í—¬ìŠ¤ì¥ì— ê°€ì„œ ìš´ë™í–ˆìŠµë‹ˆë‹¤. PT ì„¸ì…˜ë„ ë°›ê³  ì‹ë‹¨ ìƒë‹´ë„ ë°›ì•˜ì–´ìš”....
    2025-11-02 12:09:07,834 - __main__ - ERROR - âŒ ì˜¤ë¥˜: '\n  "tags"'
    âœ… íƒœê·¸: ['ê¸°íƒ€']
    ğŸ“Š ì‹ ë¢°ë„: 0.0
    ğŸ”‘ í‚¤ì›Œë“œ: {}

"""


"""test_result_2 â†’ ğŸ”¼

    `ì›ë³¸ LLMì´ ì‘ë‹µ ì¶œë ¥í•˜ê³  ìˆì§€ ì•ŠìŒ â†’ ë””ë²„ê¹… ê°•í™” ì½”ë“œ ì¶”ê°€ í•„ìš”`

    ======================================================================
    KeywordClassifier í…ŒìŠ¤íŠ¸
    ======================================================================
    2025-11-02 12:40:12,177 - __main__ - INFO - âœ… KeywordClassifier LLM ì´ˆê¸°í™” ì„±ê³µ (gpt-4o-mini)
    2025-11-02 12:40:12,178 - __main__ - INFO - âœ… í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë¡œë“œ ì„±ê³µ

    ğŸ“Š ë¶„ë¥˜ê¸° ìƒíƒœ:
        llm_initialized: True
        prompt_loaded: True
        model: openai/gpt-4o-mini
        api_configured: True
        project_root: ***/flownote-mvp
        classifier_dir: ***/flownote-mvp/backend/classifier/

    ======================================================================
    ë¶„ë¥˜ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    ======================================================================

    ğŸ“ í…ŒìŠ¤íŠ¸ 1:
    ì…ë ¥: ì˜¤ëŠ˜ íšŒì˜ê°€ ìˆê³ , ì €ë…ì— ìŠ¤í„°ë”” ëª¨ì„ì´ ìˆìŠµë‹ˆë‹¤. í”„ë¡œì íŠ¸ ì§„í–‰ ìƒí™©ì„ ê³µìœ í•˜ê³  ìƒˆë¡œìš´ ...
    2025-11-02 12:40:12,178 - __main__ - ERROR - âŒ ì˜¤ë¥˜: KeyError: '\n  "tags"'
    2025-11-02 12:40:12,178 - __main__ - INFO - ğŸ”„ Fallback ë¶„ë¥˜: ['ì—…ë¬´', 'í•™ìŠµ'], confidence: 0.95
    âœ… íƒœê·¸: ['ì—…ë¬´', 'í•™ìŠµ']
    ğŸ“Š ì‹ ë¢°ë„: 0.95
    ğŸ”‘ í‚¤ì›Œë“œ: {'ì—…ë¬´': ['íšŒì˜', 'í”„ë¡œì íŠ¸'], 'í•™ìŠµ': ['í•™ìŠµ', 'ìŠ¤í„°ë””']}

    ğŸ“ í…ŒìŠ¤íŠ¸ 2:
    ì…ë ¥: ì¼ê¸°ë¥¼ ì“°ë©´ì„œ ì˜¤ëŠ˜ í•˜ë£¨ë¥¼ ëŒì•„ë´…ë‹ˆë‹¤. ê°ì •ì„ ì •ë¦¬í•˜ê³  ë‚´ì¼ í•  ì¼ì„ ìƒê°í•´ë´¤ìŠµë‹ˆë‹¤....
    2025-11-02 12:40:12,178 - __main__ - ERROR - âŒ ì˜¤ë¥˜: KeyError: '\n  "tags"'
    2025-11-02 12:40:12,178 - __main__ - INFO - ğŸ”„ Fallback ë¶„ë¥˜: ['ê°œì¸'], confidence: 0.85
    âœ… íƒœê·¸: ['ê°œì¸']
    ğŸ“Š ì‹ ë¢°ë„: 0.85
    ğŸ”‘ í‚¤ì›Œë“œ: {'ê°œì¸': ['ì¼ê¸°', 'ìƒê°', 'ê°ì •']}

    ğŸ“ í…ŒìŠ¤íŠ¸ 3:
    ì…ë ¥: ì˜¤ëŠ˜ í—¬ìŠ¤ì¥ì— ê°€ì„œ ìš´ë™í–ˆìŠµë‹ˆë‹¤. PT ì„¸ì…˜ë„ ë°›ê³  ì‹ë‹¨ ìƒë‹´ë„ ë°›ì•˜ì–´ìš”....
    2025-11-02 12:40:12,178 - __main__ - ERROR - âŒ ì˜¤ë¥˜: KeyError: '\n  "tags"'
    2025-11-02 12:40:12,178 - __main__ - INFO - ğŸ”„ Fallback ë¶„ë¥˜: ['ê±´ê°•'], confidence: 0.85
    âœ… íƒœê·¸: ['ê±´ê°•']
    ğŸ“Š ì‹ ë¢°ë„: 0.85
    ğŸ”‘ í‚¤ì›Œë“œ: {'ê±´ê°•': ['ìš´ë™', 'í—¬ìŠ¤', 'ì‹ë‹¨']}

"""


"""test_result_3 â†’ ğŸ”¼

    `python backend/classifier/keyword_classifier.py - metadata_prompts íŒŒì¼ ì¬ê²€í†  ë° ìˆ˜ì • í•„ìš”`

    ======================================================================
    KeywordClassifier í…ŒìŠ¤íŠ¸
    ======================================================================
    2025-11-02 12:49:20,298 - __main__ - INFO - âœ… KeywordClassifier LLM ì´ˆê¸°í™” ì„±ê³µ (gpt-4o-mini)
    2025-11-02 12:49:20,299 - __main__ - INFO - âœ… í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë¡œë“œ ì„±ê³µ

    ğŸ“Š ë¶„ë¥˜ê¸° ìƒíƒœ:
        llm_initialized: True
        prompt_loaded: True
        model: openai/gpt-4o-mini
        api_configured: True
        project_root: /Users/jay/ICT-projects/flownote-mvp
        classifier_dir: /Users/jay/ICT-projects/flownote-mvp/backend/classifier

    ======================================================================
    ë¶„ë¥˜ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    ======================================================================

    ğŸ“ í…ŒìŠ¤íŠ¸ 1:
    ì…ë ¥: ì˜¤ëŠ˜ íšŒì˜ê°€ ìˆê³ , ì €ë…ì— ìŠ¤í„°ë”” ëª¨ì„ì´ ìˆìŠµë‹ˆë‹¤. í”„ë¡œì íŠ¸ ì§„í–‰ ìƒí™©ì„ ê³µìœ í•˜ê³  ìƒˆë¡œìš´ ...
    2025-11-02 12:49:20,299 - __main__ - ERROR - âŒ ì˜¤ë¥˜: KeyError: '\n  "tags"'
    2025-11-02 12:49:20,299 - __main__ - INFO - ğŸ”„ Fallback ë¶„ë¥˜: ['ì—…ë¬´', 'í•™ìŠµ'], confidence: 0.95
    âœ… íƒœê·¸: ['ì—…ë¬´', 'í•™ìŠµ']
    ğŸ“Š ì‹ ë¢°ë„: 0.95
    ğŸ”‘ í‚¤ì›Œë“œ: {'ì—…ë¬´': ['íšŒì˜', 'í”„ë¡œì íŠ¸'], 'í•™ìŠµ': ['í•™ìŠµ', 'ìŠ¤í„°ë””']}

    ğŸ“ í…ŒìŠ¤íŠ¸ 2:
    ì…ë ¥: ì¼ê¸°ë¥¼ ì“°ë©´ì„œ ì˜¤ëŠ˜ í•˜ë£¨ë¥¼ ëŒì•„ë´…ë‹ˆë‹¤. ê°ì •ì„ ì •ë¦¬í•˜ê³  ë‚´ì¼ í•  ì¼ì„ ìƒê°í•´ë´¤ìŠµë‹ˆë‹¤....
    2025-11-02 12:49:20,299 - __main__ - ERROR - âŒ ì˜¤ë¥˜: KeyError: '\n  "tags"'
    2025-11-02 12:49:20,299 - __main__ - INFO - ğŸ”„ Fallback ë¶„ë¥˜: ['ê°œì¸'], confidence: 0.85
    âœ… íƒœê·¸: ['ê°œì¸']
    ğŸ“Š ì‹ ë¢°ë„: 0.85
    ğŸ”‘ í‚¤ì›Œë“œ: {'ê°œì¸': ['ì¼ê¸°', 'ìƒê°', 'ê°ì •']}

    ğŸ“ í…ŒìŠ¤íŠ¸ 3:
    ì…ë ¥: ì˜¤ëŠ˜ í—¬ìŠ¤ì¥ì— ê°€ì„œ ìš´ë™í–ˆìŠµë‹ˆë‹¤. PT ì„¸ì…˜ë„ ë°›ê³  ì‹ë‹¨ ìƒë‹´ë„ ë°›ì•˜ì–´ìš”....
    2025-11-02 12:49:20,299 - __main__ - ERROR - âŒ ì˜¤ë¥˜: KeyError: '\n  "tags"'
    2025-11-02 12:49:20,299 - __main__ - INFO - ğŸ”„ Fallback ë¶„ë¥˜: ['ê±´ê°•'], confidence: 0.85
    âœ… íƒœê·¸: ['ê±´ê°•']
    ğŸ“Š ì‹ ë¢°ë„: 0.85
    ğŸ”‘ í‚¤ì›Œë“œ: {'ê±´ê°•': ['ìš´ë™', 'í—¬ìŠ¤', 'ì‹ë‹¨']}


"""


"""test_result_4 â†’ ğŸ”¼

    `ë¡œì§ ìˆ˜ì • â†’ ì´ìŠ¤ì¼€ì´í”„ ë¬¸ì œ ì—¬ì „íˆ ë°œìƒ`

    ======================================================================
    KeywordClassifier í…ŒìŠ¤íŠ¸
    ======================================================================
    2025-11-02 13:49:01,490 - INFO - âœ… KeywordClassifier LLM ì´ˆê¸°í™” ì„±ê³µ
    2025-11-02 13:49:01,491 - INFO - âœ… í”„ë¡¬í”„íŠ¸ ë¡œë“œ ë° Chain ìƒì„± ì„±ê³µ

    ğŸ“Š ë¶„ë¥˜ê¸° ìƒíƒœ:
        llm_initialized: True
        chain_initialized: True
        model: openai/gpt-4o-mini
        api_configured: True

    ======================================================================
    ë¶„ë¥˜ í…ŒìŠ¤íŠ¸
    ======================================================================

    ğŸ“ í…ŒìŠ¤íŠ¸ 1: ì˜¤ëŠ˜ íšŒì˜ê°€ ìˆê³ , ì €ë…ì— ìŠ¤í„°ë”” ëª¨ì„ì´ ìˆìŠµë‹ˆë‹¤.
    2025-11-02 13:49:01,491 - INFO - ğŸš€ LLM í˜¸ì¶œ ì‹œì‘: ì˜¤ëŠ˜ íšŒì˜ê°€ ìˆê³ , ì €ë…ì— ìŠ¤í„°ë”” ëª¨ì„ì´ ìˆìŠµë‹ˆë‹¤....
    2025-11-02 13:49:01,492 - ERROR - âŒ ë¶„ë¥˜ ì˜¤ë¥˜: KeyError: 'Input to ChatPromptTemplate is missing variables {\'\', \'\\n        "keyword_count"\', \'\\n  "tags"\'}.  Expected: [\'\', \'\\n        "keyword_count"\', \'\\n  "tags"\', \'text\'] Received: [\'text\']\nNote: if you intended {} to be part of the string and not a variable, please escape it with double curly braces like: \'{{}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
    2025-11-02 13:49:01,492 - ERROR - ìƒì„¸ ì—ëŸ¬: 'Input to ChatPromptTemplate is missing variables {\'\', \'\\n        "keyword_count"\', \'\\n  "tags"\'}.  Expected: [\'\', \'\\n        "keyword_count"\', \'\\n  "tags"\', \'text\'] Received: [\'text\']\nNote: if you intended {} to be part of the string and not a variable, please escape it with double curly braces like: \'{{}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
    2025-11-02 13:49:01,492 - INFO - ğŸ”„ Fallback ë¶„ë¥˜: ['ì—…ë¬´', 'í•™ìŠµ']
    âœ… íƒœê·¸: ['ì—…ë¬´', 'í•™ìŠµ']
    ğŸ“Š ì‹ ë¢°ë„: 0.65
    ğŸ”‘ í‚¤ì›Œë“œ: {'ì—…ë¬´': ['íšŒì˜'], 'í•™ìŠµ': ['ìŠ¤í„°ë””']}

    ğŸ“ í…ŒìŠ¤íŠ¸ 2: ì¼ê¸°ë¥¼ ì“°ë©´ì„œ ì˜¤ëŠ˜ í•˜ë£¨ë¥¼ ëŒì•„ë´…ë‹ˆë‹¤.
    2025-11-02 13:49:01,492 - INFO - ğŸš€ LLM í˜¸ì¶œ ì‹œì‘: ì¼ê¸°ë¥¼ ì“°ë©´ì„œ ì˜¤ëŠ˜ í•˜ë£¨ë¥¼ ëŒì•„ë´…ë‹ˆë‹¤....
    2025-11-02 13:49:01,492 - ERROR - âŒ ë¶„ë¥˜ ì˜¤ë¥˜: KeyError: 'Input to ChatPromptTemplate is missing variables {\'\', \'\\n        "keyword_count"\', \'\\n  "tags"\'}.  Expected: [\'\', \'\\n        "keyword_count"\', \'\\n  "tags"\', \'text\'] Received: [\'text\']\nNote: if you intended {} to be part of the string and not a variable, please escape it with double curly braces like: \'{{}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
    2025-11-02 13:49:01,492 - ERROR - ìƒì„¸ ì—ëŸ¬: 'Input to ChatPromptTemplate is missing variables {\'\', \'\\n        "keyword_count"\', \'\\n  "tags"\'}.  Expected: [\'\', \'\\n        "keyword_count"\', \'\\n  "tags"\', \'text\'] Received: [\'text\']\nNote: if you intended {} to be part of the string and not a variable, please escape it with double curly braces like: \'{{}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
    2025-11-02 13:49:01,492 - INFO - ğŸ”„ Fallback ë¶„ë¥˜: ['ê°œì¸']
    âœ… íƒœê·¸: ['ê°œì¸']
    ğŸ“Š ì‹ ë¢°ë„: 0.3
    ğŸ”‘ í‚¤ì›Œë“œ: {'ê°œì¸': ['ì¼ê¸°']}

    ğŸ“ í…ŒìŠ¤íŠ¸ 3: ì˜¤ëŠ˜ í—¬ìŠ¤ì¥ì— ê°€ì„œ ìš´ë™í–ˆìŠµë‹ˆë‹¤.
    2025-11-02 13:49:01,492 - INFO - ğŸš€ LLM í˜¸ì¶œ ì‹œì‘: ì˜¤ëŠ˜ í—¬ìŠ¤ì¥ì— ê°€ì„œ ìš´ë™í–ˆìŠµë‹ˆë‹¤....
    2025-11-02 13:49:01,493 - ERROR - âŒ ë¶„ë¥˜ ì˜¤ë¥˜: KeyError: 'Input to ChatPromptTemplate is missing variables {\'\', \'\\n        "keyword_count"\', \'\\n  "tags"\'}.  Expected: [\'\', \'\\n        "keyword_count"\', \'\\n  "tags"\', \'text\'] Received: [\'text\']\nNote: if you intended {} to be part of the string and not a variable, please escape it with double curly braces like: \'{{}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
    2025-11-02 13:49:01,493 - ERROR - ìƒì„¸ ì—ëŸ¬: 'Input to ChatPromptTemplate is missing variables {\'\', \'\\n        "keyword_count"\', \'\\n  "tags"\'}.  Expected: [\'\', \'\\n        "keyword_count"\', \'\\n  "tags"\', \'text\'] Received: [\'text\']\nNote: if you intended {} to be part of the string and not a variable, please escape it with double curly braces like: \'{{}}\'.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '
    2025-11-02 13:49:01,493 - INFO - ğŸ”„ Fallback ë¶„ë¥˜: ['ê±´ê°•']
    âœ… íƒœê·¸: ['ê±´ê°•']
    ğŸ“Š ì‹ ë¢°ë„: 0.65
    ğŸ”‘ í‚¤ì›Œë“œ: {'ê±´ê°•': ['ìš´ë™', 'í—¬ìŠ¤']}

"""


"""test_result_5 â†’ â­•ï¸

    ======================================================================
    KeywordClassifier í…ŒìŠ¤íŠ¸
    ======================================================================
    2025-11-02 13:52:49,371 - INFO - âœ… KeywordClassifier LLM ì´ˆê¸°í™” ì„±ê³µ
    2025-11-02 13:52:49,372 - INFO - âœ… í”„ë¡¬í”„íŠ¸ ë¡œë“œ ë° Chain ìƒì„± ì„±ê³µ

    ğŸ“Š ë¶„ë¥˜ê¸° ìƒíƒœ:
        llm_initialized: True
        chain_initialized: True
        model: openai/gpt-4o-mini
        api_configured: True

    ======================================================================
    ë¶„ë¥˜ í…ŒìŠ¤íŠ¸
    ======================================================================

    ğŸ“ í…ŒìŠ¤íŠ¸ 1: ì˜¤ëŠ˜ íšŒì˜ê°€ ìˆê³ , ì €ë…ì— ìŠ¤í„°ë”” ëª¨ì„ì´ ìˆìŠµë‹ˆë‹¤.
    2025-11-02 13:52:49,372 - INFO - ğŸš€ LLM í˜¸ì¶œ ì‹œì‘: ì˜¤ëŠ˜ íšŒì˜ê°€ ìˆê³ , ì €ë…ì— ìŠ¤í„°ë”” ëª¨ì„ì´ ìˆìŠµë‹ˆë‹¤....
    2025-11-02 13:52:51,916 - INFO - HTTP Request: POST https://*** "HTTP/1.1 200 OK"

    ================================================================================
    ğŸ” ì›ë³¸ LLM ì‘ë‹µ:
    ================================================================================
    {
        "tags": ["ì—…ë¬´", "í•™ìŠµ"],
        "confidence": 0.85,
        "matched_keywords": {
            "ì—…ë¬´": ["íšŒì˜"],
            "í•™ìŠµ": ["ìŠ¤í„°ë””"]
            },
        "reasoning": "ì—…ë¬´ ê´€ë ¨ íšŒì˜ì™€ í•™ìŠµ ê´€ë ¨ ìŠ¤í„°ë”” í‚¤ì›Œë“œê°€ ì¶œí˜„í•˜ì—¬ ë‘ ì¹´í…Œê³ ë¦¬ì— í•´ë‹¹ë¨",
        "para_hints": {
            "ì—…ë¬´": ["Projects"],
            "í•™ìŠµ": ["Areas"]
        }
    }
    ================================================================================

    ğŸ“„ ì¶”ì¶œëœ JSON:
    {
        "tags": ["ì—…ë¬´", "í•™ìŠµ"],
        "confidence": 0.85,
        "matched_keywords": {
            "ì—…ë¬´": ["íšŒì˜"],
            "í•™ìŠµ": ["ìŠ¤í„°ë””"]
            },
        "reasoning": "ì—…ë¬´ ê´€ë ¨ íšŒì˜ì™€ í•™ìŠµ ê´€ë ¨ ìŠ¤í„°ë”” í‚¤ì›Œë“œê°€ ì¶œí˜„í•˜ì—¬ ë‘ ì¹´í…Œê³ ë¦¬ì— í•´ë‹¹ë¨",
        "para_hints": {
            "ì—…ë¬´": ["Projects"],
            "í•™ìŠµ": ["Areas"]
        }
    }

    2025-11-02 13:52:51,925 - INFO - âœ… LLM ë¶„ë¥˜ ì„±ê³µ: ['ì—…ë¬´', 'í•™ìŠµ']
    âœ… íƒœê·¸: ['ì—…ë¬´', 'í•™ìŠµ']
    ğŸ“Š ì‹ ë¢°ë„: 0.85
    ğŸ”‘ í‚¤ì›Œë“œ: {'ì—…ë¬´': ['íšŒì˜'], 'í•™ìŠµ': ['ìŠ¤í„°ë””']}

    ğŸ“ í…ŒìŠ¤íŠ¸ 2: ì¼ê¸°ë¥¼ ì“°ë©´ì„œ ì˜¤ëŠ˜ í•˜ë£¨ë¥¼ ëŒì•„ë´…ë‹ˆë‹¤.
    2025-11-02 13:52:51,926 - INFO - ğŸš€ LLM í˜¸ì¶œ ì‹œì‘: ì¼ê¸°ë¥¼ ì“°ë©´ì„œ ì˜¤ëŠ˜ í•˜ë£¨ë¥¼ ëŒì•„ë´…ë‹ˆë‹¤....
    2025-11-02 13:52:51,916 - INFO - HTTP Request: POST https://*** "HTTP/1.1 200 OK"

    ================================================================================
    ğŸ” ì›ë³¸ LLM ì‘ë‹µ:
    ================================================================================
    {
        "tags": ["ê°œì¸"],
        "confidence": 0.85,
        "matched_keywords": {
            "ê°œì¸": ["ì¼ê¸°", "íšŒê³ "]
        },
        "reasoning": "ê°œì¸ì  ê¸°ë¡ê³¼ í•˜ë£¨ë¥¼ ëŒì•„ë³´ëŠ” ê°ì • ì •ë¦¬ì— í•´ë‹¹í•˜ëŠ” í‚¤ì›Œë“œê°€ ëª…í™•í•¨",
        "para_hints": {
            "ê°œì¸": ["Resources"]
        }
    }
    ================================================================================

    ğŸ“„ ì¶”ì¶œëœ JSON:
    {
        "tags": ["ê°œì¸"],
        "confidence": 0.85,
        "matched_keywords": {
            "ê°œì¸": ["ì¼ê¸°", "íšŒê³ "]
        },
        "reasoning": "ê°œì¸ì  ê¸°ë¡ê³¼ í•˜ë£¨ë¥¼ ëŒì•„ë³´ëŠ” ê°ì • ì •ë¦¬ì— í•´ë‹¹í•˜ëŠ” í‚¤ì›Œë“œê°€ ëª…í™•í•¨",
        "para_hints": {
            "ê°œì¸": ["Resources"]
        }
    }

    2025-11-02 13:52:54,244 - INFO - âœ… LLM ë¶„ë¥˜ ì„±ê³µ: ['ê°œì¸']
    âœ… íƒœê·¸: ['ê°œì¸']
    ğŸ“Š ì‹ ë¢°ë„: 0.85
    ğŸ”‘ í‚¤ì›Œë“œ: {'ê°œì¸': ['ì¼ê¸°', 'íšŒê³ ']}

    ğŸ“ í…ŒìŠ¤íŠ¸ 3: ì˜¤ëŠ˜ í—¬ìŠ¤ì¥ì— ê°€ì„œ ìš´ë™í–ˆìŠµë‹ˆë‹¤.
    2025-11-02 13:52:54,244 - INFO - ğŸš€ LLM í˜¸ì¶œ ì‹œì‘: ì˜¤ëŠ˜ í—¬ìŠ¤ì¥ì— ê°€ì„œ ìš´ë™í–ˆìŠµë‹ˆë‹¤....
    2025-11-02 13:52:51,916 - INFO - HTTP Request: POST https://*** "HTTP/1.1 200 OK"

    ================================================================================
    ğŸ” ì›ë³¸ LLM ì‘ë‹µ:
    ================================================================================
    {
        "tags": ["ê±´ê°•"],
        "confidence": 0.85,
        "matched_keywords": {
            "ê±´ê°•": ["í—¬ìŠ¤ì¥", "ìš´ë™"]
            },
        "reasoning": "ìš´ë™ ê´€ë ¨ í‚¤ì›Œë“œê°€ ëª…í™•íˆ ê°ì§€ë˜ì–´ ê±´ê°• ì¹´í…Œê³ ë¦¬ì— í•´ë‹¹ë¨",
        "para_hints": {
            "ê±´ê°•": ["Areas"]
        }
    }
    ================================================================================

    ğŸ“„ ì¶”ì¶œëœ JSON:
    {
        "tags": ["ê±´ê°•"],
        "confidence": 0.85,
        "matched_keywords": {
            "ê±´ê°•": ["í—¬ìŠ¤ì¥", "ìš´ë™"]
            },
        "reasoning": "ìš´ë™ ê´€ë ¨ í‚¤ì›Œë“œê°€ ëª…í™•íˆ ê°ì§€ë˜ì–´ ê±´ê°• ì¹´í…Œê³ ë¦¬ì— í•´ë‹¹ë¨",
        "para_hints": {
            "ê±´ê°•": ["Areas"]
        }
    }

    2025-11-02 13:52:56,918 - INFO - âœ… LLM ë¶„ë¥˜ ì„±ê³µ: ['ê±´ê°•']
    âœ… íƒœê·¸: ['ê±´ê°•']
    ğŸ“Š ì‹ ë¢°ë„: 0.85
    ğŸ”‘ í‚¤ì›Œë“œ: {'ê±´ê°•': ['í—¬ìŠ¤ì¥', 'ìš´ë™']}

"""


"""test_result_6 â†’ â­•ï¸ 

    python -m backend.classifier.keyword_classifier

    ======================================================================
    KeywordClassifier í…ŒìŠ¤íŠ¸ (í”„ë¡¬í”„íŠ¸ íŒŒì¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©!)
    ======================================================================
    2025-11-09 23:30:54,219 - INFO - âœ… KeywordClassifier LLM ì´ˆê¸°í™” ì„±ê³µ
    2025-11-09 23:30:54,221 - INFO - [3587ef52] âœ… Chain ìƒì„± ì„±ê³µ (í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë¡œë“œ ì™„ë£Œ)
    2025-11-09 23:30:54,221 - INFO - âœ… KeywordClassifier initialized (ID: 3587ef52, Time: 23:30:54)

    ======================================================================
    ë™ê¸° í…ŒìŠ¤íŠ¸ (ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ í¬í•¨)
    ======================================================================

    ğŸ“ í…ŒìŠ¤íŠ¸ 1: ì˜¤ëŠ˜ íšŒì˜ê°€ ìˆê³ , ì €ë…ì— ìŠ¤í„°ë”” ëª¨ì„ì´ ìˆìŠµë‹ˆë‹¤.
    2025-11-09 23:30:54,221 - INFO - ğŸ” [3587ef52] CLASSIFY ì‹œì‘: text_len=28, has_context=True
    2025-11-09 23:30:54,221 - INFO - [3587ef52] ğŸ” Calling LLM (sync)...
    2025-11-09 23:30:58,985 - INFO - HTTP Request: POST https://**** "HTTP/1.1 200 OK"
    2025-11-09 23:30:59,003 - INFO - [3587ef52] âœ… ë¶„ë¥˜ ì™„ë£Œ (sync):
    2025-11-09 23:30:59,003 - INFO - [3587ef52]   - Tags: ['ì½”ë“œ', 'í’ˆì§ˆ', 'ê°œì„ ', 'í…ŒìŠ¤íŠ¸']
    âœ… íƒœê·¸: ['ì½”ë“œ', 'í’ˆì§ˆ', 'ê°œì„ ', 'í…ŒìŠ¤íŠ¸']
    ğŸ“Š ì‹ ë¢°ë„: 0.85
    ğŸ†” Instance: 3587ef52
    ğŸ‘¤ User matched: True

    ğŸ“ í…ŒìŠ¤íŠ¸ 2: ì¼ê¸°ë¥¼ ì“°ë©´ì„œ ì˜¤ëŠ˜ í•˜ë£¨ë¥¼ ëŒì•„ë´…ë‹ˆë‹¤.
    2025-11-09 23:30:59,003 - INFO - ğŸ” [3587ef52] CLASSIFY ì‹œì‘: text_len=21, has_context=True
    2025-11-09 23:30:59,004 - INFO - [3587ef52] ğŸ” Calling LLM (sync)...
    2025-11-09 23:31:03,820 - INFO - HTTP Request: POST https://**** "HTTP/1.1 200 OK"
    2025-11-09 23:31:03,823 - INFO - [3587ef52] âœ… ë¶„ë¥˜ ì™„ë£Œ (sync):
    2025-11-09 23:31:03,823 - INFO - [3587ef52]   - Tags: ['ì½”ë“œ', 'í’ˆì§ˆ', 'ê´€ë¦¬', 'í…ŒìŠ¤íŠ¸', 'ë¦¬íŒ©í† ë§']
    âœ… íƒœê·¸: ['ì½”ë“œ', 'í’ˆì§ˆ', 'ê´€ë¦¬', 'í…ŒìŠ¤íŠ¸', 'ë¦¬íŒ©í† ë§']
    ğŸ“Š ì‹ ë¢°ë„: 0.9
    ğŸ†” Instance: 3587ef52
    ğŸ‘¤ User matched: True

    ğŸ“ í…ŒìŠ¤íŠ¸ 3: ì˜¤ëŠ˜ í—¬ìŠ¤ì¥ì— ê°€ì„œ ìš´ë™í–ˆìŠµë‹ˆë‹¤.
    2025-11-09 23:31:03,823 - INFO - ğŸ” [3587ef52] CLASSIFY ì‹œì‘: text_len=18, has_context=True
    2025-11-09 23:31:03,823 - INFO - [3587ef52] ğŸ” Calling LLM (sync)...
    2025-11-09 23:31:09,864 - INFO - HTTP Request: POST https://**** "HTTP/1.1 200 OK"
    2025-11-09 23:31:09,867 - INFO - [3587ef52] âœ… ë¶„ë¥˜ ì™„ë£Œ (sync):
    2025-11-09 23:31:09,867 - INFO - [3587ef52]   - Tags: ['ì½”ë“œ', 'í’ˆì§ˆ', 'ê´€ë¦¬', 'í…ŒìŠ¤íŠ¸', 'ë¦¬íŒ©í† ë§']
    âœ… íƒœê·¸: ['ì½”ë“œ', 'í’ˆì§ˆ', 'ê´€ë¦¬', 'í…ŒìŠ¤íŠ¸', 'ë¦¬íŒ©í† ë§']
    ğŸ“Š ì‹ ë¢°ë„: 0.85
    ğŸ†” Instance: 3587ef52
    ğŸ‘¤ User matched: True

    ======================================================================
    ë¹„ë™ê¸° í…ŒìŠ¤íŠ¸
    ======================================================================
    2025-11-09 23:31:09,868 - INFO - âœ… KeywordClassifier LLM ì´ˆê¸°í™” ì„±ê³µ
    2025-11-09 23:31:09,871 - INFO - [fdc6dd02] âœ… Chain ìƒì„± ì„±ê³µ (í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë¡œë“œ ì™„ë£Œ)
    2025-11-09 23:31:09,871 - INFO - âœ… KeywordClassifier initialized (ID: fdc6dd02, Time: 23:31:09)

    ğŸ“ ë¹„ë™ê¸° í…ŒìŠ¤íŠ¸ 1: ì˜¤ëŠ˜ íšŒì˜ê°€ ìˆê³ , ì €ë…ì— ìŠ¤í„°ë”” ëª¨ì„ì´ ìˆìŠµë‹ˆë‹¤.
    2025-11-09 23:31:09,871 - INFO - [fdc6dd02] ğŸ” Calling LLM (async)...
    2025-11-09 23:31:09,871 - INFO - [fdc6dd02]   - Text length: 28
    2025-11-09 23:31:09,871 - INFO - [fdc6dd02]   - Occupation: ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´
    2025-11-09 23:31:09,872 - INFO - [fdc6dd02]   - Areas: ì½”ë“œ í’ˆì§ˆ ê´€ë¦¬, ê¸°ìˆ  ì—­ëŸ‰ ê°œë°œ
    2025-11-09 23:31:13,576 - INFO - HTTP Request: POST https://**** "HTTP/1.1 200 OK"
    2025-11-09 23:31:13,579 - INFO - [fdc6dd02] âœ… ë¶„ë¥˜ ì™„ë£Œ (async):
    2025-11-09 23:31:13,579 - INFO - [fdc6dd02]   - Tags: ['ì›¹ì•±', 'ê°œë°œ', 'íŒ€', 'í™˜ê²½ êµ¬ì¶•', '12/31']
    2025-11-09 23:31:13,579 - INFO - [fdc6dd02]   - Confidence: 0.95
    2025-11-09 23:31:13,579 - INFO - [fdc6dd02]   - Time: 3.71s
    âœ… íƒœê·¸: ['ì›¹ì•±', 'ê°œë°œ', 'íŒ€', 'í™˜ê²½ êµ¬ì¶•', '12/31']
    ğŸ“Š ì‹ ë¢°ë„: 0.95
    ğŸ†” Instance: fdc6dd02
    â±ï¸  Time: 3.71s
    ğŸ‘¤ User areas: ['ì½”ë“œ í’ˆì§ˆ ê´€ë¦¬', 'ê¸°ìˆ  ì—­ëŸ‰ ê°œë°œ']

    ğŸ“ ë¹„ë™ê¸° í…ŒìŠ¤íŠ¸ 2: ì¼ê¸°ë¥¼ ì“°ë©´ì„œ ì˜¤ëŠ˜ í•˜ë£¨ë¥¼ ëŒì•„ë´…ë‹ˆë‹¤.
    2025-11-09 23:31:13,579 - INFO - [fdc6dd02] ğŸ” Calling LLM (async)...
    2025-11-09 23:31:13,579 - INFO - [fdc6dd02]   - Text length: 21
    2025-11-09 23:31:13,579 - INFO - [fdc6dd02]   - Occupation: ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´
    2025-11-09 23:31:13,579 - INFO - [fdc6dd02]   - Areas: ì½”ë“œ í’ˆì§ˆ ê´€ë¦¬, ê¸°ìˆ  ì—­ëŸ‰ ê°œë°œ
    2025-11-09 23:31:17,959 - INFO - HTTP Request: POST https://**** "HTTP/1.1 200 OK"
    2025-11-09 23:31:17,964 - INFO - [fdc6dd02] âœ… ë¶„ë¥˜ ì™„ë£Œ (async):
    2025-11-09 23:31:17,964 - INFO - [fdc6dd02]   - Tags: ['ì½”ë“œ', 'í’ˆì§ˆ', 'ê´€ë¦¬', 'í…ŒìŠ¤íŠ¸', 'ë¦¬íŒ©í† ë§']
    2025-11-09 23:31:17,964 - INFO - [fdc6dd02]   - Confidence: 0.88
    2025-11-09 23:31:17,964 - INFO - [fdc6dd02]   - Time: 4.38s
    âœ… íƒœê·¸: ['ì½”ë“œ', 'í’ˆì§ˆ', 'ê´€ë¦¬', 'í…ŒìŠ¤íŠ¸', 'ë¦¬íŒ©í† ë§']
    ğŸ“Š ì‹ ë¢°ë„: 0.88
    ğŸ†” Instance: fdc6dd02
    â±ï¸  Time: 4.38s
    ğŸ‘¤ User areas: ['ì½”ë“œ í’ˆì§ˆ ê´€ë¦¬', 'ê¸°ìˆ  ì—­ëŸ‰ ê°œë°œ']

    ğŸ“ ë¹„ë™ê¸° í…ŒìŠ¤íŠ¸ 3: ì˜¤ëŠ˜ í—¬ìŠ¤ì¥ì— ê°€ì„œ ìš´ë™í–ˆìŠµë‹ˆë‹¤.
    2025-11-09 23:31:17,964 - INFO - [fdc6dd02] ğŸ” Calling LLM (async)...
    2025-11-09 23:31:17,964 - INFO - [fdc6dd02]   - Text length: 18
    2025-11-09 23:31:17,964 - INFO - [fdc6dd02]   - Occupation: ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´
    2025-11-09 23:31:17,964 - INFO - [fdc6dd02]   - Areas: ì½”ë“œ í’ˆì§ˆ ê´€ë¦¬, ê¸°ìˆ  ì—­ëŸ‰ ê°œë°œ
    2025-11-09 23:31:27,785 - INFO - HTTP Request: POST https://**** "HTTP/1.1 200 OK"
    2025-11-09 23:31:27,789 - INFO - [fdc6dd02] âœ… ë¶„ë¥˜ ì™„ë£Œ (async):
    2025-11-09 23:31:27,789 - INFO - [fdc6dd02]   - Tags: ['ì½”ë“œ í’ˆì§ˆ ê´€ë¦¬', 'í…ŒìŠ¤íŠ¸', 'ë¦¬íŒ©í† ë§', 'ë²„ê·¸', 'í’ˆì§ˆ']
    2025-11-09 23:31:27,789 - INFO - [fdc6dd02]   - Confidence: 0.85
    2025-11-09 23:31:27,790 - INFO - [fdc6dd02]   - Time: 9.83s
    âœ… íƒœê·¸: ['ì½”ë“œ í’ˆì§ˆ ê´€ë¦¬', 'í…ŒìŠ¤íŠ¸', 'ë¦¬íŒ©í† ë§', 'ë²„ê·¸', 'í’ˆì§ˆ']
    ğŸ“Š ì‹ ë¢°ë„: 0.85
    ğŸ†” Instance: fdc6dd02
    â±ï¸  Time: 9.83s
    ğŸ‘¤ User areas: ['ì½”ë“œ í’ˆì§ˆ ê´€ë¦¬', 'ê¸°ìˆ  ì—­ëŸ‰ ê°œë°œ']

"""


"""test_result_7 â†’ â­•ï¸ 

    python -m backend.classifier.keyword_classifier

    ======================================================================
    KeywordClassifier í…ŒìŠ¤íŠ¸ (í”„ë¡¬í”„íŠ¸ íŒŒì¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©!)
    ======================================================================
    2025-11-10 23:04:45,242 - INFO - âœ… KeywordClassifier LLM ì´ˆê¸°í™” ì„±ê³µ
    2025-11-10 23:04:45,243 - INFO - [f63cf9b2] âœ… Chain ìƒì„± ì„±ê³µ (í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë¡œë“œ ì™„ë£Œ)
    2025-11-10 23:04:45,243 - INFO - âœ… KeywordClassifier initialized (ID: f63cf9b2, Time: 23:04:45)

    ======================================================================
    ë™ê¸° í…ŒìŠ¤íŠ¸ (ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ í¬í•¨)
    ======================================================================

    ğŸ“ í…ŒìŠ¤íŠ¸ 1: ì˜¤ëŠ˜ íšŒì˜ê°€ ìˆê³ , ì €ë…ì— ìŠ¤í„°ë”” ëª¨ì„ì´ ìˆìŠµë‹ˆë‹¤.
    2025-11-10 23:04:45,243 - INFO - ğŸ” [f63cf9b2] CLASSIFY ì‹œì‘: text_len=28, has_context=True
    2025-11-10 23:04:45,243 - INFO - [f63cf9b2] ğŸ” Calling LLM (sync)...
    2025-11-10 23:04:52,809 - INFO - HTTP Request: POST https://**** "HTTP/1.1 200 OK"
    2025-11-10 23:04:52,821 - INFO - [f63cf9b2] âœ… ë¶„ë¥˜ ì™„ë£Œ (sync):
    2025-11-10 23:04:52,822 - INFO - [f63cf9b2]   - Tags: ['ì½”ë“œ', 'í’ˆì§ˆ', 'ê´€ë¦¬', 'í…ŒìŠ¤íŠ¸', 'ë¦¬íŒ©í† ë§']
    âœ… íƒœê·¸: ['ì½”ë“œ', 'í’ˆì§ˆ', 'ê´€ë¦¬', 'í…ŒìŠ¤íŠ¸', 'ë¦¬íŒ©í† ë§']
    ğŸ“Š ì‹ ë¢°ë„: 0.9
    ğŸ†” Instance: f63cf9b2
    ğŸ‘¤ User matched: True

    ğŸ“ í…ŒìŠ¤íŠ¸ 2: ì¼ê¸°ë¥¼ ì“°ë©´ì„œ ì˜¤ëŠ˜ í•˜ë£¨ë¥¼ ëŒì•„ë´…ë‹ˆë‹¤.
    2025-11-10 23:04:52,822 - INFO - ğŸ” [f63cf9b2] CLASSIFY ì‹œì‘: text_len=21, has_context=True
    2025-11-10 23:04:52,822 - INFO - [f63cf9b2] ğŸ” Calling LLM (sync)...
    2025-11-10 23:05:00,044 - INFO - HTTP Request: POST https://**** "HTTP/1.1 200 OK"
    2025-11-10 23:05:00,046 - INFO - [f63cf9b2] âœ… ë¶„ë¥˜ ì™„ë£Œ (sync):
    2025-11-10 23:05:00,046 - INFO - [f63cf9b2]   - Tags: ['ì½”ë“œ', 'í’ˆì§ˆ', 'ê´€ë¦¬', 'í…ŒìŠ¤íŠ¸', 'ë¦¬íŒ©í† ë§']
    âœ… íƒœê·¸: ['ì½”ë“œ', 'í’ˆì§ˆ', 'ê´€ë¦¬', 'í…ŒìŠ¤íŠ¸', 'ë¦¬íŒ©í† ë§']
    ğŸ“Š ì‹ ë¢°ë„: 0.85
    ğŸ†” Instance: f63cf9b2
    ğŸ‘¤ User matched: True

    ğŸ“ í…ŒìŠ¤íŠ¸ 3: ì˜¤ëŠ˜ í—¬ìŠ¤ì¥ì— ê°€ì„œ ìš´ë™í–ˆìŠµë‹ˆë‹¤.
    2025-11-10 23:05:00,046 - INFO - ğŸ” [f63cf9b2] CLASSIFY ì‹œì‘: text_len=18, has_context=True
    2025-11-10 23:05:00,046 - INFO - [f63cf9b2] ğŸ” Calling LLM (sync)...
    2025-11-10 23:05:05,814 - INFO - HTTP Request: POST https://**** "HTTP/1.1 200 OK"
    2025-11-10 23:05:05,816 - INFO - [f63cf9b2] âœ… ë¶„ë¥˜ ì™„ë£Œ (sync):
    2025-11-10 23:05:05,816 - INFO - [f63cf9b2]   - Tags: ['ì½”ë“œ', 'í’ˆì§ˆ', 'ê´€ë¦¬', 'ê°œë°œ', 'í…ŒìŠ¤íŠ¸']
    âœ… íƒœê·¸: ['ì½”ë“œ', 'í’ˆì§ˆ', 'ê´€ë¦¬', 'ê°œë°œ', 'í…ŒìŠ¤íŠ¸']
    ğŸ“Š ì‹ ë¢°ë„: 0.9
    ğŸ†” Instance: f63cf9b2
    ğŸ‘¤ User matched: True

    ======================================================================
    ë¹„ë™ê¸° í…ŒìŠ¤íŠ¸
    ======================================================================
    2025-11-10 23:05:05,817 - INFO - âœ… KeywordClassifier LLM ì´ˆê¸°í™” ì„±ê³µ
    2025-11-10 23:05:05,819 - INFO - [24f8e519] âœ… Chain ìƒì„± ì„±ê³µ (í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë¡œë“œ ì™„ë£Œ)
    2025-11-10 23:05:05,819 - INFO - âœ… KeywordClassifier initialized (ID: 24f8e519, Time: 23:05:05)

    ğŸ“ ë¹„ë™ê¸° í…ŒìŠ¤íŠ¸ 1: ì˜¤ëŠ˜ íšŒì˜ê°€ ìˆê³ , ì €ë…ì— ìŠ¤í„°ë”” ëª¨ì„ì´ ìˆìŠµë‹ˆë‹¤.
    2025-11-10 23:05:05,819 - INFO - [24f8e519] ğŸ” Calling LLM (async)...
    2025-11-10 23:05:05,819 - INFO - [24f8e519]   - Text length: 28
    2025-11-10 23:05:05,819 - INFO - [24f8e519]   - Occupation: ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´
    2025-11-10 23:05:05,819 - INFO - [24f8e519]   - Areas: ì½”ë“œ í’ˆì§ˆ ê´€ë¦¬, ê¸°ìˆ  ì—­ëŸ‰ ê°œë°œ
    2025-11-10 23:05:05,819 - INFO - [24f8e519]   - Context Keywords: {}
    2025-11-10 23:05:19,640 - INFO - HTTP Request: POST https://**** "HTTP/1.1 200 OK"
    2025-11-10 23:05:19,647 - INFO - [24f8e519] ğŸ“¦ RAW LLM Response:
    2025-11-10 23:05:19,647 - INFO - [24f8e519]   - Type: <class 'str'>
    2025-11-10 23:05:19,647 - INFO - [24f8e519]   - Content preview: ```json
    {
    "tags": ["ì½”ë“œ", "í’ˆì§ˆ", "ë¦¬ë·°", "ë²„ê·¸", "ê°œë°œ"],
    "confidence": 0.85,
    "matched_keywords": {
        "Projects": ["ë§ˆê°", "íŒ€"],
        "Areas": ["í’ˆì§ˆ", "ê´€ë¦¬"],
        "Resources": [],
        "Archives": []
    },
    
    2025-11-10 23:05:19,647 - INFO - [24f8e519] ğŸ“¦ Extracted tags: ['ì½”ë“œ', 'í’ˆì§ˆ', 'ë¦¬ë·°', 'ë²„ê·¸', 'ê°œë°œ'] (type: <class 'list'>)
    2025-11-10 23:05:19,647 - INFO - [24f8e519] âœ… ë¦¬ìŠ¤íŠ¸ ê²€ì¦ ì™„ë£Œ: 5ê°œ
    2025-11-10 23:05:19,647 - INFO - [24f8e519] ğŸ“¦ Extracted tags: ['ì½”ë“œ', 'í’ˆì§ˆ', 'ë¦¬ë·°', 'ë²„ê·¸', 'ê°œë°œ'] (type: <class 'list'>)
    2025-11-10 23:05:19,647 - INFO - [24f8e519] âœ… ë¦¬ìŠ¤íŠ¸ ê²€ì¦ ì™„ë£Œ: 5ê°œ
    2025-11-10 23:05:19,647 - INFO - [24f8e519] âœ… ë¶„ë¥˜ ì™„ë£Œ (async):
    2025-11-10 23:05:19,647 - INFO - [24f8e519]   - Tags: ['ì½”ë“œ', 'í’ˆì§ˆ', 'ë¦¬ë·°', 'ë²„ê·¸', 'ê°œë°œ']
    2025-11-10 23:05:19,647 - INFO - [24f8e519]   - Confidence: 0.85
    2025-11-10 23:05:19,647 - INFO - [24f8e519]   - Time: 13.83s
    âœ… íƒœê·¸: ['ì½”ë“œ', 'í’ˆì§ˆ', 'ë¦¬ë·°', 'ë²„ê·¸', 'ê°œë°œ']
    ğŸ“Š ì‹ ë¢°ë„: 0.85
    ğŸ†” Instance: 24f8e519
    â±ï¸  Time: 13.83s
    ğŸ‘¤ User areas: ['ì½”ë“œ í’ˆì§ˆ ê´€ë¦¬', 'ê¸°ìˆ  ì—­ëŸ‰ ê°œë°œ']

    ğŸ“ ë¹„ë™ê¸° í…ŒìŠ¤íŠ¸ 2: ì¼ê¸°ë¥¼ ì“°ë©´ì„œ ì˜¤ëŠ˜ í•˜ë£¨ë¥¼ ëŒì•„ë´…ë‹ˆë‹¤.
    2025-11-10 23:05:19,647 - INFO - [24f8e519] ğŸ” Calling LLM (async)...
    2025-11-10 23:05:19,648 - INFO - [24f8e519]   - Text length: 21
    2025-11-10 23:05:19,648 - INFO - [24f8e519]   - Occupation: ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´
    2025-11-10 23:05:19,648 - INFO - [24f8e519]   - Areas: ì½”ë“œ í’ˆì§ˆ ê´€ë¦¬, ê¸°ìˆ  ì—­ëŸ‰ ê°œë°œ
    2025-11-10 23:05:19,648 - INFO - [24f8e519]   - Context Keywords: {}
    2025-11-10 23:05:25,578 - INFO - HTTP Request: POST https://**** "HTTP/1.1 200 OK"
    2025-11-10 23:05:25,581 - INFO - [24f8e519] ğŸ“¦ RAW LLM Response:
    2025-11-10 23:05:25,581 - INFO - [24f8e519]   - Type: <class 'str'>
    2025-11-10 23:05:25,581 - INFO - [24f8e519]   - Content preview: ```json
    {
    "tags": ["ì½”ë“œ", "í’ˆì§ˆ", "ë¦¬ë·°", "ê°œë°œ", "í…ŒìŠ¤íŠ¸"],
    "confidence": 0.85,
    "matched_keywords": {
        "Projects": [],
        "Areas": ["ì½”ë“œ", "í’ˆì§ˆ", "ë¦¬ë·°", "í…ŒìŠ¤íŠ¸"],
        "Resources": [],
        "Archives": []
    
    2025-11-10 23:05:25,581 - INFO - [24f8e519] ğŸ“¦ Extracted tags: ['ì½”ë“œ', 'í’ˆì§ˆ', 'ë¦¬ë·°', 'ê°œë°œ', 'í…ŒìŠ¤íŠ¸'] (type: <class 'list'>)
    2025-11-10 23:05:25,581 - INFO - [24f8e519] âœ… ë¦¬ìŠ¤íŠ¸ ê²€ì¦ ì™„ë£Œ: 5ê°œ
    2025-11-10 23:05:25,581 - INFO - [24f8e519] ğŸ“¦ Extracted tags: ['ì½”ë“œ', 'í’ˆì§ˆ', 'ë¦¬ë·°', 'ê°œë°œ', 'í…ŒìŠ¤íŠ¸'] (type: <class 'list'>)
    2025-11-10 23:05:25,581 - INFO - [24f8e519] âœ… ë¦¬ìŠ¤íŠ¸ ê²€ì¦ ì™„ë£Œ: 5ê°œ
    2025-11-10 23:05:25,581 - INFO - [24f8e519] âœ… ë¶„ë¥˜ ì™„ë£Œ (async):
    2025-11-10 23:05:25,581 - INFO - [24f8e519]   - Tags: ['ì½”ë“œ', 'í’ˆì§ˆ', 'ë¦¬ë·°', 'ê°œë°œ', 'í…ŒìŠ¤íŠ¸']
    2025-11-10 23:05:25,581 - INFO - [24f8e519]   - Confidence: 0.85
    2025-11-10 23:05:25,581 - INFO - [24f8e519]   - Time: 5.93s
    âœ… íƒœê·¸: ['ì½”ë“œ', 'í’ˆì§ˆ', 'ë¦¬ë·°', 'ê°œë°œ', 'í…ŒìŠ¤íŠ¸']
    ğŸ“Š ì‹ ë¢°ë„: 0.85
    ğŸ†” Instance: 24f8e519
    â±ï¸  Time: 5.93s
    ğŸ‘¤ User areas: ['ì½”ë“œ í’ˆì§ˆ ê´€ë¦¬', 'ê¸°ìˆ  ì—­ëŸ‰ ê°œë°œ']

    ğŸ“ ë¹„ë™ê¸° í…ŒìŠ¤íŠ¸ 3: ì˜¤ëŠ˜ í—¬ìŠ¤ì¥ì— ê°€ì„œ ìš´ë™í–ˆìŠµë‹ˆë‹¤.
    2025-11-10 23:05:25,581 - INFO - [24f8e519] ğŸ” Calling LLM (async)...
    2025-11-10 23:05:25,581 - INFO - [24f8e519]   - Text length: 18
    2025-11-10 23:05:25,581 - INFO - [24f8e519]   - Occupation: ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´
    2025-11-10 23:05:25,581 - INFO - [24f8e519]   - Areas: ì½”ë“œ í’ˆì§ˆ ê´€ë¦¬, ê¸°ìˆ  ì—­ëŸ‰ ê°œë°œ
    2025-11-10 23:05:25,582 - INFO - [24f8e519]   - Context Keywords: {}
    2025-11-10 23:05:31,824 - INFO - HTTP Request: POST https://**** "HTTP/1.1 200 OK"
    2025-11-10 23:05:31,827 - INFO - [24f8e519] ğŸ“¦ RAW LLM Response:
    2025-11-10 23:05:31,827 - INFO - [24f8e519]   - Type: <class 'str'>
    2025-11-10 23:05:31,827 - INFO - [24f8e519]   - Content preview: ```json
    {
    "tags": ["ì½”ë“œ", "í’ˆì§ˆ", "ë¦¬ë·°", "í…ŒìŠ¤íŠ¸", "ë¦¬íŒ©í† ë§"],
    "confidence": 0.85,
    "matched_keywords": {
        "Projects": [],
        "Areas": ["ì½”ë“œ", "í’ˆì§ˆ", "ë¦¬ë·°"],
        "Resources": [],
        "Archives": []
    },
    
    2025-11-10 23:05:31,827 - INFO - [24f8e519] ğŸ“¦ Extracted tags: ['ì½”ë“œ', 'í’ˆì§ˆ', 'ë¦¬ë·°', 'í…ŒìŠ¤íŠ¸', 'ë¦¬íŒ©í† ë§'] (type: <class 'list'>)
    2025-11-10 23:05:31,827 - INFO - [24f8e519] âœ… ë¦¬ìŠ¤íŠ¸ ê²€ì¦ ì™„ë£Œ: 5ê°œ
    2025-11-10 23:05:31,827 - INFO - [24f8e519] ğŸ“¦ Extracted tags: ['ì½”ë“œ', 'í’ˆì§ˆ', 'ë¦¬ë·°', 'í…ŒìŠ¤íŠ¸', 'ë¦¬íŒ©í† ë§'] (type: <class 'list'>)
    2025-11-10 23:05:31,827 - INFO - [24f8e519] âœ… ë¦¬ìŠ¤íŠ¸ ê²€ì¦ ì™„ë£Œ: 5ê°œ
    2025-11-10 23:05:31,827 - INFO - [24f8e519] âœ… ë¶„ë¥˜ ì™„ë£Œ (async):
    2025-11-10 23:05:31,827 - INFO - [24f8e519]   - Tags: ['ì½”ë“œ', 'í’ˆì§ˆ', 'ë¦¬ë·°', 'í…ŒìŠ¤íŠ¸', 'ë¦¬íŒ©í† ë§']
    2025-11-10 23:05:31,828 - INFO - [24f8e519]   - Confidence: 0.85
    2025-11-10 23:05:31,828 - INFO - [24f8e519]   - Time: 6.25s
    âœ… íƒœê·¸: ['ì½”ë“œ', 'í’ˆì§ˆ', 'ë¦¬ë·°', 'í…ŒìŠ¤íŠ¸', 'ë¦¬íŒ©í† ë§']
    ğŸ“Š ì‹ ë¢°ë„: 0.85
    ğŸ†” Instance: 24f8e519
    â±ï¸  Time: 6.25s
    ğŸ‘¤ User areas: ['ì½”ë“œ í’ˆì§ˆ ê´€ë¦¬', 'ê¸°ìˆ  ì—­ëŸ‰ ê°œë°œ']

"""
