# backend/api/endpoints/conflict_resolver_agent.py

"""
Conflict Resolution Agent (LangGraph ê¸°ë°˜)
- para_agent.py êµ¬ì¡° ì™„ë²½ ì¬í™œìš©
- ì¶©ëŒ ê°ì§€ â†’ ë¶„ì„ â†’ í•´ê²°ì±… ì œì•ˆ â†’ ì„ íƒ â†’ ì ìš©
"""

from typing import TypedDict, List, Dict, Any
from langgraph.graph import StateGraph, START, END
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from pathlib import Path
import json
import logging

from backend.config import ModelConfig

# ëª¨ë¸ í†µí•© ë§ˆì´ê·¸ë ˆì´ì…˜ ì„í¬íŠ¸
from backend.models import (
    ConflictRecord,
    ConflictReport,
    ConflictType,
    ConflictResolution,
    ResolutionMethod,
    ResolutionStatus,
    ResolutionStrategy,
    
)

logger = logging.getLogger(__name__)

# ============================================
# State ì •ì˜
# ============================================
class ConflictResolutionState(TypedDict):
    """Conflict Resolverì˜ ìƒíƒœ"""
    conflicts: List[ConflictRecord]  # ì…ë ¥: ê°ì§€ëœ ì¶©ëŒë“¤
    current_conflict: ConflictRecord  # í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ì¶©ëŒ
    analysis_result: Dict[str, Any]   # ë¶„ì„ ê²°ê³¼
    suggested_strategies: List[Dict]  # ì œì•ˆëœ ì „ëµë“¤
    selected_strategy: Dict           # ì„ íƒëœ ìµœì  ì „ëµ
    resolutions: List[ConflictResolution]  # í•´ê²°ì±…ë“¤
    final_report: ConflictReport      # ìµœì¢… ë³´ê³ ì„œ


# ============================================
# Node 1: Analyze (ì¶©ëŒ ë¶„ì„)
# ============================================
def analyze_conflict_node(state: ConflictResolutionState) -> ConflictResolutionState:
    """ğŸ” ì¶©ëŒ ë¶„ì„ ë…¸ë“œ"""
    conflict = state["current_conflict"]
    logger.info(f"ğŸ” ë¶„ì„ ì‹œì‘: {conflict.type}")

    llm = ChatOpenAI(
        api_key=ModelConfig.GPT4O_MINI_API_KEY,
        base_url=ModelConfig.GPT4O_MINI_BASE_URL,
        model=ModelConfig.GPT4O_MINI_MODEL,
        temperature=0.0
    )

    analysis_prompt = f"""ë©”íƒ€ë°ì´í„° ì¶©ëŒì„ ë¶„ì„í•˜ì„¸ìš”.

ì¶©ëŒ ì •ë³´:
- ìœ í˜•: {conflict.type}
- ì„¤ëª…: {conflict.description}
- ì‹¬ê°ë„: {conflict.severity}

JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”. ë§ˆí¬ë‹¤ìš´ ì½”ë“œë¸”ë¡ ì—†ì´!!!

{{"root_cause": "ì›ì¸", "priority": "high"}}"""

    try:
        response = llm.invoke(analysis_prompt)
        
        # âœ… response ì²´í¬
        if not response or not response.content:
            raise ValueError("LLM response is empty")
        
        analysis_text = response.content.strip()
        
        # âœ… ë§ˆí¬ë‹¤ìš´ ì œê±°!!!
        if analysis_text.startswith("```"):
            # ì²« ë²ˆì§¸ ``` ë’¤ ì œê±°
            start_idx = analysis_text.find("\n")
            if start_idx != -1:
                analysis_text = analysis_text[start_idx + 1:]
            # ë§ˆì§€ë§‰ ```
            end_idx = analysis_text.rfind("```")
            if end_idx != -1:
                analysis_text = analysis_text[:end_idx]
            analysis_text = analysis_text.strip()
        
        if not analysis_text:
            raise ValueError("Empty after cleanup")
        
        logger.info(f"ğŸ“ Raw response: {analysis_text[:100]}")
        
        # âœ… JSON íŒŒì‹±
        try:
            analysis_result = json.loads(analysis_text)
        except json.JSONDecodeError as e:
            logger.error(f"JSON íŒŒì‹± ì‹¤íŒ¨: {analysis_text}")
            raise ValueError(f"Invalid JSON: {e}")
        
        logger.info(f"âœ… ë¶„ì„ ì™„ë£Œ: {analysis_result.get('priority')}")
        
        return {
            **state,
            "analysis_result": analysis_result
        }

    except Exception as e:
        logger.error(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {e}")
        return {
            **state,
            "analysis_result": {
                "root_cause": "ë¶„ì„ ì‹¤íŒ¨",
                "priority": "medium"
            }
        }


# ============================================
# Node 2: Suggest (í•´ê²°ì±… ì œì•ˆ)
# ============================================
def suggest_strategies_node(state: ConflictResolutionState) -> ConflictResolutionState:
    """ğŸ’¡ í•´ê²°ì±… ì œì•ˆ ë…¸ë“œ"""
    conflict = state["current_conflict"]
    analysis = state["analysis_result"]
    
    logger.info(f"ğŸ’¡ ì „ëµ ì œì•ˆ ì‹œì‘")

    llm = ChatOpenAI(
        api_key=ModelConfig.GPT4O_MINI_API_KEY,
        base_url=ModelConfig.GPT4O_MINI_BASE_URL,
        model=ModelConfig.GPT4O_MINI_MODEL,
        temperature=0.3
    )

    strategy_prompt = f"""ì¶©ëŒ í•´ê²° ì „ëµì„ ì œì•ˆí•˜ì„¸ìš”.

ë¶„ì„ ê²°ê³¼:
- ì›ì¸: {analysis.get("root_cause", "ë¶ˆëª…")}
- ìš°ì„ ìˆœìœ„: {analysis.get("priority", "medium")}

ì¶©ëŒ:
- ìœ í˜•: {conflict.type}
- ì„¤ëª…: {conflict.description}

JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”. ë§ˆí¬ë‹¤ìš´ ì½”ë“œë¸”ë¡ ì—†ì´!!!

{{"method": "auto_by_confidence", "recommended_value": "ê°’", "confidence": 0.95, "reasoning": "ì´ìœ "}}"""

    try:
        response = llm.invoke(strategy_prompt)
        
        # âœ… response ì²´í¬
        if not response or not response.content:
            raise ValueError("LLM response is empty")
        
        strategy_text = response.content.strip()
        
        # âœ… ë§ˆí¬ë‹¤ìš´ ì œê±°!!!
        if strategy_text.startswith("```"):
            start_idx = strategy_text.find("\n")
            if start_idx != -1:
                strategy_text = strategy_text[start_idx + 1:]
            end_idx = strategy_text.rfind("```")
            if end_idx != -1:
                strategy_text = strategy_text[:end_idx]
            strategy_text = strategy_text.strip()
        
        if not strategy_text:
            raise ValueError("Empty after cleanup")
        
        logger.info(f"ğŸ“ Raw response: {strategy_text[:100]}")
        
        # âœ… JSON íŒŒì‹±
        try:
            strategy = json.loads(strategy_text)
        except json.JSONDecodeError as e:
            logger.error(f"JSON íŒŒì‹± ì‹¤íŒ¨: {strategy_text}")
            raise ValueError(f"Invalid JSON: {e}")
        
        logger.info(f"âœ… ì „ëµ ì œì•ˆ ì™„ë£Œ: {strategy.get('method')}")
        
        return {
            **state,
            "suggested_strategies": [strategy]
        }

    except Exception as e:
        logger.error(f"âŒ ì „ëµ ì œì•ˆ ì‹¤íŒ¨: {e}")
        return {
            **state,
            "suggested_strategies": [{
                "method": ResolutionMethod.MANUAL_OVERRIDE.value,
                "recommended_value": "ìˆ˜ë™ ê²€í†  í•„ìš”",
                "confidence": 0.3,
                "reasoning": "ìë™ ì œì•ˆ ì‹¤íŒ¨"
            }]
        }


# ============================================
# Node 3: Select (ìµœì  ì „ëµ ì„ íƒ)
# ============================================
def select_best_strategy_node(state: ConflictResolutionState) -> ConflictResolutionState:
    """ğŸ¯ ìµœì  ì „ëµ ì„ íƒ"""
    strategies = state.get("suggested_strategies", [])
    
    if not strategies:
        logger.warning("âš ï¸  ì „ëµ ì—†ìŒ")
        return {**state, "selected_strategy": None}
    
    # ì‹ ë¢°ë„ ê¸°ì¤€ ì •ë ¬
    best = sorted(strategies, key=lambda s: s.get("confidence", 0), reverse=True)[0]
    
    logger.info(f"ğŸ¯ ì„ íƒ: {best.get('method')} (ì‹ ë¢°ë„: {best.get('confidence', 0):.1%})")
    
    return {
        **state,
        "selected_strategy": best
    }


# ============================================
# Node 4: Apply (í•´ê²°ì±… ì ìš©)
# ============================================
def apply_resolution_node(state: ConflictResolutionState) -> ConflictResolutionState:
    """âœ… í•´ê²°ì±… ì ìš©"""
    strategy = state.get("selected_strategy")
    conflict = state["current_conflict"]
    
    if not strategy:
        logger.warning("âš ï¸  ì ìš©í•  ì „ëµ ì—†ìŒ")
        return {**state}
    
    # âœ… conflict_id ì¶”ê°€!!!
    strategy["conflict_id"] = conflict.conflict_id
    
    confidence = strategy.get("confidence", 0)
    
    # ì‹ ë¢°ë„ ê¸°ì¤€ íŒì •
    if confidence >= 0.85:
        status = ResolutionStatus.RESOLVED
        resolved_by = "system"
    elif confidence >= 0.5:
        status = ResolutionStatus.PENDING_REVIEW
        resolved_by = "pending_user"
    else:
        status = ResolutionStatus.FAILED
        resolved_by = "manual"
    
    resolution = ConflictResolution(
        conflict_id=conflict.conflict_id,
        status=status,
        strategy=strategy,
        resolved_by=resolved_by,
        notes=f"ë°©ë²•: {strategy.get('method')}, ì‹ ë¢°ë„: {confidence:.1%}"
    )
    
    resolutions = state.get("resolutions", [])
    resolutions.append(resolution)
    
    logger.info(f"âœ… í•´ê²° ì ìš©: {status.value}")
    
    return {
        **state,
        "resolutions": resolutions
    }


# ============================================
# Node 5: Generate Report
# ============================================
def generate_report_node(state: ConflictResolutionState) -> ConflictResolutionState:
    """ğŸ“Š ìµœì¢… ë³´ê³ ì„œ"""
    conflicts = state.get("conflicts", [])
    resolutions = state.get("resolutions", [])
    
    total = len(conflicts)
    resolved = len([r for r in resolutions 
                    if r.status == ResolutionStatus.RESOLVED])
    pending = len([r for r in resolutions 
                    if r.status == ResolutionStatus.PENDING_REVIEW])
    
    resolution_rate = (resolved / total) if total > 0 else 0.0
    
    report = ConflictReport(
        total_conflicts=total,
        detected_conflicts=conflicts,
        resolutions=resolutions,
        auto_resolved_count=resolved,
        manual_review_needed=pending,
        resolution_rate=resolution_rate,
        status="completed" if resolution_rate >= 0.8 else "partial",
        summary=f"{total}ê°œ ì¤‘ {resolved}ê°œ ìë™ í•´ê²°"
    )
    
    logger.info(f"ğŸ“Š ìµœì¢…: í•´ê²°ë¥  {resolution_rate:.1%}")
    
    return {
        **state,
        "final_report": report
    }


# ============================================
# Graph êµ¬ì„±
# ============================================
def create_conflict_resolver_graph():
    """LangGraph ìƒì„±"""
    graph = StateGraph(ConflictResolutionState)
    
    # ë…¸ë“œ ì¶”ê°€
    graph.add_node("analyze", analyze_conflict_node)
    graph.add_node("suggest", suggest_strategies_node)
    graph.add_node("select", select_best_strategy_node)
    graph.add_node("apply", apply_resolution_node)
    graph.add_node("report", generate_report_node)
    
    # ì—£ì§€ ì¶”ê°€
    graph.add_edge(START, "analyze")
    graph.add_edge("analyze", "suggest")
    graph.add_edge("suggest", "select")
    graph.add_edge("select", "apply")
    graph.add_edge("apply", "report")
    graph.add_edge("report", END)
    
    return graph.compile()


# ============================================
# ë©”ì¸ í•¨ìˆ˜
# ============================================
def resolve_conflicts_sync(conflicts: List[ConflictRecord]) -> ConflictReport:
    """ì¶©ëŒ í•´ê²° (ë™ê¸°)"""
    logger.info(f"ğŸš€ ì‹œì‘: {len(conflicts)}ê°œ ì¶©ëŒ")
    
    graph = create_conflict_resolver_graph()
    
    all_resolutions = []
    
    # ê° ì¶©ëŒ ì²˜ë¦¬
    for idx, conflict in enumerate(conflicts):
        logger.info(f"[{idx+1}/{len(conflicts)}] ì²˜ë¦¬ ì¤‘...")
        
        initial_state = {
            "conflicts": conflicts,
            "current_conflict": conflict,
            "analysis_result": {},
            "suggested_strategies": [],
            "selected_strategy": None,
            "resolutions": all_resolutions,
            "final_report": None
        }
        
        result = graph.invoke(initial_state)
        all_resolutions = result["resolutions"]
    
    # ìµœì¢… ë³´ê³ ì„œ
    total = len(conflicts)
    resolved = len([r for r in all_resolutions 
                    if r.status == ResolutionStatus.RESOLVED])
    pending = len([r for r in all_resolutions 
                    if r.status == ResolutionStatus.PENDING_REVIEW])
    
    resolution_rate = (resolved / total) if total > 0 else 0.0
    
    final_report = ConflictReport(
        total_conflicts=total,
        detected_conflicts=conflicts,
        resolutions=all_resolutions,
        auto_resolved_count=resolved,
        manual_review_needed=pending,
        resolution_rate=resolution_rate,
        status="completed" if resolution_rate >= 0.8 else "partial",
        summary=f"{total}ê°œ ì¤‘ {resolved}ê°œ ìë™ í•´ê²°, {pending}ê°œ ìˆ˜ë™ ê²€í†  í•„ìš”"
    )
    
    logger.info(f"âœ… ì™„ë£Œ!!! í•´ê²°ë¥ : {resolution_rate:.1%}")
    
    return final_report




# ============================================
# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
# ============================================

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    
    # í…ŒìŠ¤íŠ¸ ì¶©ëŒ ìƒì„±
    test_conflicts = [
        ConflictRecord(
            type=ConflictType.KEYWORD_CONFLICT,
            description="ìœ ì‚¬ í‚¤ì›Œë“œ: 'python' vs 'py'",
            severity=0.8,
            auto_resolvable=True
        ),
        ConflictRecord(
            type=ConflictType.CATEGORY_CONFLICT,
            description="íŒŒì¼ file_001ì´ ì—¬ëŸ¬ ì¹´í…Œê³ ë¦¬ì— ì†í•¨",
            severity=0.7,
            auto_resolvable=False
        )
    ]
    
    # í•´ê²° ì‹¤í–‰
    report = resolve_conflicts_sync(test_conflicts)
    
    print("\n" + "="*60)
    print("ğŸ“Š ìµœì¢… ë³´ê³ ì„œ")
    print("="*60)
    print(f"ì´ ì¶©ëŒ: {report.total_conflicts}")
    print(f"ìë™ í•´ê²°: {report.auto_resolved_count}")
    print(f"ìˆ˜ë™ ê²€í† : {report.manual_review_needed}")
    print(f"í•´ê²°ë¥ : {report.resolution_rate:.1%}")
    print(f"\nìš”ì•½: {report.summary}")
    print("="*60)




"""test_result_1 - ë³µì¡í•œ í”„ë¡¬í”„íŠ¸ 

    ```bash
    python -c "
    from backend.api.endpoints.conflict_resolver import ConflictDetector
    from backend.api.endpoints.conflict_resolver_agent import resolve_conflicts_sync

    detector = ConflictDetector(data_source='mock')
    report_detect = detector.detect_all()
    report_resolve = resolve_conflicts_sync(report_detect.detected_conflicts)
    print(f'âœ… í•´ê²°ë¥ : {report_resolve.resolution_rate:.1%}')
    "
    âŒ ë¶„ì„ ì‹¤íŒ¨: Expecting value: line 1 column 1 (char 0)
    âŒ ë¶„ì„ ì‹¤íŒ¨: Expecting value: line 1 column 1 (char 0)
    âœ… í•´ê²°ë¥ : 100.0%
    ```

"""