# backend/api/endpoints/conflict_resolver.py

from difflib import SequenceMatcher
from typing import List
from backend.api.models import ConflictRecord, ConflictReport, ConflictType

class ConflictDetector:
    def __init__(self, data_source: str = "mock"):
        """
        Args:
            data_source: "mock" ë˜ëŠ” "dashboard"
        """
        self.data_source = data_source
        self.metadata = self._load_metadata()
    
    def _load_metadata(self) -> List[dict]:
        """ë©”íƒ€ë°ì´í„° ë¡œë“œ (ì¡°ê±´ë¶€)"""
        if self.data_source == "mock":
            return self._get_mock_data()
        elif self.data_source == "dashboard":
            try:
                from backend.dashboard.dashboard_core import MetadataAggregator
                dashboard = MetadataAggregator()
                
                # ğŸ“ dashboardê°€ ì‹¤ì œë¡œ ì œê³µí•˜ëŠ” ë©”ì†Œë“œ ì‚¬ìš©
                # get_all_metadata() ëŒ€ì‹ ì— ë‹¤ìŒì„ ì‚¬ìš©:
                stats = dashboard.get_file_statistics()
                para_breakdown = dashboard.get_para_breakdown()
                keywords = dashboard.get_top_keywords(top_n=20)
                
                # Mock í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•´ì„œ ë°˜í™˜
                metadata = []
                for i, keyword in enumerate(keywords):
                    metadata.append({
                        "file_id": f"dashboard_file_{i}",
                        "category": "Projects",     # ì‹¤ì œë¡œëŠ” statsì—ì„œ íŒŒì‹±
                        "keywords": [keyword],
                        "timestamp": "2025-11-04T20:00:00"
                    })
                
                return metadata if metadata else self._get_mock_data()
            
            except Exception as e:
                print(f"âš ï¸ Dashboard ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
                print("   Mock ë°ì´í„°ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
                return self._get_mock_data()        # ì‹¤íŒ¨ ì‹œ Mockìœ¼ë¡œ ëŒ€ì²´
        
        else:
            raise ValueError(
                f"Invalid data_source: {self.data_source}. "
                f"Must be 'mock' or 'dashboard'"
            )


    def _get_mock_data(self) -> List[dict]:
        """Mock í…ŒìŠ¤íŠ¸ ë°ì´í„°"""
        return [
            {
                "file_id": "file_001",
                "category": "Projects",
                "keywords": ["python", "api", "backend"],
                "timestamp": "2025-11-04T20:00:00"
            },
            {
                "file_id": "file_002",
                "category": "Archives",
                "keywords": ["python", "py", "backend"],
                "timestamp": "2025-11-04T20:05:00"
            },
        ]
    
    def _calculate_similarity(self, str1: str, str2: str) -> float:
        """ìœ ì‚¬ë„ ê³„ì‚° (0.0 ~ 1.0)"""
        return SequenceMatcher(None, str1.lower(), str2.lower()).ratio()
    
    def detect_keyword_conflicts(self, threshold: float = 0.8) -> List[ConflictRecord]:
        """ìœ ì‚¬ í‚¤ì›Œë“œ ê°ì§€"""
        conflicts = []
        
        # ëª¨ë“  í‚¤ì›Œë“œ ìˆ˜ì§‘
        all_keywords = []
        for metadata in self.metadata:
            all_keywords.extend(metadata.get("keywords", []))
        
        # ìœ ì‚¬ í‚¤ì›Œë“œ ì°¾ê¸°
        processed = set()
        for i, kw1 in enumerate(all_keywords):
            if kw1 in processed:
                continue
            for kw2 in all_keywords[i+1:]:
                if kw2 in processed:
                    continue
                similarity = self._calculate_similarity(kw1, kw2)
                if similarity >= threshold:
                    # ì¶©ëŒ ê¸°ë¡ ìƒì„±
                    conflict = ConflictRecord(
                        type=ConflictType.KEYWORD_CONFLICT,
                        description=f"ìœ ì‚¬ í‚¤ì›Œë“œ: '{kw1}' vs '{kw2}'",
                        severity=similarity
                    )
                    conflicts.append(conflict)
                    processed.add(kw2)
        
        return conflicts
    
    def detect_category_conflicts(self) -> List[ConflictRecord]:
        """ì¹´í…Œê³ ë¦¬ ì¶©ëŒ ê°ì§€"""
        # ê°™ì€ íŒŒì¼ì´ ì—¬ëŸ¬ ì¹´í…Œê³ ë¦¬ì— ì†í•˜ëŠ”ì§€ í™•ì¸
        file_categories = {}
        for metadata in self.metadata:
            file_id = metadata.get("file_id")
            category = metadata.get("category")
            if file_id not in file_categories:
                file_categories[file_id] = []
            file_categories[file_id].append(category)
        
        conflicts = []
        for file_id, categories in file_categories.items():
            if len(set(categories)) > 1:
                conflict = ConflictRecord(
                    type=ConflictType.CATEGORY_CONFLICT,
                    description=f"íŒŒì¼ {file_id}ê°€ ì—¬ëŸ¬ ì¹´í…Œê³ ë¦¬ì— ì†í•¨: {categories}",
                    severity=0.8
                )
                conflicts.append(conflict)
        
        return conflicts
    
    def detect_all(self) -> ConflictReport:
        """ëª¨ë“  ì¶©ëŒ ê°ì§€ ë° ë³´ê³ ì„œ ìƒì„±"""
        keyword_conflicts = self.detect_keyword_conflicts()
        category_conflicts = self.detect_category_conflicts()
        
        all_conflicts = keyword_conflicts + category_conflicts
        
        report = ConflictReport(
            total_conflicts=len(all_conflicts),
            detected_conflicts=all_conflicts,
            auto_resolved_count=0,
            manual_review_needed=len(all_conflicts),
            resolution_rate=0.0,
            summary=f"ì´ {len(all_conflicts)}ê°œì˜ ì¶©ëŒ ê°ì§€ë¨"
        )
        
        return report



"""test_result_1 - Mock ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸

    python -c "
    from backend.api.endpoints.conflict_resolver import ConflictDetector

    # Mock ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸
    detector = ConflictDetector(data_source='mock')
    report = detector.detect_all()
    print(f'ê°ì§€ëœ ì¶©ëŒ: {report.total_conflicts}')
    "
    ê°ì§€ëœ ì¶©ëŒ: 2

"""


"""test_result_2 - ì‚´ì œ ë©”íƒ€ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸

    python -c '
    from backend.api.endpoints.conflict_resolver import ConflictDetector

    # ì‹¤ì œ ë©”íƒ€ë°ì´í„°ë¡œ ì‹¤í–‰
    detector_real = ConflictDetector(data_source="dashboard")
    report = detector_real.detect_all()
    print(f"Real: {report.total_conflicts} conflicts found")

    # ì˜ëª»ëœ ê°’ì´ë©´ error (ì´ ë¶€ë¶„ì€ ì‹¤í–‰ ì‹œ ì˜ˆì™¸ë¥¼ ë°œìƒì‹œí‚¤ë¯€ë¡œ í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ë‚¨ê²¨ë‘¡ë‹ˆë‹¤.)
    detector_error = ConflictDetector(data_source="invalid")
    '
    Traceback (most recent call last):
        File "<string>", line 5, in <module>
        File "/Users/jay/ICT-projects/flownote-mvp/backend/api/endpoints/conflict_resolver.py", line 14, in __init__
            self.metadata = self._load_metadata()
                            ^^^^^^^^^^^^^^^^^^^^^
        File "/Users/jay/ICT-projects/flownote-mvp/backend/api/endpoints/conflict_resolver.py", line 25, in _load_metadata
            return dashboard.get_all_metadata()
                ^^^^^^^^^^^^^^^^^^^^^^^^^^
    AttributeError: 'MetadataAggregator' object has no attribute 'get_all_metadata'


    # dashboard_core.pyì˜ ë©”ì†Œë“œ
        âœ… get_file_statistics()        # ìˆì„ ê±°
        âœ… get_para_breakdown()         # ìˆì„ ê±°
        âœ… get_keyword_categories()     # ìˆì„ ê±°
        âŒ get_all_metadata()           # ì—†ì„ ê±°!

"""


"""test_result_3 - `dashboard_core.py ë¶„ì„`

ìˆëŠ” ë©”ì†Œë“œë“¤ â†’ ì½”ë“œ ìˆ˜ì • â†’ ë‹¤ì‹œ í…ŒìŠ¤íŠ¸ 
    âœ… get_file_statistics() - íŒŒì¼ í†µê³„
    âœ… get_para_breakdown() - PARAë³„ ë¶„ë¥˜
    âœ… get_keyword_categories() - í‚¤ì›Œë“œ ì¹´í…Œê³ ë¦¬
    âœ… get_top_keywords() - ìƒìœ„ í‚¤ì›Œë“œ

"python -c "
from backend.api.endpoints.conflict_resolver import ConflictDetector

# Mock í…ŒìŠ¤íŠ¸
detector_mock = ConflictDetector(data_source='mock')
report_mock = detector_mock.detect_all()
print(f'âœ… Mock: {report_mock.total_conflicts} conflicts found')

# Dashboard í…ŒìŠ¤íŠ¸ (ì´ì œ ë˜ê±°ë‚˜ ì•ˆì „í•˜ê²Œ Mockìœ¼ë¡œ ëŒ€ì²´)
detector_dashboard = ConflictDetector(data_source='dashboard')
report_dashboard = detector_dashboard.detect_all()
print(f'âœ… Dashboard: {report_dashboard.total_conflicts} conflicts found')

# Invalid í…ŒìŠ¤íŠ¸
try:
    detector_invalid = ConflictDetector(data_source='invalid')
except ValueError as e:
    print(f'âœ… Error handling works: {e}')
"

âœ… Mock: 2 conflicts found 
    - âœ… ì™„ë²½ (2ê°œ ì¶©ëŒ) 
    - âœ… 2ê°œ ì¶©ëŒ ê°ì§€
    - ì¶©ëŒ ê°ì§€ ë¡œì§ ì •ìƒ
âœ… Dashboard: 0 conflicts found 
    - âœ… 0ê°œ ì¶©ëŒ + ì•ˆì „í•œ í´ë°±
    - ë°ì´í„° ì—†ì–´ë„ ì—ëŸ¬ ì•ˆ ë‚¨
âœ… Error handling works: Invalid data_source: invalid. Must be 'mock' or 'dashboard'
    - âœ… ValueError ë°œìƒ
    - ì˜ëª»ëœ ì…ë ¥ ì²˜ë¦¬ ì™„ë²½

"""
