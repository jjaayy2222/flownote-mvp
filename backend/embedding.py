# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# backend/embedding.py
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

"""
FlowNote ì„ë² ë”© ê´€ë¦¬
"""

import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from typing import List, Tuple
import numpy as np
from backend.config import get_embedding_client, EMBEDDING_MODEL

def get_embeddings(
    texts: List[str],
    show_progress: bool = True
) -> Tuple[List[List[float]], int, float]:
    """
    í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ â†’ ì„ë² ë”© ë²¡í„° + ë¹„ìš© ê³„ì‚°
    
    Args:
        texts: í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
        show_progress: ì§„í–‰ ìƒí™© í‘œì‹œ ì—¬ë¶€
        
    Returns:
        Tuple[embeddings, tokens, cost]:
        - embeddings: ì„ë² ë”© ë²¡í„° ë¦¬ìŠ¤íŠ¸
        - tokens: ì‚¬ìš©ëœ í† í° ìˆ˜
        - cost: ì˜ˆìƒ ë¹„ìš© (USD)
        
    Example:
        >>> texts = ["ì•ˆë…•", "ë°˜ê°€ì›Œ"]
        >>> embeddings, tokens, cost = get_embeddings(texts)
        >>> print(f"í† í°: {tokens}, ë¹„ìš©: ${cost:.6f}")
    """
    if not texts:
        return [], 0, 0.0
    
    try:
        # OpenAI Embedding API í˜¸ì¶œ
        client = get_embedding_client()
        
        if show_progress:
            print(f"ğŸ“Š ì„ë² ë”© ìƒì„± ì¤‘... ({len(texts)}ê°œ ì²­í¬)")
        
        response = client.embeddings.create(
            model=EMBEDDING_MODEL,
            input=texts
        )
        
        # ì„ë² ë”© ì¶”ì¶œ
        embeddings = [item.embedding for item in response.data]
        
        # í† í° & ë¹„ìš© ê³„ì‚°
        tokens = response.usage.total_tokens
        
        # Text-Embedding-3-Small: $0.00002/1k tokens
        cost_per_1k_tokens = 0.00002
        cost = (tokens / 1000) * cost_per_1k_tokens
        
        if show_progress:
            print(f"âœ… ì„ë² ë”© ì™„ë£Œ!")
            print(f"   - ì²­í¬ ìˆ˜: {len(texts)}")
            print(f"   - í† í° ìˆ˜: {tokens:,}")
            print(f"   - ì˜ˆìƒ ë¹„ìš©: ${cost:.6f}")
            print(f"   - ë²¡í„° ì°¨ì›: {len(embeddings[0])}")
        
        return embeddings, tokens, cost
        
    except Exception as e:
        print(f"âŒ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
        return [], 0, 0.0


def get_single_embedding(text: str) -> List[float]:
    """
    ë‹¨ì¼ í…ìŠ¤íŠ¸ â†’ ì„ë² ë”© ë²¡í„°
    (ê²€ìƒ‰ ì¿¼ë¦¬ìš©)
    
    Args:
        text: ê²€ìƒ‰ ì¿¼ë¦¬ í…ìŠ¤íŠ¸
        
    Returns:
        List[float]: ì„ë² ë”© ë²¡í„°
    """
    embeddings, _, _ = get_embeddings([text], show_progress=False)
    return embeddings[0] if embeddings else []


def calculate_similarity(
    embedding1: List[float],
    embedding2: List[float]
) -> float:
    """
    ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
    
    Args:
        embedding1: ì²« ë²ˆì§¸ ì„ë² ë”©
        embedding2: ë‘ ë²ˆì§¸ ì„ë² ë”©
        
    Returns:
        float: ìœ ì‚¬ë„ (0~1, 1ì´ ê°€ì¥ ìœ ì‚¬)
        
    Example:
        >>> emb1 = [0.1, 0.2, 0.3]
        >>> emb2 = [0.1, 0.2, 0.3]
        >>> similarity = calculate_similarity(emb1, emb2)
        >>> print(f"ìœ ì‚¬ë„: {similarity:.4f}")
        1.0000
    """
    # numpy ë°°ì—´ë¡œ ë³€í™˜
    vec1 = np.array(embedding1)
    vec2 = np.array(embedding2)
    
    # ì½”ì‚¬ì¸ ìœ ì‚¬ë„
    dot_product = np.dot(vec1, vec2)
    norm1 = np.linalg.norm(vec1)
    norm2 = np.linalg.norm(vec2)
    
    if norm1 == 0 or norm2 == 0:
        return 0.0
    
    similarity = dot_product / (norm1 * norm2)
    return float(similarity)


# ì‚¬ìš© ì˜ˆì‹œ (í…ŒìŠ¤íŠ¸ìš©)
if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸
    test_texts = [
        "FlowNoteëŠ” AI ëŒ€í™” ê´€ë¦¬ ë„êµ¬ì…ë‹ˆë‹¤.",
        "í‚¤ì›Œë“œ ê²€ìƒ‰ìœ¼ë¡œ ëŒ€í™”ë¥¼ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
        "Pythonìœ¼ë¡œ ê°œë°œë˜ì—ˆìŠµë‹ˆë‹¤."
    ]
    
    print("=" * 50)
    print("ì„ë² ë”© í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    # ì„ë² ë”© ìƒì„±
    embeddings, tokens, cost = get_embeddings(test_texts)
    
    if embeddings:
        print(f"\nâœ… ì„±ê³µ!")
        print(f"   - ì„ë² ë”© ê°œìˆ˜: {len(embeddings)}")
        print(f"   - ë²¡í„° ì°¨ì›: {len(embeddings[0])}")
        print(f"   - ì²« 5ê°œ ê°’: {embeddings[0][:5]}")
        
        # ìœ ì‚¬ë„ ê³„ì‚°
        print(f"\nìœ ì‚¬ë„ ê³„ì‚°:")
        sim = calculate_similarity(embeddings[0], embeddings[1])
        print(f"   - ì²­í¬ 0 vs ì²­í¬ 1: {sim:.4f}")


"""result

    ==================================================
    ì„ë² ë”© í…ŒìŠ¤íŠ¸
    ==================================================
    ğŸ“Š ì„ë² ë”© ìƒì„± ì¤‘... (3ê°œ ì²­í¬)
    âœ… ì„ë² ë”© ì™„ë£Œ!
        - ì²­í¬ ìˆ˜: 3
        - í† í° ìˆ˜: 40
        - ì˜ˆìƒ ë¹„ìš©: $0.000001
        - ë²¡í„° ì°¨ì›: 1536

    âœ… ì„±ê³µ!
        - ì„ë² ë”© ê°œìˆ˜: 3
        - ë²¡í„° ì°¨ì›: 1536
        - ì²« 5ê°œ ê°’: [-0.03015800751745701, 0.022111691534519196, -0.047065719962120056, -0.05024244636297226, -0.002251923317089677]

    ìœ ì‚¬ë„ ê³„ì‚°:
        - ì²­í¬ 0 vs ì²­í¬ 1: 0.3841

"""