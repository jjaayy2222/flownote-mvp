# backend/services/gpt_helper.py

"""
ğŸ¤– GPT-4o í—¬í¼ í´ë˜ìŠ¤
ê¸°ì¡´ config.pyë¥¼ í™œìš©í•œ ì¬ì‚¬ìš© ê°€ëŠ¥í•œ GPT í˜¸ì¶œ ìœ í‹¸ë¦¬í‹°
"""

import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

import os
from dotenv import load_dotenv

# ë¡œì»¬ .env ë¡œë“œ
load_dotenv()

# Streamlit Secrets (ë°°í¬ìš©)
try:
    import streamlit as st
    if hasattr(st, 'secrets') and len(st.secrets) > 0:
        for key in ["GPT4O_API_KEY", "GPT4O_BASE_URL", ...]:
            if key in st.secrets:
                os.environ[key] = st.secrets[key]
except:
    pass

from backend.config import ModelConfig

import re
import json
import logging
from typing import Dict, List, Optional
from backend.config import ModelConfig

logger = logging.getLogger(__name__)


class GPT4oHelper:
    """
    GPT-4o ì „ìš© í—¬í¼ í´ë˜ìŠ¤
    
    ê¸°ëŠ¥:
    - suggest_areas: ì§ì—…ë³„ ì±…ì„ ì˜ì—­ ì¶”ì²œ
    - generate_keywords: ì˜ì—­ë³„ í‚¤ì›Œë“œ ìƒì„±
    - classify_text: ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ë¶„ë¥˜
    """
    
    def __init__(self):
        """ì´ˆê¸°í™”: GPT-4o í´ë¼ì´ì–¸íŠ¸ ìƒì„±"""
        try:
            self.client = ModelConfig.get_openai_client("gpt-4o")
            self.model = ModelConfig.GPT4O_MODEL
            logger.info("âœ… GPT-4o í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ")
        except Exception as e:
            logger.error(f"âŒ GPT-4o ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.client = None
            self.model = None
    
    def _call(self, prompt: str, system_prompt: str = None, max_tokens: int = 500) -> str:
        """
        GPT-4o í˜¸ì¶œ (ë‚´ë¶€ ë©”ì„œë“œ)
        
        Args:
            prompt: ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸
            system_prompt: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
            max_tokens: ìµœëŒ€ í† í°
            
        Returns:
            GPT-4o ì‘ë‹µ í…ìŠ¤íŠ¸
        """
        if not self.client:
            raise Exception("GPT-4o í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        messages = []
        
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
        
        messages.append({"role": "user", "content": prompt})
        
        response = self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            max_tokens=max_tokens,
            temperature=0.7
        )
        
        raw_response = response.choices[0].message.content.strip()
        
        # âœ¨ ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ í•œë°©ì— ì œê±°!
        # 1. ì‹œì‘ ë¶€ë¶„ì˜ ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ë§ˆì»¤ ì œê±° (```json ë˜ëŠ” ```)
        raw_response = re.sub(r'^```(?:json)?\n', '', raw_response)
        # 2. ë ë¶€ë¶„ì˜ ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ë§ˆì»¤ ì œê±° (```)
        # ë§ˆì§€ë§‰ì— ```ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ì œê±°í•˜ë„ë¡ $ ì•µì»¤ë¥¼ ì¶”ê°€í•˜ëŠ” ê²ƒì´ ì•ˆì „
        raw_response = re.sub(r'\n```$', '', raw_response)
        
        logger.info(f"ğŸ” CLEANED RESPONSE: {raw_response[:200]}")           # â† ì²˜ìŒ 200ì ì¶œë ¥!
        logger.info(f"ğŸ“ RESPONSE LENGTH: {len(raw_response)}")             # â† ê¸¸ì´ í™•ì¸!
        
        return raw_response
    
    # ============================================
    # ğŸ¯ í•µì‹¬ ê¸°ëŠ¥ 1: ì§ì—…ë³„ ì˜ì—­ ì¶”ì²œ
    # ============================================
    
    def _load_prompt(self, prompt_name: str) -> str:
        """
        prompts/ í´ë”ì—ì„œ í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë¡œë“œ
        
        Args:
            prompt_name: í”„ë¡¬í”„íŠ¸ íŒŒì¼ëª… (í™•ì¥ì ì œì™¸)
            
        Returns:
            í”„ë¡¬í”„íŠ¸ ë‚´ìš©
        """
        from pathlib import Path
        
        prompt_path = Path(__file__).parent.parent / "classifier" / "prompts" / f"{prompt_name}.txt"
        
        if not prompt_path.exists():
            logger.warning(f"âš ï¸ í”„ë¡¬í”„íŠ¸ íŒŒì¼ ì—†ìŒ: {prompt_path}")
            return ""
        
        with open(prompt_path, "r", encoding="utf-8") as f:
            return f.read()
    
    def suggest_areas(self, occupation: str, count: int = 5) -> Dict[str, any]:
        """
        ì§ì—…ì— ë§ëŠ” ì±…ì„ ì˜ì—­ ì¶”ì²œ
        
        Args:
            occupation: ì§ì—… (ì˜ˆ: "êµì‚¬", "ê°œë°œì")
            count: ì¶”ì²œí•  ì˜ì—­ ê°œìˆ˜
            
        Returns:
            {
                "status": "success" | "error",
                "areas": ["ì˜ì—­1", "ì˜ì—­2", ...],
                "message": "ì„¤ëª…"
            }
        """
        try:
            # âœ… prompts/ì—ì„œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì‹œë„
            system_prompt = self._load_prompt("onboarding_suggest_areas")
            
            # âœ… í”„ë¡¬í”„íŠ¸ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
            if not system_prompt:
                logger.warning("âš ï¸ í”„ë¡¬í”„íŠ¸ íŒŒì¼ ì—†ìŒ, ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©")
                system_prompt = """
ë‹¹ì‹ ì€ ì§ì—…ë³„ í•µì‹¬ ì±…ì„ ì˜ì—­ì„ ì¶”ì²œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ê° ì˜ì—­ì€ 3-5ë‹¨ì–´ë¡œ ê°„ê²°í•˜ê²Œ í‘œí˜„í•˜ì„¸ìš”.
ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.
                """.strip()
            
            user_prompt = f"""
ì§ì—…: {occupation}

ì´ ì§ì—…ì˜ ì‚¬ëŒì´ ì±…ì„ì§€ê³  ê´€ë¦¬í•´ì•¼ í•˜ëŠ” í•µì‹¬ ì˜ì—­ì„ {count}ê°œ ì¶”ì²œí•´ì£¼ì„¸ìš”.

ì¶œë ¥ í˜•ì‹ (JSONë§Œ):
{{
  "areas": ["ì˜ì—­1", "ì˜ì—­2", "ì˜ì—­3", "ì˜ì—­4", "ì˜ì—­5"]
}}
            """.strip()
            
            # GPT-4o í˜¸ì¶œ
            response = self._call(user_prompt, system_prompt)
            
            # JSON íŒŒì‹±
            result = json.loads(response)
            areas = result.get("areas", [])
            
            logger.info(f"âœ… GPT-4o ì˜ì—­ ì¶”ì²œ ì„±ê³µ: {occupation} â†’ {len(areas)}ê°œ")
            
            return {
                "status": "success",
                "areas": areas,
                "message": f"{occupation}ì˜ í•µì‹¬ ì˜ì—­ {len(areas)}ê°œ ì¶”ì²œë¨"
            }
        
        except json.JSONDecodeError as e:
            logger.error(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            # Fallback
            return {
                "status": "success",
                "areas": self._get_fallback_areas(occupation, count),
                "message": "ê¸°ë³¸ ì¶”ì²œê°’ (GPT íŒŒì‹± ì‹¤íŒ¨)"
            }
        
        except Exception as e:
            logger.error(f"âŒ GPT-4o í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return {
                "status": "error",
                "areas": self._get_fallback_areas(occupation, count),
                "message": f"ì˜¤ë¥˜: {str(e)}"
            }




    def _get_fallback_areas(self, occupation: str, count: int = 5) -> List[str]:
        """
        Fallback: í•˜ë“œì½”ë”©ëœ ì§ì—…ë³„ ì˜ì—­
        """
        fallback_map = {
            "êµì‚¬": ["í•™ìƒ í‰ê°€", "ìˆ˜ì—… ê³„íš", "í•™ê¸‰ ìš´ì˜", "í•™ë¶€ëª¨ ì†Œí†µ", "êµì‚¬ ì—°ìˆ˜"],
            "ê°œë°œì": ["ì½”ë“œ ë¦¬ë·°", "ì•„í‚¤í…ì²˜ ì„¤ê³„", "íŒ€ í˜‘ì—…", "ê¸°ìˆ  í•™ìŠµ", "í”„ë¡œì íŠ¸ ê´€ë¦¬"],
            "ë§ˆì¼€í„°": ["ìº í˜ì¸ ì „ëµ", "ê³ ê° ë¶„ì„", "ë¸Œëœë“œ ê´€ë¦¬", "ë°ì´í„° ë¶„ì„", "ì‹œì¥ ì¡°ì‚¬"],
            "í•™ìƒ": ["ì‹œí—˜ ì¤€ë¹„", "ê³¼ì œ ê´€ë¦¬", "ë™ì•„ë¦¬ í™œë™", "ì§„ë¡œ íƒìƒ‰", "ê³µë¶€ ìŠµê´€"],
        }
        
        return fallback_map.get(occupation, [f"ê´€ì‹¬ë¶„ì•¼{i+1}" for i in range(count)])
    
    # ============================================
    # ğŸ¯ í•µì‹¬ ê¸°ëŠ¥ 2: ì˜ì—­ë³„ í‚¤ì›Œë“œ ìƒì„±
    # ============================================
    
    def generate_keywords(self, occupation: str, areas: List[str]) -> Dict[str, List[str]]:
        """
        ê° ì˜ì—­ë³„ í•µì‹¬ í‚¤ì›Œë“œ ìƒì„±
        
        Args:
            occupation: ì§ì—…
            areas: ì˜ì—­ ëª©ë¡
            
        Returns:
            {
                "ì˜ì—­1": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2", ...],
                "ì˜ì—­2": ["í‚¤ì›Œë“œ3", "í‚¤ì›Œë“œ4", ...],
                ...
            }
        """
        try:
            system_prompt = """
ë‹¹ì‹ ì€ ì˜ì—­ë³„ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ê° ì˜ì—­ë§ˆë‹¤ 3-5ê°œì˜ í‚¤ì›Œë“œë¥¼ ì œì‹œí•˜ì„¸ìš”.
ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.
            """.strip()
            
            user_prompt = f"""
ì§ì—…: {occupation}
ì˜ì—­: {', '.join(areas)}

ê° ì˜ì—­ë³„ë¡œ í•µì‹¬ í‚¤ì›Œë“œ 3-5ê°œë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

ì¶œë ¥ í˜•ì‹ (JSONë§Œ):
{{
  "ì˜ì—­1": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2", "í‚¤ì›Œë“œ3"],
  "ì˜ì—­2": ["í‚¤ì›Œë“œ4", "í‚¤ì›Œë“œ5", "í‚¤ì›Œë“œ6"],
  ...
}}
            """.strip()
            
            response = self._call(user_prompt, system_prompt, max_tokens=800)
            result = json.loads(response)
            
            logger.info(f"âœ… í‚¤ì›Œë“œ ìƒì„± ì„±ê³µ: {len(result)}ê°œ ì˜ì—­")
            return result
        
        except Exception as e:
            logger.error(f"âŒ í‚¤ì›Œë“œ ìƒì„± ì‹¤íŒ¨: {e}")
            # Fallback
            return {area: [f"{area}_í‚¤ì›Œë“œ{i+1}" for i in range(3)] for area in areas}
    
    # ============================================
    # ğŸ¯ í•µì‹¬ ê¸°ëŠ¥ 3: ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ë¶„ë¥˜
    # ============================================
    
    def classify_text(self, text: str, categories: List[str]) -> Dict[str, any]:
        """
        í…ìŠ¤íŠ¸ë¥¼ ì£¼ì–´ì§„ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜
        
        Args:
            text: ë¶„ë¥˜í•  í…ìŠ¤íŠ¸
            categories: ì¹´í…Œê³ ë¦¬ ëª©ë¡
            
        Returns:
            {
                "status": "success",
                "category": "ì„ íƒëœ ì¹´í…Œê³ ë¦¬",
                "confidence": 0.95,
                "reasoning": "ë¶„ë¥˜ ì´ìœ "
            }
        """
        try:
            system_prompt = """
ë‹¹ì‹ ì€ í…ìŠ¤íŠ¸ ë¶„ë¥˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì£¼ì–´ì§„ ì¹´í…Œê³ ë¦¬ ì¤‘ ê°€ì¥ ì í•©í•œ ê²ƒì„ ì„ íƒí•˜ì„¸ìš”.
ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.
            """.strip()
            
            user_prompt = f"""
í…ìŠ¤íŠ¸: {text}
ì¹´í…Œê³ ë¦¬: {', '.join(categories)}

ê°€ì¥ ì í•©í•œ ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•˜ê³ , ì‹ ë¢°ë„(0-1)ì™€ ì´ìœ ë¥¼ ì œì‹œí•˜ì„¸ìš”.

ì¶œë ¥ í˜•ì‹ (JSONë§Œ):
{{
  "category": "ì„ íƒëœ ì¹´í…Œê³ ë¦¬",
  "confidence": 0.95,
  "reasoning": "ë¶„ë¥˜ ì´ìœ  (í•œêµ­ì–´)"
}}
            """.strip()
            
            response = self._call(user_prompt, system_prompt)
            result = json.loads(response)
            
            return {
                "status": "success",
                **result
            }
        
        except Exception as e:
            logger.error(f"âŒ í…ìŠ¤íŠ¸ ë¶„ë¥˜ ì‹¤íŒ¨: {e}")
            return {
                "status": "error",
                "category": categories[0] if categories else "Unknown",
                "confidence": 0.5,
                "reasoning": f"ì˜¤ë¥˜: {str(e)}"
            }


# ============================================
# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ (ì„ íƒì‚¬í•­)
# ============================================

_gpt_helper_instance: Optional[GPT4oHelper] = None

def get_gpt_helper() -> GPT4oHelper:
    """GPT4oHelper ì‹±ê¸€í†¤ ë°˜í™˜"""
    global _gpt_helper_instance
    
    if _gpt_helper_instance is None:
        _gpt_helper_instance = GPT4oHelper()
    
    return _gpt_helper_instance


# ============================================
# í…ŒìŠ¤íŠ¸ ì½”ë“œ
# ============================================

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    
    print("\n" + "="*60)
    print("ğŸ¤– GPT-4o Helper í…ŒìŠ¤íŠ¸")
    print("="*60)
    
    helper = GPT4oHelper()
    
    # í…ŒìŠ¤íŠ¸ 1: ì˜ì—­ ì¶”ì²œ
    print("\n[í…ŒìŠ¤íŠ¸ 1] ì§ì—…ë³„ ì˜ì—­ ì¶”ì²œ")
    result = helper.suggest_areas("êµì‚¬")
    print(f"ìƒíƒœ: {result['status']}")
    print(f"ì˜ì—­: {result['areas']}")
    print(f"ë©”ì‹œì§€: {result['message']}")
    
    # í…ŒìŠ¤íŠ¸ 2: í‚¤ì›Œë“œ ìƒì„±
    print("\n[í…ŒìŠ¤íŠ¸ 2] ì˜ì—­ë³„ í‚¤ì›Œë“œ ìƒì„±")
    keywords = helper.generate_keywords("êµì‚¬", result['areas'][:3])
    for area, kws in keywords.items():
        print(f"  {area}: {', '.join(kws)}")
    
    # í…ŒìŠ¤íŠ¸ 3: í…ìŠ¤íŠ¸ ë¶„ë¥˜
    print("\n[í…ŒìŠ¤íŠ¸ 3] í…ìŠ¤íŠ¸ ë¶„ë¥˜")
    classify_result = helper.classify_text(
        "2025ë…„ ìˆ˜ì—… ê³„íšì„œ ì‘ì„±",
        ["Projects", "Areas", "Resources", "Archives"]
    )
    print(f"ì¹´í…Œê³ ë¦¬: {classify_result['category']}")
    print(f"ì‹ ë¢°ë„: {classify_result['confidence']}")
    print(f"ì´ìœ : {classify_result['reasoning']}")
    
    print("\n" + "="*60)
    print("ğŸ¤– GPT-4o Helper ìˆ˜ì • í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    print("="*60)


"""test_result_1 - âŒ

    â€ curl "http://localhost:8000/api/onboarding/suggest-areas?user_id=test&occupation=êµì‚¬" | jq '.'

    % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                    Dload  Upload   Total   Spent    Left  Speed
    100    30    0    30    0     0  22988      0 --:--:-- --:--:-- --:--:-- 30000
    jq: parse error: Invalid numeric literal at line 1, column 8

    â python -m backend.services.gpt_helper

    ============================================================
    ğŸ¤– GPT-4o Helper í…ŒìŠ¤íŠ¸
    ============================================================
    INFO:__main__:âœ… GPT-4o í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ

    [í…ŒìŠ¤íŠ¸ 1] ì§ì—…ë³„ ì˜ì—­ ì¶”ì²œ
    INFO:httpx:HTTP Request: POST https://**** "HTTP/1.1 200 OK"
    ERROR:__main__:âŒ JSON íŒŒì‹± ì‹¤íŒ¨: Expecting value: line 1 column 1 (char 0)
        ìƒíƒœ: success
        ì˜ì—­: ['í•™ìƒ í‰ê°€', 'ìˆ˜ì—… ê³„íš', 'í•™ê¸‰ ìš´ì˜', 'í•™ë¶€ëª¨ ì†Œí†µ', 'êµì‚¬ ì—°ìˆ˜']
        ë©”ì‹œì§€: ê¸°ë³¸ ì¶”ì²œê°’ (GPT íŒŒì‹± ì‹¤íŒ¨)

    [í…ŒìŠ¤íŠ¸ 2] ì˜ì—­ë³„ í‚¤ì›Œë“œ ìƒì„±
    INFO:httpx:HTTP Request: POST https://**** "HTTP/1.1 200 OK"
    ERROR:__main__:âŒ í‚¤ì›Œë“œ ìƒì„± ì‹¤íŒ¨: Expecting value: line 1 column 1 (char 0)
        í•™ìƒ í‰ê°€: í•™ìƒ í‰ê°€_í‚¤ì›Œë“œ1, í•™ìƒ í‰ê°€_í‚¤ì›Œë“œ2, í•™ìƒ í‰ê°€_í‚¤ì›Œë“œ3
        ìˆ˜ì—… ê³„íš: ìˆ˜ì—… ê³„íš_í‚¤ì›Œë“œ1, ìˆ˜ì—… ê³„íš_í‚¤ì›Œë“œ2, ìˆ˜ì—… ê³„íš_í‚¤ì›Œë“œ3
        í•™ê¸‰ ìš´ì˜: í•™ê¸‰ ìš´ì˜_í‚¤ì›Œë“œ1, í•™ê¸‰ ìš´ì˜_í‚¤ì›Œë“œ2, í•™ê¸‰ ìš´ì˜_í‚¤ì›Œë“œ3

    [í…ŒìŠ¤íŠ¸ 3] í…ìŠ¤íŠ¸ ë¶„ë¥˜
    INFO:httpx:HTTP Request: POST https://**** "HTTP/1.1 200 OK"
    ì¹´í…Œê³ ë¦¬: Projects
    ì‹ ë¢°ë„: 0.9
    ì´ìœ : ìˆ˜ì—… ê³„íšì„œëŠ” íŠ¹ì •í•œ ëª©í‘œì™€ ê²°ê³¼ë¥¼ ì—¼ë‘ì— ë‘ê³  ì‘ì„±ë˜ëŠ” ë¬¸ì„œë¡œ, ì¼ì •ì— ë”°ë¼ ìˆ˜í–‰í•´ì•¼ í•  ì‘ì—…ì„ í¬í•¨í•©ë‹ˆë‹¤. ì´ëŠ” í”„ë¡œì íŠ¸ì˜ íŠ¹ì„±ê³¼ ìœ ì‚¬í•˜ì—¬ 'Projects' ì¹´í…Œê³ ë¦¬ì— ê°€ì¥ ì í•©í•©ë‹ˆë‹¤.

    ============================================================
    ğŸ¤– GPT-4o Helper í…ŒìŠ¤íŠ¸ ì™„ë£Œ

    â†’ JSON íŒŒì‹± ì‹¤íŒ¨: ì‘ë‹µì´ ê·¸ëƒ¥ í…ìŠ¤íŠ¸ (JSON ì•„ë‹˜) â† ì´ê²Œ ê°€ì¥ ê°€ëŠ¥ì„± ë†’ìŒ!
    â†’ í”„ë¡ì‹œ ë¬¸ì œ â†’ JSON ëŒ€ì‹  ë‹¤ë¥¸ í˜•ì‹ ë°˜í™˜í•˜ëŠ” ê²ƒì¼ìˆ˜ë„ ìˆìŒ
    â†’ ë””ë²„ê¹… ì½”ë“œ ì¶”ê°€í•˜ê¸° 

"""


"""test_result_2 â†’ âŒ

    ```python
    # def _call(self, prompt: str, system_prompt: str = None, max_tokens: int = 500) -> str:
    
        # âœ¨ ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°!
        if raw_response.startswith("```json"):
            raw_response = raw_response.replace("``````", "")
        elif raw_response.startswith("```"):
            raw_response = raw_response.replace("```\n", "").replace("\n```", "")
        
        logger.info(f"ğŸ” CLEANED RESPONSE: {raw_response[:200]}")           # â† ì²˜ìŒ 200ì ì¶œë ¥!
        logger.info(f"ğŸ“ RESPONSE LENGTH: {len(raw_response)}")             # â† ê¸¸ì´ í™•ì¸!
    ```
    
    python -m backend.services.gpt_helper

    ============================================================
    ğŸ¤– GPT-4o Helper í…ŒìŠ¤íŠ¸
    ============================================================
    INFO:__main__:âœ… GPT-4o í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ

    [í…ŒìŠ¤íŠ¸ 1] ì§ì—…ë³„ ì˜ì—­ ì¶”ì²œ
    INFO:httpx:HTTP Request: POST https://**** "HTTP/1.1 200 OK"
    ERROR:__main__:âŒ GPT-4o í˜¸ì¶œ ì‹¤íŒ¨: 'list' object has no attribute 'message'
    ìƒíƒœ: error
    ì˜ì—­: ['í•™ìƒ í‰ê°€', 'ìˆ˜ì—… ê³„íš', 'í•™ê¸‰ ìš´ì˜', 'í•™ë¶€ëª¨ ì†Œí†µ', 'êµì‚¬ ì—°ìˆ˜']
    ë©”ì‹œì§€: ì˜¤ë¥˜: 'list' object has no attribute 'message'

    [í…ŒìŠ¤íŠ¸ 2] ì˜ì—­ë³„ í‚¤ì›Œë“œ ìƒì„±
    INFO:httpx:HTTP Request: POST https://**** "HTTP/1.1 200 OK"
    ERROR:__main__:âŒ í‚¤ì›Œë“œ ìƒì„± ì‹¤íŒ¨: 'list' object has no attribute 'message'
    í•™ìƒ í‰ê°€: í•™ìƒ í‰ê°€_í‚¤ì›Œë“œ1, í•™ìƒ í‰ê°€_í‚¤ì›Œë“œ2, í•™ìƒ í‰ê°€_í‚¤ì›Œë“œ3
    ìˆ˜ì—… ê³„íš: ìˆ˜ì—… ê³„íš_í‚¤ì›Œë“œ1, ìˆ˜ì—… ê³„íš_í‚¤ì›Œë“œ2, ìˆ˜ì—… ê³„íš_í‚¤ì›Œë“œ3
    í•™ê¸‰ ìš´ì˜: í•™ê¸‰ ìš´ì˜_í‚¤ì›Œë“œ1, í•™ê¸‰ ìš´ì˜_í‚¤ì›Œë“œ2, í•™ê¸‰ ìš´ì˜_í‚¤ì›Œë“œ3

    [í…ŒìŠ¤íŠ¸ 3] í…ìŠ¤íŠ¸ ë¶„ë¥˜
    INFO:httpx:HTTP Request: POST https://**** "HTTP/1.1 200 OK"
    ERROR:__main__:âŒ í…ìŠ¤íŠ¸ ë¶„ë¥˜ ì‹¤íŒ¨: 'list' object has no attribute 'message'
    ì¹´í…Œê³ ë¦¬: Projects
    ì‹ ë¢°ë„: 0.5
    ì´ìœ : ì˜¤ë¥˜: 'list' object has no attribute 'message'

    ============================================================
    ğŸ¤– GPT-4o Helper í…ŒìŠ¤íŠ¸ ì™„ë£Œ
    ============================================================

"""


"""test_result_3 â†’ âŒ

    â€ python -m backend.services.gpt_helper

    ```python
    # def _call(self, prompt: str, system_prompt: str = None, max_tokens: int = 500) -> str:
    
        # âœ¨ ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ í•œë°©ì— ì œê±°!
        # 1. ì‹œì‘ ë¶€ë¶„ì˜ ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ë§ˆì»¤ ì œê±° (```json ë˜ëŠ” ```)
        raw_response = re.sub(r'^```(?:json)?\n', '', raw_response)
        # 2. ë ë¶€ë¶„ì˜ ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ë§ˆì»¤ ì œê±° (```)
        # ë§ˆì§€ë§‰ì— ```ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ì œê±°í•˜ë„ë¡ $ ì•µì»¤ë¥¼ ì¶”ê°€í•˜ëŠ” ê²ƒì´ ì•ˆì „
        raw_response = re.sub(r'\n```$', '', raw_response)
        
        logger.info(f"ğŸ” CLEANED RESPONSE: {raw_response[:200]}")           # â† ì²˜ìŒ 200ì ì¶œë ¥!
        logger.info(f"ğŸ“ RESPONSE LENGTH: {len(raw_response)}")             # â† ê¸¸ì´ í™•ì¸!
        
        return raw_response
    
    ```


    ============================================================
    ğŸ¤– GPT-4o Helper í…ŒìŠ¤íŠ¸
    ============================================================
    INFO:__main__:âœ… GPT-4o í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ

    [í…ŒìŠ¤íŠ¸ 1] ì§ì—…ë³„ ì˜ì—­ ì¶”ì²œ
    INFO:httpx:HTTP Request: POST https://mlapi.run/0e6857e3-a90b-4c99-93ac-1f9f887a193e/v1/chat/completions "HTTP/1.1 200 OK"
    INFO:__main__:ğŸ” CLEANED RESPONSE: ```json
    {
    "areas": ["êµê³¼ëª© êµìœ¡", "í•™ìƒ í‰ê°€", "ìˆ˜ì—… ê³„íš", "í•™ê¸‰ ê´€ë¦¬", "ë¶€ëª¨ ì†Œí†µ"]
    }
    ```
    INFO:__main__:ğŸ“ RESPONSE LENGTH: 73
    ERROR:__main__:âŒ JSON íŒŒì‹± ì‹¤íŒ¨: Expecting value: line 1 column 1 (char 0)
    ìƒíƒœ: success
    ì˜ì—­: ['í•™ìƒ í‰ê°€', 'ìˆ˜ì—… ê³„íš', 'í•™ê¸‰ ìš´ì˜', 'í•™ë¶€ëª¨ ì†Œí†µ', 'êµì‚¬ ì—°ìˆ˜']
    ë©”ì‹œì§€: ê¸°ë³¸ ì¶”ì²œê°’ (GPT íŒŒì‹± ì‹¤íŒ¨)

    [í…ŒìŠ¤íŠ¸ 2] ì˜ì—­ë³„ í‚¤ì›Œë“œ ìƒì„±
    INFO:httpx:HTTP Request: POST https://mlapi.run/0e6857e3-a90b-4c99-93ac-1f9f887a193e/v1/chat/completions "HTTP/1.1 200 OK"
    INFO:__main__:ğŸ” CLEANED RESPONSE: ```json
    {
    "í•™ìƒ í‰ê°€": ["ì„±ì·¨ë„", "í‰ê°€ ê¸°ì¤€", "í”¼ë“œë°±", "ê°ê´€ì„±", "ê°œë³„í™”"],
    "ìˆ˜ì—… ê³„íš": ["í•™ìŠµ ëª©í‘œ", "êµìˆ˜ë²•", "êµìœ¡ ìë£Œ", "ì»¤ë¦¬í˜ëŸ¼", "ì°¨ì‹œë³„ ê³„íš"],
    "í•™ê¸‰ ìš´ì˜": ["í•™ê¸‰ ê´€ë¦¬", "ê·œì¹™ ì„¤ì •", "í•™ìƒ ì°¸ì—¬", "ì†Œí†µ", "ì•ˆì „"]
    }
    ```
    INFO:__main__:ğŸ“ RESPONSE LENGTH: 172
    ERROR:__main__:âŒ í‚¤ì›Œë“œ ìƒì„± ì‹¤íŒ¨: Expecting value: line 1 column 1 (char 0)
    í•™ìƒ í‰ê°€: í•™ìƒ í‰ê°€_í‚¤ì›Œë“œ1, í•™ìƒ í‰ê°€_í‚¤ì›Œë“œ2, í•™ìƒ í‰ê°€_í‚¤ì›Œë“œ3
    ìˆ˜ì—… ê³„íš: ìˆ˜ì—… ê³„íš_í‚¤ì›Œë“œ1, ìˆ˜ì—… ê³„íš_í‚¤ì›Œë“œ2, ìˆ˜ì—… ê³„íš_í‚¤ì›Œë“œ3
    í•™ê¸‰ ìš´ì˜: í•™ê¸‰ ìš´ì˜_í‚¤ì›Œë“œ1, í•™ê¸‰ ìš´ì˜_í‚¤ì›Œë“œ2, í•™ê¸‰ ìš´ì˜_í‚¤ì›Œë“œ3

    [í…ŒìŠ¤íŠ¸ 3] í…ìŠ¤íŠ¸ ë¶„ë¥˜
    INFO:httpx:HTTP Request: POST https://mlapi.run/0e6857e3-a90b-4c99-93ac-1f9f887a193e/v1/chat/completions "HTTP/1.1 200 OK"
    INFO:__main__:ğŸ” CLEANED RESPONSE: ```json
    {
    "category": "Projects",
    "confidence": 0.9,
    "reasoning": "ìˆ˜ì—… ê³„íšì„œëŠ” ë¯¸ë˜ì˜ êµìœ¡ í™œë™ì„ ìœ„í•œ êµ¬ì²´ì ì¸ ê³„íšì„ ì„¸ìš°ëŠ” ë¬¸ì„œë¡œ, ì´ëŠ” í”„ë¡œì íŠ¸ì˜ ì„±ê²©ê³¼ ìœ ì‚¬í•©ë‹ˆë‹¤. ë”°ë¼ì„œ '2025ë…„ ìˆ˜ì—… ê³„íšì„œ ì‘ì„±'ì€ íŠ¹ì • ëª©í‘œë¥¼ ë‹¬ì„±í•˜ê¸° ìœ„í•œ ê³„íšì´ë¯€ë¡œ 'Projects' ì¹´í…Œê³ ë¦¬ê°€ ì í•©í•©ë‹ˆë‹¤.
    INFO:__main__:ğŸ“ RESPONSE LENGTH: 207
    ERROR:__main__:âŒ í…ìŠ¤íŠ¸ ë¶„ë¥˜ ì‹¤íŒ¨: Expecting value: line 1 column 1 (char 0)
    ì¹´í…Œê³ ë¦¬: Projects
    ì‹ ë¢°ë„: 0.5
    ì´ìœ : ì˜¤ë¥˜: Expecting value: line 1 column 1 (char 0)
"""


"""test_result_4 â†’ â­•ï¸
    ```python
    # def _call(self, prompt: str, system_prompt: str = None, max_tokens: int = 500) -> str:
    
        raw_response = response.choices[0].message.content.strip()      # â† [0] ì¶”ê°€
        # âœ¨ ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ í•œë°©ì— ì œê±°!
    ```

    python -m backend.services.gpt_helper

    ============================================================
    ğŸ¤– GPT-4o Helper í…ŒìŠ¤íŠ¸
    ============================================================
    INFO:__main__:âœ… GPT-4o í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ

    [í…ŒìŠ¤íŠ¸ 1] ì§ì—…ë³„ ì˜ì—­ ì¶”ì²œ
    INFO:httpx:HTTP Request: POST https://mlapi.run/0e6857e3-a90b-4c99-93ac-1f9f887a193e/v1/chat/completions "HTTP/1.1 200 OK"
    INFO:__main__:ğŸ” CLEANED RESPONSE: {
    "areas": ["ìˆ˜ì—… ê³„íš", "í•™ìƒ í‰ê°€", "êµì‹¤ ê´€ë¦¬", "ìƒë‹´ ì§€ë„", "êµê³¼ ì—°êµ¬"]
    }
    INFO:__main__:ğŸ“ RESPONSE LENGTH: 60
    INFO:__main__:âœ… GPT-4o ì˜ì—­ ì¶”ì²œ ì„±ê³µ: êµì‚¬ â†’ 5ê°œ
    ìƒíƒœ: success
    ì˜ì—­: ['ìˆ˜ì—… ê³„íš', 'í•™ìƒ í‰ê°€', 'êµì‹¤ ê´€ë¦¬', 'ìƒë‹´ ì§€ë„', 'êµê³¼ ì—°êµ¬']
    ë©”ì‹œì§€: êµì‚¬ì˜ í•µì‹¬ ì˜ì—­ 5ê°œ ì¶”ì²œë¨

    [í…ŒìŠ¤íŠ¸ 2] ì˜ì—­ë³„ í‚¤ì›Œë“œ ìƒì„±
    INFO:httpx:HTTP Request: POST https://mlapi.run/0e6857e3-a90b-4c99-93ac-1f9f887a193e/v1/chat/completions "HTTP/1.1 200 OK"
    INFO:__main__:ğŸ” CLEANED RESPONSE: {
    "ìˆ˜ì—… ê³„íš": ["í•™ìŠµ ëª©í‘œ", "êµì¬ ì„ ì •", "ì‹œê°„ ë°°ë¶„", "êµìœ¡ ìë£Œ", "ìˆ˜ì—… ì§„í–‰"],
    "í•™ìƒ í‰ê°€": ["ì‹œí—˜", "ê³¼ì œ", "ì°¸ì—¬ë„", "í”¼ë“œë°±", "ì„±ì¥ ë¶„ì„"],
    "êµì‹¤ ê´€ë¦¬": ["ê·œì¹™ ì„¤ì •", "í™˜ê²½ ì¡°ì„±", "í•™ìƒ ì°¸ì—¬", "ë¬¸ì œ í•´ê²°", "ì•ˆì „ ê´€ë¦¬"]
    }
    INFO:__main__:ğŸ“ RESPONSE LENGTH: 166
    INFO:__main__:âœ… í‚¤ì›Œë“œ ìƒì„± ì„±ê³µ: 3ê°œ ì˜ì—­
    ìˆ˜ì—… ê³„íš: í•™ìŠµ ëª©í‘œ, êµì¬ ì„ ì •, ì‹œê°„ ë°°ë¶„, êµìœ¡ ìë£Œ, ìˆ˜ì—… ì§„í–‰
    í•™ìƒ í‰ê°€: ì‹œí—˜, ê³¼ì œ, ì°¸ì—¬ë„, í”¼ë“œë°±, ì„±ì¥ ë¶„ì„
    êµì‹¤ ê´€ë¦¬: ê·œì¹™ ì„¤ì •, í™˜ê²½ ì¡°ì„±, í•™ìƒ ì°¸ì—¬, ë¬¸ì œ í•´ê²°, ì•ˆì „ ê´€ë¦¬

    [í…ŒìŠ¤íŠ¸ 3] í…ìŠ¤íŠ¸ ë¶„ë¥˜
    INFO:httpx:HTTP Request: POST https://mlapi.run/0e6857e3-a90b-4c99-93ac-1f9f887a193e/v1/chat/completions "HTTP/1.1 200 OK"
    INFO:__main__:ğŸ” CLEANED RESPONSE: {
    "category": "Projects",
    "confidence": 0.9,
    "reasoning": "ìˆ˜ì—… ê³„íšì„œ ì‘ì„±ì€ ë¯¸ë˜ì˜ íŠ¹ì • ëª©í‘œë¥¼ ìœ„í•œ ê³„íš ë° ì¤€ë¹„ë¥¼ í¬í•¨í•˜ëŠ” ì‘ì—…ìœ¼ë¡œ, í”„ë¡œì íŠ¸ ì„±ê²©ì´ ê°•í•©ë‹ˆë‹¤. ë”°ë¼ì„œ 'Projects' ì¹´í…Œê³ ë¦¬ê°€ ê°€ì¥ ì í•©í•©ë‹ˆë‹¤."
    }
    INFO:__main__:ğŸ“ RESPONSE LENGTH: 158
    ì¹´í…Œê³ ë¦¬: Projects
    ì‹ ë¢°ë„: 0.9
    ì´ìœ : ìˆ˜ì—… ê³„íšì„œ ì‘ì„±ì€ ë¯¸ë˜ì˜ íŠ¹ì • ëª©í‘œë¥¼ ìœ„í•œ ê³„íš ë° ì¤€ë¹„ë¥¼ í¬í•¨í•˜ëŠ” ì‘ì—…ìœ¼ë¡œ, í”„ë¡œì íŠ¸ ì„±ê²©ì´ ê°•í•©ë‹ˆë‹¤. ë”°ë¼ì„œ 'Projects' ì¹´í…Œê³ ë¦¬ê°€ ê°€ì¥ ì í•©í•©ë‹ˆë‹¤.

    ============================================================
    ğŸ¤– GPT-4o Helper í…ŒìŠ¤íŠ¸ ì™„ë£Œ
    ============================================================

"""


"""test_result_5 â†’ ì„œë²„ í…ŒìŠ¤íŠ¸ â­•ï¸ 

    curl "http://localhost:8000/api/onboarding/suggest-areas?user_id=test&occupation=teacher"

    {
        "status":"success",
        "user_id":"test",
        "occupation":"teacher",
        "suggested_areas":[
            "ê´€ì‹¬ë¶„ì•¼1","ê´€ì‹¬ë¶„ì•¼2","ê´€ì‹¬ë¶„ì•¼3","ê´€ì‹¬ë¶„ì•¼4","ê´€ì‹¬ë¶„ì•¼5"
            ],
        "message":"Step 2: ì•„ë˜ ì˜ì—­ ì¤‘ ê´€ì‹¬ìˆëŠ” ê²ƒì„ ì„ íƒí•˜ì„¸ìš”",
        "next_step":"/api/onboarding/save-context (POST with selected_areas)"
    }

    [ì„œë²„ ìƒíƒœ] python -m backend.main
    âœ… ModelConfig loaded from backend.config
    INFO:__main__:âœ… api_router ë“±ë¡ ì™„ë£Œ
    INFO:__main__:âœ… classifier_router ë“±ë¡ ì™„ë£Œ
    INFO:__main__:âœ… onboarding_router ë“±ë¡ ì™„ë£Œ
    INFO:__main__:ğŸš€ FlowNote API ì‹œì‘...
    INFO:__main__:ğŸ“ http://localhost:8000
    INFO:__main__:ğŸ“š ë¬¸ì„œ: http://localhost:8000/docs
    INFO:     Started server process [97993]
    INFO:     Waiting for application startup.
    INFO:     Application startup complete.
    INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
    INFO:     127.0.0.1:59841 - "GET /api/onboarding/suggest-areas?user_id=test&occupation=teacher HTTP/1.1" 200 OK

"""







