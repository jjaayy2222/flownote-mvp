# backend/services/classification_service.py

"""
Î∂ÑÎ•ò ÎπÑÏ¶àÎãàÏä§ Î°úÏßÅ ÏÑúÎπÑÏä§ (Skeleton)
- PARA Agent + Keyword Classifier + Conflict Resolution Ïò§ÏºÄÏä§Ìä∏Î†àÏù¥ÏÖò
- Î°úÍπÖ Î∞è Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû•

Ïù¥ ÌååÏùºÏùÄ Phase 4 Step 2ÏóêÏÑú ÎºàÎåÄÎßå ÏÉùÏÑ±ÎêòÏóàÏäµÎãàÎã§.
Ïã§Ï†ú Î°úÏßÅÏùÄ Step 3ÏóêÏÑú Íµ¨ÌòÑÎê©ÎãàÎã§.
"""

import logging
import json
import csv
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, List, Optional

# Î™®Îç∏ Î∞è ÏùòÏ°¥ÏÑ± ÏûÑÌè¨Ìä∏
from backend.models import ClassifyResponse
from backend.services.conflict_service import ConflictService
from backend.data_manager import DataManager
from backend.classifier.para_agent import run_para_agent
from backend.classifier.keyword import KeywordClassifier

# Ï∂îÌõÑ Step 3ÏóêÏÑú Ïã§Ï†ú Î°úÏßÅ Íµ¨ÌòÑ Ïãú ÌïÑÏöîÌïú ÏûÑÌè¨Ìä∏Îì§
# from backend.classifier.para_agent import run_para_agent
# from backend.classifier.keyword_classifier import KeywordClassifier

logger = logging.getLogger(__name__)


class ClassificationService:
    """
    Î∂ÑÎ•ò Ïò§ÏºÄÏä§Ìä∏Î†àÏù¥ÏÖò ÏÑúÎπÑÏä§

    Ï±ÖÏûÑ:
    1. ÏÇ¨Ïö©Ïûê Ïª®ÌÖçÏä§Ìä∏ Íµ¨ÏÑ±
    2. PARA Î∂ÑÎ•ò Ïã§Ìñâ
    3. ÌÇ§ÏõåÎìú Ï∂îÏ∂ú Ïã§Ìñâ
    4. Ï∂©Îèå Ìï¥Í≤∞ (Conflict Service ÏúÑÏûÑ)
    5. Í≤∞Í≥º Ï†ÄÏû• Î∞è Î°úÍπÖ
    """

    def __init__(self):
        # ÏùòÏ°¥ÏÑ± Ï£ºÏûÖ (ÎòêÎäî ÎÇ¥Î∂Ä ÏÉùÏÑ±)
        self.conflict_service = ConflictService()
        self.data_manager = DataManager()
        logger.info("‚úÖ ClassificationService initialized")

    async def classify(
        self,
        text: str,
        user_id: str = None,
        file_id: str = None,
        occupation: str = None,
        areas: list = None,
        interests: list = None,
    ) -> ClassifyResponse:
        """
        ÌÜµÌï© Î∂ÑÎ•ò Î©îÏÑúÎìú (Main Entry Point)

        Args:
            text: Î∂ÑÎ•òÌï† ÌÖçÏä§Ìä∏ Î≥∏Î¨∏
            user_id: ÏÇ¨Ïö©Ïûê ID
            file_id: ÌååÏùºÎ™Ö ÎòêÎäî ID
            occupation: ÏßÅÏóÖ
            areas: Í¥ÄÏã¨ ÏòÅÏó≠ Î¶¨Ïä§Ìä∏
            interests: Í¥ÄÏã¨ÏÇ¨ Î¶¨Ïä§Ìä∏

        Returns:
            ClassifyResponse: ÏµúÏ¢Ö Î∂ÑÎ•ò Í≤∞Í≥º Î™®Îç∏
        """
        try:
            logger.info(f"üîµ Î∂ÑÎ•ò ÏãúÏûë: user_id={user_id}, text_len={len(text)}")

            # Step 1: ÏÇ¨Ïö©Ïûê Ïª®ÌÖçÏä§Ìä∏ Íµ¨ÏÑ±
            user_context = self._build_user_context(
                user_id, occupation, areas, interests
            )

            # Step 2: PARA Î∂ÑÎ•ò
            para_result = await self._run_para_classification(text, user_context)

            # Step 3: ÌÇ§ÏõåÎìú Ï∂îÏ∂ú
            keyword_result = await self._extract_keywords(text, user_context)

            # Step 4: Ï∂©Îèå Ìï¥Í≤∞
            conflict_result = await self._resolve_conflicts(
                para_result, keyword_result, text, user_context
            )

            # Step 5: ÏµúÏ¢Ö Ïπ¥ÌÖåÍ≥†Î¶¨ Í≤∞Ï†ï
            final_category = (
                conflict_result.get("final_category")
                or para_result.get("category")
                or "Resources"
            )

            # Step 6: Í≤∞Í≥º Ï†ÄÏû• (CSV + JSON) - Step 4ÏóêÏÑú ÏÉÅÏÑ∏ Íµ¨ÌòÑ
            # ÌòÑÏû¨Îäî Í∏∞Î≥∏ Ï†ïÎ≥¥Îßå ÎÑòÍπÄ
            log_info = self._save_results(
                user_id=user_id or "anonymous",
                file_id=file_id or "unknown",
                final_category=final_category,
                keyword_tags=keyword_result.get("tags", []),
                confidence=conflict_result.get("confidence", 0.0),
                snapshot_id=para_result.get("snapshot_id", ""),
            )

            # Step 7: ÏùëÎãµ ÏÉùÏÑ±
            response = ClassifyResponse(
                category=final_category,
                confidence=conflict_result.get("confidence", 0.0),
                snapshot_id=str(para_result.get("snapshot_id", "")),
                conflict_detected=conflict_result.get("conflict_detected", False),
                requires_review=conflict_result.get("requires_review", False),
                keyword_tags=keyword_result.get("tags", []),
                reasoning=conflict_result.get("reason", ""),
                user_context_matched=keyword_result.get("user_context_matched", False),
                user_areas=areas or [],
                user_context=user_context,
                context_injected=bool(areas),
                log_info=log_info,
            )

            logger.info(f"‚úÖ Î∂ÑÎ•ò ÏôÑÎ£å: {final_category}")
            return response

        except Exception as e:
            logger.error(f"‚ùå Î∂ÑÎ•ò Ïã§Ìå®: {e}", exc_info=True)
            raise

    # Private Î©îÏÑúÎìú Íµ¨ÌòÑ
    def _build_user_context(self, user_id, occupation, areas, interests) -> dict:
        """ÏÇ¨Ïö©Ïûê Ïª®ÌÖçÏä§Ìä∏ Íµ¨ÏÑ±"""
        return {
            "user_id": user_id or "anonymous",
            "occupation": occupation or "ÏùºÎ∞ò ÏÇ¨Ïö©Ïûê",
            "areas": areas or [],
            "interests": interests or [],
            "context_keywords": {
                area: [area, f"{area} Í¥ÄÎ†®", f"{area} ÏóÖÎ¨¥", f"{area} ÌîÑÎ°úÏ†ùÌä∏"]
                for area in (areas or [])
            },
        }

    async def _run_para_classification(self, text: str, metadata: dict) -> dict:
        """PARA Î∂ÑÎ•ò Ïã§Ìñâ"""
        try:
            result = await run_para_agent(text=text, metadata=metadata)
            logger.info(f"‚úÖ PARA: {result.get('category')}")
            return result
        except Exception as e:
            logger.error(f"‚ùå PARA Ïã§Ìå®: {e}")
            return {
                "category": "Resources",
                "confidence": 0.0,
                "snapshot_id": f"snap_failed_{int(datetime.now().timestamp())}",
            }

    async def _extract_keywords(self, text: str, user_context: dict) -> dict:
        """ÌÇ§ÏõåÎìú Ï∂îÏ∂ú"""
        classifier = KeywordClassifier()  # Îß§Î≤à ÏÉà Ïù∏Ïä§ÌÑ¥Ïä§ (ÏÉÅÌÉú ÏóÜÏùå)
        result = await classifier.classify(text=text, context=user_context)

        # ÌÉúÍ∑∏ ÏïàÏ†Ñ Ï≤òÎ¶¨
        tags = result.get("tags", [])
        if not isinstance(tags, list):
            tags = [str(tags)] if tags else ["Í∏∞ÌÉÄ"]
        elif not tags:
            tags = ["Í∏∞ÌÉÄ"]

        result["tags"] = tags
        logger.info(f"‚úÖ Keywords: {tags[:5]}")
        return result

    async def _resolve_conflicts(
        self, para_result: dict, keyword_result: dict, text: str, user_context: dict
    ) -> dict:
        """Ï∂©Îèå Ìï¥Í≤∞"""
        result = await self.conflict_service.classify_text(
            para_result=para_result,
            keyword_result=keyword_result,
            text=text,
            user_context=user_context,
        )
        logger.info(f"‚úÖ Conflict: {result.get('final_category')}")
        return result

    def _save_results(
        self,
        user_id: str,
        file_id: str,
        final_category: str,
        keyword_tags: list,
        confidence: float,
        snapshot_id: str,
    ) -> dict:
        """Í≤∞Í≥º Ï†ÄÏû• (CSV + JSON)"""
        try:
            # Í≤ΩÎ°ú ÏÑ§Ï†ï (ÌîÑÎ°úÏ†ùÌä∏ Î£®Ìä∏ Í∏∞Ï§Ä)
            PROJECT_ROOT = Path(__file__).parent.parent.parent
            LOG_DIR = PROJECT_ROOT / "data" / "log"
            CSV_DIR = PROJECT_ROOT / "data" / "classifications"

            LOG_DIR.mkdir(parents=True, exist_ok=True)
            CSV_DIR.mkdir(parents=True, exist_ok=True)

            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")[:-3]

            # 1. CSV Î°úÍ∑∏
            csv_path = CSV_DIR / "classification_log.csv"
            file_exists = csv_path.exists() and csv_path.stat().st_size > 0

            with open(csv_path, "a", newline="", encoding="utf-8") as f:
                writer = csv.DictWriter(
                    f,
                    fieldnames=[
                        "timestamp",
                        "user_id",
                        "file_id",
                        "category",
                        "confidence",
                        "keyword_tags",
                    ],
                )
                if not file_exists:
                    writer.writeheader()
                writer.writerow(
                    {
                        "timestamp": datetime.now().isoformat(),
                        "user_id": user_id,
                        "file_id": file_id,
                        "category": final_category,
                        "confidence": round(confidence, 3),
                        "keyword_tags": ",".join(keyword_tags),
                    }
                )

            # 2. JSON Î°úÍ∑∏
            json_path = LOG_DIR / f"classification_{timestamp}.json"
            json_data = {
                "timestamp": timestamp,
                "user_id": user_id,
                "file_id": file_id,
                "category": final_category,
                "keyword_tags": keyword_tags,
                "confidence": confidence,
                "snapshot_id": snapshot_id,
            }
            with open(json_path, "w", encoding="utf-8") as f:
                json.dump(json_data, f, ensure_ascii=False, indent=2)

            logger.info(f"‚úÖ Î°úÍ∑∏ Ï†ÄÏû•: CSV + JSON")

            return {
                "csv_saved": True,
                "json_saved": True,
                "csv_path": str(csv_path),
                "json_path": json_path.name,
            }

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Î°úÍ∑∏ Ï†ÄÏû• Ïã§Ìå® (Î¨¥Ïãú Í∞ÄÎä•): {e}")
            return {"error": str(e)}
