# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# app.py (íŒŒì¼ ëª©ë¡ì— ì—…ë¡œë“œëœ íŒŒì¼ ì¶”ê°€)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

"""
FlowNote MVP - Streamlit UI
"""

import streamlit as st
from pathlib import Path
from datetime import datetime
import uuid

from backend.chunking import TextChunker
from backend.embedding import EmbeddingGenerator
from backend.faiss_search import FAISSRetriever
from backend.metadata import FileMetadata
from backend.search_history import SearchHistory
from backend.config import EMBEDDING_MODEL

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="FlowNote MVP",
    page_icon="ğŸ’¬",
    layout="wide"
)

# ë°ì´í„° ë””ë ‰í† ë¦¬
DATA_DIR = Path("data")
UPLOADS_DIR = DATA_DIR / "uploads"
UPLOADS_DIR.mkdir(parents=True, exist_ok=True)

# Session State ì´ˆê¸°í™”
if 'retriever' not in st.session_state:
    st.session_state.retriever = FAISSRetriever()

if 'metadata' not in st.session_state:
    st.session_state.metadata = FileMetadata()

if 'search_history' not in st.session_state:
    st.session_state.search_history = SearchHistory()


def save_file(uploaded_file) -> Path:
    """íŒŒì¼ ì €ì¥"""
    file_path = UPLOADS_DIR / uploaded_file.name
    with open(file_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    return file_path


def process_uploaded_file(uploaded_file, file_id: str):
    """ì—…ë¡œë“œëœ íŒŒì¼ ì²˜ë¦¬ (ì²­í‚¹ â†’ ì„ë² ë”© â†’ FAISS)"""
    
    # 1. íŒŒì¼ ì½ê¸°
    content = uploaded_file.read().decode('utf-8')
    
    # 2. ì²­í‚¹
    chunker = TextChunker(chunk_size=500, chunk_overlap=50)
    chunks = chunker.chunk_text(content)
    
    # 3. ì„ë² ë”© ìƒì„±
    generator = EmbeddingGenerator()
    result = generator.generate_embeddings(chunks)
    embeddings = result['embeddings']
    
    # 4. FAISSì— ì €ì¥
    st.session_state.retriever.add_documents(chunks, embeddings)
    
    # 5. ë©”íƒ€ë°ì´í„°ì— ê¸°ë¡
    st.session_state.metadata.add_file(
        file_name=uploaded_file.name,
        file_size=uploaded_file.size,
        chunk_count=len(chunks),
        embedding_dim=len(embeddings[0]) if embeddings else 0,
        model=EMBEDDING_MODEL
    )
    
    return len(chunks), result['tokens'], result['cost']


# í—¤ë”
st.title("ğŸ’¬ FlowNote MVP")

# ì‚¬ì´ë“œë°”: íŒŒì¼ í†µê³„
with st.sidebar:
    st.header("ğŸ“Š íŒŒì¼ í†µê³„")
    
    stats = st.session_state.metadata.get_statistics()
    
    col1, col2 = st.columns(2)
    with col1:
        st.metric("ì´ íŒŒì¼", f"{stats['total_files']}ê°œ")
        st.metric("ì´ ì²­í¬", f"{stats['total_chunks']}ê°œ")
    
    with col2:
        st.metric("ì´ ìš©ëŸ‰", f"{stats['total_size_mb']:.2f} MB")
        st.metric("ëª¨ë¸ ìˆ˜", f"{len(stats['models_used'])}ê°œ")
    
    st.divider()
    
    st.header("ğŸ“‚ íŒŒì¼ ëª©ë¡")
    
    all_files = st.session_state.metadata.get_all_files()
    
    if all_files:
        # âœ… ë”•ì…”ë„ˆë¦¬ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ê³  ìƒì„± ì‹œê°„ ê¸°ì¤€ ì •ë ¬
        file_items = sorted(
            all_files.items(),
            key=lambda x: x[1].get('created_at', ''),
            reverse=True  # ìµœì‹  ìˆœ
        )
        
        # âœ… ì „ì²´ íŒŒì¼ í‘œì‹œ (ìµœëŒ€ 10ê°œë¡œ ì œí•œ)
        display_count = min(len(file_items), 10)
        st.caption(f"ìµœê·¼ {display_count}ê°œ íŒŒì¼")
        
        for file_id, file_data in file_items[:display_count]:
            with st.expander(f"ğŸ“„ {file_data.get('file_name', 'Unknown')}"):
                st.text(f"í¬ê¸°: {file_data.get('file_size_mb', 0):.2f} MB")
                st.text(f"ì²­í¬: {file_data.get('chunk_count', 0)}ê°œ")
                st.text(f"ëª¨ë¸: {file_data.get('embedding_model', 'N/A')}")
                st.text(f"ì—…ë¡œë“œ: {file_data.get('created_at', 'N/A')}")
    else:
        st.info("ì—…ë¡œë“œëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

# ë©”ì¸ ì˜ì—­: íƒ­
tab1, tab2, tab3 = st.tabs(["ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ", "ğŸ” ê²€ìƒ‰", "ğŸ“Š íˆìŠ¤í† ë¦¬"])

# íƒ­ 1: íŒŒì¼ ì—…ë¡œë“œ
with tab1:
    st.header("ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ")
    st.caption("í…ìŠ¤íŠ¸ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ìë™ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
    
    st.subheader("íŒŒì¼ ì„ íƒ")
    uploaded_file = st.file_uploader(
        "Drag and drop file here",
        type=['txt', 'md'],
        label_visibility="collapsed"
    )
    
    if uploaded_file:
        st.write(f"ğŸ“„ **{uploaded_file.name}** ({uploaded_file.size / 1024:.1f} KB)")
        
        if st.button("ğŸ“¤ ì²˜ë¦¬ ì‹œì‘", type="primary"):
            with st.spinner("íŒŒì¼ ì²˜ë¦¬ ì¤‘..."):
                try:
                    # íŒŒì¼ ID ìƒì„±
                    file_id = f"file_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{uuid.uuid4().hex[:8]}"
                    
                    # íŒŒì¼ ì €ì¥
                    file_path = save_file(uploaded_file)
                    
                    # íŒŒì¼ ì²˜ë¦¬ (ì²­í‚¹ â†’ ì„ë² ë”© â†’ FAISS)
                    uploaded_file.seek(0)  # íŒŒì¼ í¬ì¸í„° ë¦¬ì…‹
                    chunks, tokens, cost = process_uploaded_file(uploaded_file, file_id)
                    
                    st.success("âœ… íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ!")
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("ì²­í¬ ìˆ˜", f"{chunks}ê°œ")
                    with col2:
                        st.metric("í† í° ìˆ˜", f"{tokens}ê°œ")
                    with col3:
                        st.metric("ì˜ˆìƒ ë¹„ìš©", f"${cost:.6f}")
                    
                    st.info("ğŸ’¡ ì´ì œ ê²€ìƒ‰ íƒ­ì—ì„œ íŒŒì¼ ë‚´ìš©ì„ ê²€ìƒ‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")
                    
                except Exception as e:
                    st.error(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")

# íƒ­ 2: ê²€ìƒ‰
with tab2:
    st.header("ğŸ” ê²€ìƒ‰")
    st.caption("ì—…ë¡œë“œí•œ íŒŒì¼ì—ì„œ ë‚´ìš©ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.")
    
    query = st.text_input("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”", placeholder="ì˜ˆ: FlowNote ì‚¬ìš©ë²•")
    k = st.slider("ê²°ê³¼ ê°œìˆ˜", 1, 10, 3)
    
    if st.button("ğŸ” ê²€ìƒ‰", type="primary"):
        if query:
            with st.spinner("ê²€ìƒ‰ ì¤‘..."):
                # FAISS ê²€ìƒ‰
                results = st.session_state.retriever.search(query, k=k)
                
                # ê²€ìƒ‰ ê¸°ë¡ ì €ì¥
                search_id = st.session_state.search_history.add_search(
                    query=query,
                    results_count=len(results),
                    top_results=[r['text'][:100] for r in results[:3]] if results else []
                )
                
                # ê²°ê³¼ í‘œì‹œ
                if results:
                    st.success(f"âœ… {len(results)}ê°œ ê²°ê³¼ ë°œê²¬")
                    
                    for i, result in enumerate(results, 1):
                        with st.container():
                            st.subheader(f"{i}ìœ„ (ìœ ì‚¬ë„: {result['similarity']:.4f})")
                            st.write(result['text'])
                            st.divider()
                else:
                    st.warning("âš ï¸ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.warning("âš ï¸ ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

# íƒ­ 3: íˆìŠ¤í† ë¦¬
with tab3:
    st.header("ğŸ“Š ê²€ìƒ‰ íˆìŠ¤í† ë¦¬")
    
    # âœ… get_recent_searches()ëŠ” ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜!
    recent_searches = st.session_state.search_history.get_recent_searches(limit=10)
    
    if recent_searches:
        # âœ… ì´ë¯¸ ë¦¬ìŠ¤íŠ¸ì´ë¯€ë¡œ ë°”ë¡œ ìˆœíšŒ!
        for search_data in recent_searches:
            with st.expander(f"ğŸ” {search_data['query']} (ê²°ê³¼: {search_data['results_count']}ê°œ)"):
                st.text(f"ì‹œê°„: {search_data['created_at']}")
                
                if search_data.get('top_results'):
                    st.subheader("ìƒìœ„ ê²°ê³¼:")
                    for i, result in enumerate(search_data['top_results'], 1):
                        st.write(f"{i}. {result}...")
                else:
                    st.info("0ê°œ ê²°ê³¼ ë°œê²¬")
    else:
        st.info("ì•„ì§ ê²€ìƒ‰ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")

# í‘¸í„°
st.divider()
st.caption("FlowNote MVP v1.0 | Made with â¤ï¸ by Jay")
