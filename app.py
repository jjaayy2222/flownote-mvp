# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# app.py (íŒŒì¼ ì—…ë¡œë“œ ì—ëŸ¬ í•¸ë“¤ë§ ì¶”ê°€)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""
FlowNote MVP - Streamlit UI
"""

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ì„í¬íŠ¸
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
import streamlit as st
import os
from datetime import datetime
import numpy as np
from collections import defaultdict                                                     # âœ¨ ì¶”ê°€!

# backend í´ë˜ìŠ¤ ì„í¬íŠ¸
from backend.embedding import EmbeddingGenerator
from backend.chunking import TextChunker
from backend.faiss_search import FAISSRetriever
from backend.metadata import FileMetadata
from backend.search_history import SearchHistory

# ê²€ì¦ ë° íŒŒì¼ ì²˜ë¦¬ ìœ í‹¸ë¦¬í‹° ì„í¬íŠ¸
from backend.validators import FileValidator, QueryValidator, APIKeyValidator           # ìœ íš¨ì„± ê²€ì¦ í´ë˜ìŠ¤
from backend.exceptions import FileValidationError, QueryValidationError, APIKeyError   # ì˜ˆì™¸ ì²˜ë¦¬ í´ë˜ìŠ¤
from backend.utils import read_file_content, format_file_size                           # íŒŒì¼ ì½ê¸° ë° í¬ê¸° í¬ë§· í•¨ìˆ˜

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# í˜ì´ì§€ ì„¤ì •
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
st.set_page_config(
    page_title="FlowNote",                      # ë¸Œë¼ìš°ì € íƒ­ ì œëª©
    page_icon="ğŸ“š",                             # ë¸Œë¼ìš°ì € íƒ­ ì•„ì´ì½˜
    layout="wide",                              # ë„“ì€ ë ˆì´ì•„ì›ƒ ì‚¬ìš© ì„¤ì •
    initial_sidebar_state="expanded"            # ì‚¬ì´ë“œë°” ì´ˆê¸° í™•ì¥ ìƒíƒœ
)

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# st.session_stateëŠ” ì›¹ì‚¬ì´íŠ¸ë¥¼ ì´ìš©í•˜ëŠ” ë™ì•ˆ ë°ì´í„°ë¥¼ ì €ì¥í•˜ëŠ” ê³µê°„
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# ì—…ë¡œë“œëœ íŒŒì¼ ê²½ë¡œ ì €ì¥ ëª©ë¡
if "uploaded_files" not in st.session_state:
    st.session_state.uploaded_files = []

# ì²­í¬ëœ ë¬¸ì„œ ê°ì²´ ì €ì¥ ëª©ë¡
if "documents" not in st.session_state:
    st.session_state.documents = []

# FAISS ê²€ìƒ‰ ê°ì²´ (ì¸ë±ìŠ¤)
if "faiss_retriever" not in st.session_state:
    st.session_state.faiss_retriever = None

# íŒŒì¼ ë©”íƒ€ë°ì´í„° ê´€ë¦¬ ê°ì²´
if "file_metadata_manager" not in st.session_state:
    st.session_state.file_metadata_manager = FileMetadata()

# ê²€ìƒ‰ íˆìŠ¤í† ë¦¬ ê´€ë¦¬ ê°ì²´
if "search_history_manager" not in st.session_state:
    st.session_state.search_history_manager = SearchHistory()

# ì²­ì»¤ ì´ˆê¸°í™”
chunker = TextChunker(chunk_size=500, chunk_overlap=50)

# ì„ë² ë”© ìƒì„±ê¸° ì´ˆê¸°í™”
embedding_generator = EmbeddingGenerator()

# ê²€ì¦ê¸° ì´ˆê¸°í™”
file_validator = FileValidator(
    max_file_size_mb=200,                           # ìµœëŒ€ íŒŒì¼ í¬ê¸° (200MB)
    allowed_extensions=['.pdf', '.txt', '.md']      # í—ˆìš©ë˜ëŠ” íŒŒì¼ í™•ì¥ì ëª©ë¡ (PDF ì¶”ê°€)
)

query_validator = QueryValidator(
    min_length=2,           # ìµœì†Œ ê²€ìƒ‰ì–´ ê¸¸ì´
    max_length=500          # ìµœëŒ€ ê²€ìƒ‰ì–´ ê¸¸ì´
)

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# API í‚¤ ê²€ì¦
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
try:
    # API í‚¤ ìœ íš¨ì„± ê²€ì‚¬
    valid, error = APIKeyValidator.validate_api_keys()  # í‚¤ ê²€ì¦ í•¨ìˆ˜ í˜¸ì¶œ
    if not valid:
        st.error(f"ğŸš¨ {error}")  # ì˜¤ë¥˜ ë©”ì‹œì§€ í‘œì‹œ
        st.info("ğŸ’¡ `.env` íŒŒì¼ì—ì„œ API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”.")  # ì•ˆë‚´ ë©”ì‹œì§€ í‘œì‹œ
        st.stop()  # ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰ ì¤‘ì§€
except Exception as e:
    st.error(f"âŒ API í‚¤ ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {str(e)}")  # ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ì²˜ë¦¬
    st.stop()

# Document í´ë˜ìŠ¤ ì •ì˜
class SimpleDocument:
    """ê°„ë‹¨í•œ ë¬¸ì„œ í´ë˜ìŠ¤"""
    def __init__(self, page_content: str, metadata: dict = None):
        self.page_content = page_content
        self.metadata = metadata or {}

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ë©”ì¸ íƒ€ì´í‹€
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
st.title("ğŸ“š FlowNote MVP")         # ë©”ì¸ ì œëª©
st.markdown("AI ê¸°ë°˜ ë¬¸ì„œ ê²€ìƒ‰ ì‹œìŠ¤í…œ")  # ë³´ì¡° ì„¤ëª…

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ì‚¬ì´ë“œë°” (íŒŒì¼ ì—…ë¡œë“œ ë° ì²˜ë¦¬)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")  # ì„¤ì • ì„¹ì…˜ ì œëª©
    
    # íŒŒì¼ ì—…ë¡œë“œ ìœ„ì ¯
    uploaded_files = st.file_uploader(
        "ğŸ“ ë¬¸ì„œ ì—…ë¡œë“œ",                                  # íŒŒì¼ ì—…ë¡œë“œ ìœ„ì ¯ ë¼ë²¨
        type=["pdf", "txt", "md"],                      # í—ˆìš© íŒŒì¼ í˜•ì‹ (PDF, TXT, MD)
        accept_multiple_files=True,                     # ì—¬ëŸ¬ íŒŒì¼ ë™ì‹œ ì—…ë¡œë“œ í—ˆìš©
        help=f"ì§€ì› í˜•ì‹: PDF, TXT, MD\nìµœëŒ€ í¬ê¸°: {file_validator.max_file_size_mb}MB"
    )
    
    if uploaded_files:
        if st.button("ğŸ“¤ íŒŒì¼ ì²˜ë¦¬í•˜ê¸°", type="primary"):              # íŒŒì¼ ì²˜ë¦¬ ì‹œì‘ ë²„íŠ¼
            with st.spinner("íŒŒì¼ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):               # ì‘ì—… ì¤‘ ë¡œë”© ë©”ì‹œì§€
                try:
                    # ì„ì‹œ ì €ì¥ í´ë” ìƒì„±
                    os.makedirs("uploaded_files", exist_ok=True)    # íŒŒì¼ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
                    saved_files = []                                # ì €ì¥ ì„±ê³µ íŒŒì¼ ê²½ë¡œ ëª©ë¡
                    failed_files = []                               # ì²˜ë¦¬ ì‹¤íŒ¨ íŒŒì¼ ì´ë¦„ ëª©ë¡
                    
                    # íŒŒì¼ ì €ì¥ ë° ê²€ì¦
                    for uploaded_file in uploaded_files:
                        # íŒŒì¼ ì €ì¥ ê²½ë¡œ ì„¤ì •
                        file_path = os.path.join("uploaded_files", uploaded_file.name)
                        
                        try:
                            # íŒŒì¼ ì„ì‹œ ì €ì¥
                            with open(file_path, "wb") as f:
                                f.write(uploaded_file.getbuffer())                  # ì—…ë¡œë“œëœ íŒŒì¼ì˜ ë‚´ìš© ì“°ê¸°
                            
                            # íŒŒì¼ ìœ íš¨ì„± ê²€ì‚¬
                            valid, error = file_validator.validate_file(file_path)  # ìœ íš¨ì„± ê²€ì¦ ìˆ˜í–‰
                            if not valid:
                                st.warning(f"âš ï¸ {uploaded_file.name}: {error}")     # ê²½ê³  ë©”ì‹œì§€ í‘œì‹œ
                                os.remove(file_path)                                # ê²€ì¦ ì‹¤íŒ¨ íŒŒì¼ ì‚­ì œ
                                failed_files.append(uploaded_file.name)             # ì‹¤íŒ¨ ëª©ë¡ì— ì¶”ê°€
                                continue
                            
                            saved_files.append(file_path)                       # ì„±ê³µ ëª©ë¡ì— ì¶”ê°€
                            st.success(f"âœ… {uploaded_file.name} ê²€ì¦ ì™„ë£Œ")      # ì„±ê³µ ë©”ì‹œì§€ í‘œì‹œ
                            
                        except Exception as e:
                            st.error(f"âŒ {uploaded_file.name}: {str(e)}")      # íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜ ë©”ì‹œì§€
                            failed_files.append(uploaded_file.name)
                            if os.path.exists(file_path):
                                os.remove(file_path)                            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì„ì‹œ íŒŒì¼ ì‚­ì œ
                    
                    if not saved_files:
                        st.error("âŒ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")                 # ì²˜ë¦¬ ê°€ëŠ¥ íŒŒì¼ì´ ì—†ëŠ” ê²½ìš° ì˜¤ë¥˜
                        raise FileValidationError("ëª¨ë“  íŒŒì¼ ê²€ì¦ ì‹¤íŒ¨")
                    
                    # íŒŒì¼ ë‚´ìš© ì½ê¸° ë° ì²­í¬ ë¶„í• 
                    all_documents = []                                          # ì „ì²´ ë¬¸ì„œ ì²­í¬ ì €ì¥ ëª©ë¡
                    
                    for file_path in saved_files:
                        try:
                            file_name = os.path.basename(file_path)             # íŒŒì¼ ì´ë¦„ ì¶”ì¶œ
                            file_size = os.path.getsize(file_path)              # íŒŒì¼ í¬ê¸° ê°€ì ¸ì˜¤ê¸°
                            
                            # ì²˜ë¦¬ ìƒíƒœ ì •ë³´ í‘œì‹œ
                            st.info(f"ğŸ“„ {file_name} ì²˜ë¦¬ ì¤‘... ({format_file_size(file_size)})")
                            
                            # âœ¨ íŒŒì¼ ì½ê¸° (PDF/TXT/MD ìë™ ì²˜ë¦¬)
                            # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì‚¬ìš© â†’ íŒŒì¼ ë‚´ìš© ì½ê¸°
                            content = read_file_content(file_path)  
                            
                            if not content or not content.strip():
                                st.warning(f"âš ï¸ {file_name}: íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")   # ë‚´ìš©ì´ ì—†ëŠ” ê²½ìš° ê²½ê³ 
                                continue
                            
                            # í…ìŠ¤íŠ¸ ì²­í¬ ë¶„í• 
                            chunker = TextChunker()                              # ì²­í¬ ë¶„í•  ê°ì²´ ìƒì„±
                            chunks = chunker.chunk_text(content)                 # í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• 
                            
                            # Document ê°ì²´ ìƒì„± ë° ë©”íƒ€ë°ì´í„° ì¶”ê°€
                            for i, chunk in enumerate(chunks):
                                doc = {
                                    "content": chunk,  # ì²­í¬ ë‚´ìš©
                                    "metadata": {
                                        "source": file_name,                     # ì¶œì²˜ íŒŒì¼ ì´ë¦„
                                        "chunk_index": i,                        # ì²­í¬ ì¸ë±ìŠ¤ ë²ˆí˜¸
                                        "file_path": file_path,                  # ì›ë³¸ íŒŒì¼ ê²½ë¡œ
                                        "file_size": file_size,                  # ì›ë³¸ íŒŒì¼ í¬ê¸°
                                        "timestamp": datetime.now().isoformat()  # ì²˜ë¦¬ ì™„ë£Œ ì‹œê°„
                                    }
                                }
                                # ì „ì²´ ëª©ë¡ì— ì¶”ê°€
                                all_documents.append(doc)
                            
                            # ì²­í¬ ìƒì„± ì™„ë£Œ ë©”ì‹œì§€
                            st.success(f"âœ… {file_name}: {len(chunks)}ê°œ ì²­í¬ ìƒì„±")
                            
                        except Exception as e:
                            # íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ
                            st.error(f"âŒ {os.path.basename(file_path)} ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
                            continue
                    
                    if not all_documents:
                        st.error("âŒ ë¬¸ì„œë¥¼ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")                  # ì²­í¬ê°€ í•˜ë‚˜ë„ ì—†ëŠ” ê²½ìš°
                        raise ValueError("ë¬¸ì„œ ì²˜ë¦¬ ì‹¤íŒ¨")
                    
                    # ì„ë² ë”© ìƒì„±
                    st.info(f"ğŸ”„ {len(all_documents)}ê°œ ì²­í¬ ì„ë² ë”© ìƒì„± ì¤‘...")  # ì„ë² ë”© ìƒì„± ì‹œì‘ ë©”ì‹œì§€
                    
                    embedding_generator = EmbeddingGenerator()               # ì„ë² ë”© ìƒì„± ê°ì²´
                    texts = [doc["content"] for doc in all_documents]        # ëª¨ë“  ì²­í¬ ë‚´ìš©ë§Œ ì¶”ì¶œ
                    
                    # âœ¨ dictì—ì„œ ì„ë² ë”© ì¶”ì¶œ!
                    result = embedding_generator.generate_embeddings(texts)
                    embeddings = result["embeddings"]
                    
                    st.info(f"âœ… ì„ë² ë”© ìƒì„± ì™„ë£Œ (í† í°: {result['tokens']}, ë¹„ìš©: ${result['cost']:.6f})")
                    
                    # NumPy ë°°ì—´ë¡œ ë³€í™˜
                    embeddings_np = np.array(embeddings, dtype=np.float32)
                    
                    # FAISS ì¸ë±ìŠ¤ ìƒì„±
                    retriever = FAISSRetriever(dimension=len(embeddings[0]))
                    retriever.add_documents(embeddings_np, all_documents)
                    
                    # ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸ (ê²€ìƒ‰ì— ì‚¬ìš©ë  ë°ì´í„° ì €ì¥)
                    st.session_state.faiss_retriever = retriever            # FAISS ê°ì²´ ì €ì¥
                    st.session_state.documents = all_documents              # ì „ì²´ ë¬¸ì„œ ëª©ë¡ ì €ì¥
                    st.session_state.uploaded_files = saved_files           # ì—…ë¡œë“œ íŒŒì¼ ê²½ë¡œ ì €ì¥
                    
                    # âœ¨ ë©”íƒ€ë°ì´í„° ì €ì¥ (ìˆ˜ì •!)
                    # íŒŒì¼ë³„ë¡œ ì²­í¬ ê°œìˆ˜ ê³„ì‚°
                    file_chunk_counts = defaultdict(int)
                    file_info_map = {}                                      # íŒŒì¼ ì •ë³´ ì €ì¥
                    
                    for doc in all_documents:
                        source = doc["metadata"]["source"]
                        file_chunk_counts[source] += 1
                        
                        # íŒŒì¼ ì •ë³´ ì €ì¥ (ì²« ë²ˆì§¸ ì²­í¬ì—ì„œ)
                        if source not in file_info_map:
                            file_info_map[source] = {
                                "file_size": doc["metadata"]["file_size"]
                            }
                    
                    # íŒŒì¼ë³„ë¡œ í•œ ë²ˆë§Œ ë©”íƒ€ë°ì´í„° ì €ì¥
                    for source, chunk_count in file_chunk_counts.items():
                        st.session_state.file_metadata_manager.add_file(
                            file_name=source,
                            file_size=file_info_map[source]["file_size"],
                            chunk_count=chunk_count,
                            embedding_dim=len(embeddings[0]),
                            model="text-embedding-3-small"
                        )
                    
                    st.success(f"ğŸ‰ ì´ {len(all_documents)}ê°œ ì²­í¬ ì²˜ë¦¬ ì™„ë£Œ!")
                    st.info(f"ğŸ“Š íŒŒì¼ {len(file_chunk_counts)}ê°œ ë©”íƒ€ë°ì´í„° ì €ì¥ ì™„ë£Œ")
                    
                    if failed_files:
                        st.warning(f"âš ï¸ ì‹¤íŒ¨í•œ íŒŒì¼: {', '.join(failed_files)}")
                    
                except FileValidationError as e:
                    # íŒŒì¼ ê²€ì¦ ê´€ë ¨ ì˜¤ë¥˜
                    st.error(f"âŒ íŒŒì¼ ê²€ì¦ ì˜¤ë¥˜: {str(e)}")
                except Exception as e:
                    st.error(f"âŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                    import traceback
                    st.code(traceback.format_exc())
    
    # í˜„ì¬ ì—…ë¡œë“œëœ íŒŒì¼ ëª©ë¡ í‘œì‹œ
    if st.session_state.uploaded_files:
        st.markdown("---")
        st.subheader("ğŸ“‚ ì—…ë¡œë“œëœ íŒŒì¼")
        
        for file_path in st.session_state.uploaded_files:
            file_name = os.path.basename(file_path)                 # íŒŒì¼ ì´ë¦„
            file_size = os.path.getsize(file_path)                  # íŒŒì¼ í¬ê¸°
            st.text(f"ğŸ“„ {file_name}")
            st.caption(f"   í¬ê¸°: {format_file_size(file_size)}")    # ì½ê¸° ì‰¬ìš´ í¬ê¸° í¬ë§·
            
        # í†µê³„ ì¶”ê°€
        st.markdown("---")
        st.subheader("ğŸ“Š í†µê³„")

        # ë©”íŠ¸ë¦­ ì¹´ë“œ (2ì—´)
        col1, col2 = st.columns(2)
        
        with col1:
            st.metric(
                label="íŒŒì¼ ìˆ˜",
                value=len(st.session_state.uploaded_files),
                help="ì—…ë¡œë“œëœ íŒŒì¼ ê°œìˆ˜"
            )
        
        with col2:
            st.metric(
                label="ì²­í¬ ìˆ˜",
                value=len(st.session_state.documents) if st.session_state.documents else 0,
                help="ìƒì„±ëœ í…ìŠ¤íŠ¸ ì²­í¬ ê°œìˆ˜"
            )
        
        # ê²€ìƒ‰ í†µê³„
        if st.session_state.search_history_manager.history:
            total_searches = len(st.session_state.search_history_manager.history)
            st.metric(
                label="ê²€ìƒ‰ íšŸìˆ˜",
                value=total_searches,
                help="ì´ ê²€ìƒ‰ íšŸìˆ˜"
            )




# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ë©”ì¸ ì»¨í…ì¸  - ê²€ìƒ‰
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
if st.session_state.faiss_retriever is not None:
    # ê²€ìƒ‰ ì„¹ì…˜
    st.subheader("ğŸ” ë¬¸ì„œ ê²€ìƒ‰")
    
    col1, col2 = st.columns([4, 1])
    
    with col1:
        query = st.text_input(
            "ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”",
            placeholder="ì˜ˆ: í”„ë¡œì íŠ¸ ëª©í‘œê°€ ë¬´ì—‡ì¸ê°€ìš”?",
            help="ë¬¸ì„œì—ì„œ ì°¾ê³  ì‹¶ì€ ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”."
        )
    
    with col2:
        k = st.number_input("ê²°ê³¼ ìˆ˜", min_value=1, max_value=10, value=3)
    
    if st.button("ğŸ” ê²€ìƒ‰", type="primary"):
        # âœ¨ ì¿¼ë¦¬ ê²€ì¦
        valid, error = query_validator.validate_query(query)
        
        if not valid:
            st.warning(f"âš ï¸ {error}")
        else:
            with st.spinner("ê²€ìƒ‰ ì¤‘ì…ë‹ˆë‹¤..."):
                try:
                    # FAISS ê²€ìƒ‰
                    search_results = st.session_state.faiss_retriever.search(query, k=k)
                    
                    # ê²€ìƒ‰ íˆìŠ¤í† ë¦¬ ì €ì¥
                    st.session_state.search_history_manager.add_search(
                        query=query,
                        results_count=len(search_results)
                    )
                    
                    # ê²°ê³¼ í‘œì‹œ
                    st.success(f"âœ… {len(search_results)}ê°œ ê²°ê³¼ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                    
                    for i, result in enumerate(search_results, 1):
                        with st.expander(f"ğŸ“„ ê²°ê³¼ {i} - {result['metadata']['source']} (ìœ ì‚¬ë„: {result['score']:.2%})"):
                            st.markdown(f"**ë‚´ìš©:**\n{result['content']}")
                            st.caption(f"ì¶œì²˜: {result['metadata']['source']} (ì²­í¬ {result['metadata']['chunk_index']})")
                    
                except Exception as e:
                    st.error(f"âŒ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
                    import traceback
                    st.code(traceback.format_exc())

    # ê²€ìƒ‰ ì„¹ì…˜ ì•„ë˜ì— íˆìŠ¤í† ë¦¬ í‘œì‹œ
    if st.session_state.faiss_retriever is not None:
        st.markdown("---")
        st.subheader("ğŸ“œ ìµœê·¼ ê²€ìƒ‰ ê¸°ë¡")
        
        # ìµœê·¼ 10ê°œ ê²€ìƒ‰ ê¸°ë¡ ê°€ì ¸ì˜¤ê¸°
        recent_searches = st.session_state.search_history_manager.get_recent_searches(limit=10)
        
        if recent_searches:
            # í…Œì´ë¸” í˜•íƒœë¡œ í‘œì‹œ
            st.markdown("**ìµœê·¼ 10ê°œ ê²€ìƒ‰**")
            
            for search in recent_searches:
                # ê²€ìƒ‰ ì¹´ë“œ
                with st.container():
                    col1, col2, col3 = st.columns([3, 1, 2])
                    
                    with col1:
                        st.text(f"ğŸ” {search['query']}")
                    
                    with col2:
                        st.text(f"ê²°ê³¼: {search['results_count']}ê°œ")
                    
                    with col3:
                        # ì‹œê°„ í¬ë§·íŒ…
                        from datetime import datetime
                        timestamp = datetime.fromisoformat(search['created_at'])
                        st.caption(timestamp.strftime("%m/%d %H:%M"))
                    
                    st.markdown("---")
        else:
            st.info("ì•„ì§ ê²€ìƒ‰ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")

else:
    st.info(
        """ğŸ‘‹ **FlowNoteì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤!** ğŸ‘‹ 
        
        ì‹œì‘í•˜ë ¤ë©´:
        
            1. ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ PDF,TXT, MD íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”
            2. "íŒŒì¼ ì²˜ë¦¬í•˜ê¸°" ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”
            3. ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì—¬ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ì„¸ìš”
            
        ğŸ’¡ Tip! - ì—¬ëŸ¬ íŒŒì¼ì„ í•œ ë²ˆì— ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!
        """
        )


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# í‘¸í„°
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
st.divider()
st.caption("FlowNote MVP v2.0 | Made with â¤ï¸ by Jay")
