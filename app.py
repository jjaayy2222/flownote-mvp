# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# app.py (3rd)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

"""
FlowNote MVP - AI ëŒ€í™” ê´€ë¦¬ ë„êµ¬
ì‘ì„±ì: Jay Lee
ë‚ ì§œ: 2025.10.25
"""

import streamlit as st
from pathlib import Path
from datetime import datetime
import sys

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from backend.chunking import TextChunker
from backend.embedding import EmbeddingGenerator
from backend.faiss_search import FAISSRetriever
from backend.metadata import FileMetadata
from backend.search_history import SearchHistory

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# í˜ì´ì§€ ì„¤ì •
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

st.set_page_config(
    page_title="FlowNote MVP",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ì´ˆê¸°í™”
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

if 'retriever' not in st.session_state:
    st.session_state.retriever = FAISSRetriever()

if 'metadata' not in st.session_state:
    st.session_state.metadata = FileMetadata()

if 'history' not in st.session_state:
    st.session_state.history = SearchHistory()

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ì‚¬ì´ë“œë°”
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

with st.sidebar:
    st.title("ğŸ¤– FlowNote MVP")
    st.markdown("---")
    
    # íŒŒì¼ í†µê³„
    st.subheader("ğŸ“Š íŒŒì¼ í†µê³„")
    stats = st.session_state.metadata.get_statistics()
    
    col1, col2 = st.columns(2)
    with col1:
        st.metric("ì´ íŒŒì¼", f"{stats['total_files']}ê°œ")
        st.metric("ì´ ì²­í¬", f"{stats['total_chunks']}ê°œ")
    with col2:
        st.metric("ì´ ìš©ëŸ‰", f"{stats['total_size_mb']} MB")
        st.metric("ëª¨ë¸ ìˆ˜", f"{len(stats['models_used'])}ê°œ")
    
    st.markdown("---")
    
    # íŒŒì¼ ëª©ë¡
    st.subheader("ğŸ“ íŒŒì¼ ëª©ë¡")
    all_files = st.session_state.metadata.get_all_files()
    
    if all_files:
        for file_id, info in all_files.items():
            with st.expander(f"ğŸ“„ {info['file_name']}", expanded=False):
                st.write(f"**í¬ê¸°:** {info['file_size_mb']} MB")
                st.write(f"**ì²­í¬:** {info['chunk_count']}ê°œ")
                st.write(f"**ëª¨ë¸:** {info['embedding_model']}")
                st.write(f"**ì—…ë¡œë“œ:** {info['created_at']}")
    else:
        st.info("íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    st.markdown("---")
    
    # ê²€ìƒ‰ í†µê³„
    st.subheader("ğŸ” ê²€ìƒ‰ í†µê³„")
    search_stats = st.session_state.history.get_statistics()
    
    st.metric("ì´ ê²€ìƒ‰", f"{search_stats['total_searches']}íšŒ")
    if search_stats['most_common_query']:
        st.write(f"**ìì£¼ ê²€ìƒ‰:** {search_stats['most_common_query']}")

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ë©”ì¸ í˜ì´ì§€
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# íƒ­ ìƒì„±
tab1, tab2, tab3 = st.tabs(["ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ", "ğŸ” ê²€ìƒ‰", "ğŸ“Š íˆìŠ¤í† ë¦¬"])

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# íƒ­ 1: íŒŒì¼ ì—…ë¡œë“œ
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

with tab1:
    st.header("ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ")
    st.write("í…ìŠ¤íŠ¸ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ìë™ìœ¼ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤.")
    
    uploaded_file = st.file_uploader(
        "íŒŒì¼ ì„ íƒ",
        type=['txt', 'md'],
        help="í…ìŠ¤íŠ¸ íŒŒì¼ (txt, md)ì„ ì—…ë¡œë“œí•˜ì„¸ìš”."
    )
    
    if uploaded_file:
        if st.button("ğŸš€ ì²˜ë¦¬ ì‹œì‘", type="primary"):
            with st.spinner("íŒŒì¼ ì²˜ë¦¬ ì¤‘..."):
                # 1. íŒŒì¼ ì €ì¥
                content = uploaded_file.read().decode('utf-8')
                timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')
                file_path = Path(f"data/uploads/{timestamp}_{uploaded_file.name}")
                file_path.parent.mkdir(parents=True, exist_ok=True)
                file_path.write_text(content, encoding='utf-8')
                
                # 2. ì²­í‚¹
                chunker = TextChunker()
                chunks = chunker.chunk_text(content)
                
                # 3. ì„ë² ë”©
                embedder = EmbeddingGenerator()
                embeddings, token_count, cost = embedder.generate_embeddings(chunks)
                
                # 4. FAISS ì €ì¥
                st.session_state.retriever.add_documents(chunks, embeddings)
                
                # 5. ë©”íƒ€ë°ì´í„° ì €ì¥
                file_id = st.session_state.metadata.add_file(
                    file_name=uploaded_file.name,
                    file_size=uploaded_file.size,
                    chunk_count=len(chunks),
                    embedding_dim=len(embeddings[0])
                )
                
                st.success("âœ… ì²˜ë¦¬ ì™„ë£Œ!")
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("ì²­í¬ ìˆ˜", f"{len(chunks)}ê°œ")
                with col2:
                    st.metric("í† í° ìˆ˜", f"{token_count:,}")
                with col3:
                    st.metric("ë¹„ìš©", f"${cost:.6f}")

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# íƒ­ 2: ê²€ìƒ‰
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

with tab2:
    st.header("ğŸ” ê²€ìƒ‰")
    
    query = st.text_input(
        "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”",
        placeholder="ì˜ˆ: FlowNoteì˜ ì£¼ìš” ê¸°ëŠ¥ì€?"
    )
    
    col1, col2 = st.columns([3, 1])
    with col1:
        top_k = st.slider("ê²°ê³¼ ê°œìˆ˜", 1, 10, 3)
    with col2:
        search_button = st.button("ğŸ” ê²€ìƒ‰", type="primary")
    
    if search_button and query:
        with st.spinner("ê²€ìƒ‰ ì¤‘..."):
            # ê²€ìƒ‰ ìˆ˜í–‰
            results = st.session_state.retriever.search(query, top_k=top_k)
            
            # ê²€ìƒ‰ íˆìŠ¤í† ë¦¬ ì €ì¥
            top_results = [r['text'][:100] for r in results[:3]]
            st.session_state.history.add_search(
                query=query,
                results_count=len(results),
                top_results=top_results
            )
            
            # ê²°ê³¼ í‘œì‹œ
            st.success(f"âœ… {len(results)}ê°œ ê²°ê³¼ ë°œê²¬!")
            
            for i, result in enumerate(results, 1):
                with st.expander(f"#{i} - ìœ ì‚¬ë„: {result['score']:.4f}", expanded=(i==1)):
                    st.write(result['text'])

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# íƒ­ 3: íˆìŠ¤í† ë¦¬
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

with tab3:
    st.header("ğŸ“Š ê²€ìƒ‰ íˆìŠ¤í† ë¦¬")
    
    # ìµœê·¼ ê²€ìƒ‰ í‘œì‹œ
    recent_searches = st.session_state.history.get_recent_searches(limit=10)
    
    if recent_searches:
        for search in recent_searches:
            with st.expander(
                f"ğŸ” {search['query']} ({search['created_at']})",
                expanded=False
            ):
                st.write(f"**ê²°ê³¼ ìˆ˜:** {search['results_count']}ê°œ")
                if search['top_results']:
                    st.write("**ìƒìœ„ ê²°ê³¼:**")
                    for i, result in enumerate(search['top_results'], 1):
                        st.write(f"{i}. {result}")
    else:
        st.info("ê²€ìƒ‰ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    # íˆìŠ¤í† ë¦¬ ì‚­ì œ
    st.markdown("---")
    if st.button("ğŸ—‘ï¸ íˆìŠ¤í† ë¦¬ ì „ì²´ ì‚­ì œ", type="secondary"):
        st.session_state.history.clear_all()
        st.success("âœ… íˆìŠ¤í† ë¦¬ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤!")
        st.rerun()

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# Footer
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

st.markdown("---")
st.markdown(
    """
    <div style='text-align: center; color: gray;'>
        FlowNote MVP v1.0 | Made with â¤ï¸ by Jay
    </div>
    """,
    unsafe_allow_html=True
)



"""result



"""