# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# app.py (íŒŒì¼ ì—…ë¡œë“œ ì—ëŸ¬ í•¸ë“¤ë§ ì¶”ê°€)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

"""
FlowNote MVP - Streamlit UI
"""

import streamlit as st
import os
from datetime import datetime
import numpy as np

# backend í´ë˜ìŠ¤ ì„í¬íŠ¸
from backend.embedding import EmbeddingGenerator
from backend.chunking import TextChunker
from backend.faiss_search import FAISSRetriever
from backend.metadata import FileMetadata
from backend.search_history import SearchHistory

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="FlowNote",
    page_icon="ğŸ“š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "uploaded_files" not in st.session_state:
    st.session_state.uploaded_files = []
if "documents" not in st.session_state:
    st.session_state.documents = []
if "faiss_retriever" not in st.session_state:
    st.session_state.faiss_retriever = None
if "file_metadata_manager" not in st.session_state:
    st.session_state.file_metadata_manager = FileMetadata()
if "search_history_manager" not in st.session_state:
    st.session_state.search_history_manager = SearchHistory()

# ì²­ì»¤ ì´ˆê¸°í™”
chunker = TextChunker(chunk_size=500, chunk_overlap=50)

# ì„ë² ë”© ìƒì„±ê¸° ì´ˆê¸°í™”
embedding_generator = EmbeddingGenerator()


# Document í´ë˜ìŠ¤ ì •ì˜
class SimpleDocument:
    """ê°„ë‹¨í•œ ë¬¸ì„œ í´ë˜ìŠ¤"""
    def __init__(self, page_content: str, metadata: dict = None):
        self.page_content = page_content
        self.metadata = metadata or {}


# ë©”ì¸ UI
st.title("ğŸ“š FlowNote")
st.markdown("### AI ê¸°ë°˜ ë¬¸ì„œ ê²€ìƒ‰ ë° ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ")

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    
    # íŒŒì¼ ì—…ë¡œë“œ
    uploaded_files = st.file_uploader(
        "ğŸ“ ë¬¸ì„œ ì—…ë¡œë“œ (PDF/TXT)",
        type=["pdf", "txt"],
        accept_multiple_files=True,
        help="PDF ë˜ëŠ” TXT íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”."
    )
    
    if uploaded_files:
        if st.button("ğŸ“¤ íŒŒì¼ ì²˜ë¦¬í•˜ê¸°", type="primary"):
            with st.spinner("íŒŒì¼ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                try:
                    # íŒŒì¼ ì €ì¥
                    os.makedirs("uploaded_files", exist_ok=True)
                    saved_files = []
                    
                    for uploaded_file in uploaded_files:
                        file_path = os.path.join("uploaded_files", uploaded_file.name)
                        with open(file_path, "wb") as f:
                            f.write(uploaded_file.getbuffer())
                        saved_files.append(file_path)
                    
                    # ë¬¸ì„œ ë¡œë“œ ë° ì²­í¬ ë¶„í• 
                    all_texts = []
                    all_documents = []
                    
                    for file_path in saved_files:
                        # íŒŒì¼ ì½ê¸°
                        try:
                            with open(file_path, "r", encoding="utf-8") as f:
                                text = f.read()
                        except UnicodeDecodeError:
                            with open(file_path, "r", encoding="cp949") as f:
                                text = f.read()
                        
                        # ì²­í¬ ë¶„í• 
                        chunks_with_meta = chunker.chunk_with_metadata(
                            text, 
                            metadata={"source": os.path.basename(file_path)}
                        )
                        
                        for chunk in chunks_with_meta:
                            all_texts.append(chunk["text"])
                            all_documents.append(SimpleDocument(
                                page_content=chunk["text"],
                                metadata=chunk["metadata"]
                            ))
                        
                        # íŒŒì¼ ë©”íƒ€ë°ì´í„° ì €ì¥
                        file_size = os.path.getsize(file_path)
                        st.session_state.file_metadata_manager.add_file(
                            file_name=os.path.basename(file_path),
                            file_size=file_size,
                            chunk_count=len(chunks_with_meta),
                            embedding_dim=1536,
                            model="text-embedding-3-small"
                        )
                    
                    if all_texts:
                        # ì„ë² ë”© ìƒì„±
                        embed_result = embedding_generator.generate_embeddings(all_texts)
                        embeddings = embed_result['embeddings']
                        
                        # FAISS Retriever ìƒì„±
                        retriever = FAISSRetriever(dimension=1536)
                        retriever.add_documents(all_texts, embeddings)
                        
                        # ì„¸ì…˜ ìƒíƒœ ì €ì¥
                        st.session_state.documents = all_documents
                        st.session_state.uploaded_files = saved_files
                        st.session_state.faiss_retriever = retriever
                        
                        st.success(f"âœ… {len(uploaded_files)}ê°œ íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤!")
                        st.info(f"ğŸ“Š ì´ {len(all_documents)}ê°œì˜ ì²­í¬ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    else:
                        st.error("âŒ íŒŒì¼ ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                        
                except Exception as e:
                    st.error(f"âŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    
    st.divider()
    
    # ì—…ë¡œë“œëœ íŒŒì¼ ëª©ë¡
    if st.session_state.uploaded_files:
        st.subheader("ğŸ“‚ ì—…ë¡œë“œëœ íŒŒì¼")
        all_files = st.session_state.file_metadata_manager.get_all_files()
        
        for file_id, file_info in all_files.items():
            with st.expander(f"ğŸ“„ {file_info['file_name']}"):
                st.write(f"**í¬ê¸°:** {file_info['file_size_mb']} MB")
                st.write(f"**ì²­í¬ ìˆ˜:** {file_info['chunk_count']}")
                st.write(f"**ëª¨ë¸:** {file_info['embedding_model']}")
                st.write(f"**ì—…ë¡œë“œ:** {file_info['created_at']}")

# ë©”ì¸ ì»¨í…ì¸ 
if st.session_state.faiss_retriever is not None:
    # ê²€ìƒ‰ ì„¹ì…˜
    st.subheader("ğŸ” ë¬¸ì„œ ê²€ìƒ‰")
    
    col1, col2 = st.columns([4, 1])
    with col1:
        query = st.text_input(
            "ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”",
            placeholder="ì˜ˆ: í”„ë¡œì íŠ¸ ëª©í‘œê°€ ë¬´ì—‡ì¸ê°€ìš”?",
            help="ë¬¸ì„œì—ì„œ ì°¾ê³  ì‹¶ì€ ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”."
        )
    with col2:
        k = st.number_input("ê²°ê³¼ ìˆ˜", min_value=1, max_value=10, value=3)
    
    if st.button("ğŸ” ê²€ìƒ‰", type="primary"):
        if query:
            with st.spinner("ê²€ìƒ‰ ì¤‘ì…ë‹ˆë‹¤..."):
                try:
                    # FAISS ê²€ìƒ‰
                    search_results = st.session_state.faiss_retriever.search(query, k=k)
                    
                    if search_results:
                        # ë¬¸ì„œì™€ ìœ ì‚¬ë„ ë§¤ì¹­
                        results = []
                        result_texts = []
                        
                        for result in search_results:
                            # í…ìŠ¤íŠ¸ë¡œ ë¬¸ì„œ ì°¾ê¸°
                            for doc in st.session_state.documents:
                                if doc.page_content == result['text']:
                                    results.append((doc, result['similarity']))
                                    result_texts.append(doc.page_content[:100])
                                    break
                        
                        # ê²€ìƒ‰ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
                        st.session_state.search_history_manager.add_search(
                            query=query,
                            results_count=len(results),
                            top_results=result_texts
                        )
                        
                        st.success(f"âœ… {len(results)}ê°œì˜ ê²°ê³¼ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
                        
                        # ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ
                        for i, (doc, score) in enumerate(results, 1):
                            with st.expander(f"ğŸ“„ ê²°ê³¼ {i} (ìœ ì‚¬ë„: {score:.2%})"):
                                st.markdown(f"**ë‚´ìš©:**\n{doc.page_content}")
                                st.markdown(f"**ì¶œì²˜:** {doc.metadata.get('source', 'Unknown')}")
                    else:
                        st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        
                except Exception as e:
                    st.error(f"âŒ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        else:
            st.warning("âš ï¸ ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    # ê²€ìƒ‰ íˆìŠ¤í† ë¦¬
    st.divider()
    st.subheader("ğŸ“Š ê²€ìƒ‰ íˆìŠ¤í† ë¦¬")
    
    recent_searches = st.session_state.search_history_manager.get_recent_searches(limit=10)
    
    if recent_searches:
        col1, col2 = st.columns([3, 1])
        with col2:
            if st.button("ğŸ—‘ï¸ íˆìŠ¤í† ë¦¬ ì‚­ì œ"):
                st.session_state.search_history_manager.clear_all()
                st.rerun()
        
        for search in recent_searches:
            with st.expander(f"ğŸ• {search['created_at']} - {search['query']}"):
                st.markdown(f"**ê²€ìƒ‰ì–´:** {search['query']}")
                st.markdown(f"**ê²°ê³¼ ìˆ˜:** {search['results_count']}")
                
                if search['top_results']:
                    st.markdown("**ìƒìœ„ ê²°ê³¼:**")
                    for result in search['top_results']:
                        st.markdown(f"- {result}")
    else:
        st.info("ê²€ìƒ‰ íˆìŠ¤í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")

else:
    # ì´ˆê¸° í™”ë©´
    st.info(
        """
        ğŸ‘‹ **FlowNoteì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤!**
        
        ì‹œì‘í•˜ë ¤ë©´:
        1. ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ PDF ë˜ëŠ” TXT íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”
        2. "íŒŒì¼ ì²˜ë¦¬í•˜ê¸°" ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”
        3. ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì—¬ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ì„¸ìš”
        
        ğŸ’¡ **íŒ:** ì—¬ëŸ¬ íŒŒì¼ì„ í•œ ë²ˆì— ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!
        """
    )



# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# í‘¸í„°
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
st.divider()
st.caption("FlowNote MVP v1.1 | Made with â¤ï¸ by Jay")
