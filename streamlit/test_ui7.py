# streamlit/test_ui6.py

"""
FlowNote í†µí•© UI - ì˜¨ë³´ë”© í”Œë¡œìš° ì¶”ê°€
- main
    - tab1 : ì˜¨ë³´ë”© â†’ ì„ íƒ ì˜ì—­ì„ 10ê°œë¡œ ëŠ˜ë¦¬ê³  ì‚¬ìš©ìê°€ 5ê°œë¥¼ ì„ íƒí•˜ë„ë¡ í•˜ê¸° 
    - tab2 : íŒŒì¼ ì—…ë¡œë“œ & ë¶„ë¥˜
    - tab3 : í‚¤ì›Œë“œ ê²€ìƒ‰
    - tab4 : íŒŒì¼ í†µê³„ (â† tab2ì˜ ì •ë³´ ì‹¤ì‹œê°„ ë°˜ì˜ë˜ë„ë¡ ìˆ˜ì •)
    - tab5 : ë©”íƒ€ë°ì´í„° + ì‚¬ìš©ì ì •ë³´ ê¸°ë°˜ í•„í„°ë§ ì¶”ê°€
- ì‚¬ì´ë“œë°”
    - ì˜¨ë³´ë”© ìƒíƒœ ì¶”ê°€
    - ë¶„ë¥˜ íˆìŠ¤í† ë¦¬
"""

import requests 
import os
import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent.parent 
sys.path.insert(0, str(project_root))

# Streamlit + í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
import streamlit as st
from dotenv import load_dotenv

# ë¡œì»¬ì—ì„œëŠ” .env ë¡œë“œ
load_dotenv()

# ë°°í¬ í™˜ê²½ì—ì„œëŠ” Streamlit Secrets ë¡œë“œ
try:
    if hasattr(st, 'secrets') and len(st.secrets) > 0:
        for key in ["EMBEDDING_API_KEY", "EMBEDDING_BASE_URL", "EMBEDDING_MODEL",
                    "EMBEDDING_LARGE_API_KEY", "EMBEDDING_LARGE_BASE_URL", "EMBEDDING_LARGE_MODEL",
                    "GPT4O_API_KEY", "GPT4O_BASE_URL", "GPT4O_MODEL",
                    "GPT4O_MINI_API_KEY", "GPT4O_MINI_BASE_URL", "GPT4O_MINI_MODEL",
                    "GPT41_API_KEY", "GPT41_BASE_URL", "GPT41_MODEL"]:
            if key in st.secrets:
                os.environ[key] = st.secrets[key]
except:
    pass

from datetime import datetime
import json
import pandas as pd
import numpy as np

# Backend ì„í¬íŠ¸
from backend.embedding import EmbeddingGenerator
from backend.chunking import TextChunker
from backend.faiss_search import FAISSRetriever
from backend.metadata import FileMetadata
from backend.search_history import SearchHistory
from backend.classifier.para_classifier import PARAClassifier
from backend.validators import FileValidator
from backend.exceptions import FileValidationError
from backend.classifier.para_agent_wrapper import run_para_agent_sync
from backend.database.metadata_schema import ClassificationMetadataExtender
from backend.database.connection import DatabaseConnection
from backend.utils import format_file_size, load_pdf
from backend.export import MarkdownExporter
from backend.modules import extract_text_from_pdf
from backend.data_manager import DataManager

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="FlowNote í†µí•© UI í…ŒìŠ¤íŠ¸",
    page_icon="ğŸ“š",
    layout="wide"
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "classification_history" not in st.session_state:
    st.session_state.classification_history = []

if "db_extender" not in st.session_state:
    st.session_state.db_extender = ClassificationMetadataExtender()

# ì˜¨ë³´ë”© í”Œë¡œìš°ìš© ì„¸ì…˜ ìƒíƒœ
if "onboarding_step" not in st.session_state:
    st.session_state.onboarding_step = 1

if "onboarding_user_id" not in st.session_state:
    st.session_state.onboarding_user_id = None

if "onboarding_name" not in st.session_state:
    st.session_state.onboarding_name = ""

if "onboarding_occupation" not in st.session_state:
    st.session_state.onboarding_occupation = ""

if "suggested_areas" not in st.session_state:
    st.session_state.suggested_areas = []

if "selected_areas" not in st.session_state:
    st.session_state.selected_areas = []


# íŒŒì¼ ì €ì¥ ì •ì˜ í•¨ìˆ˜
def save_to_para_folder(filename, content, category):
    base_path = Path("data/exports")
    category_path = base_path / category
    category_path.mkdir(parents=True, exist_ok=True)
    file_path = category_path / filename
    with open(file_path, 'w', encoding='utf-8') as f:
        f.write(content)
    return str(file_path)


# ==========================
# íƒ€ì´í‹€
# ==========================

st.title("ğŸ“š FlowNote í†µí•© í…ŒìŠ¤íŠ¸ UI")
st.markdown("**ì˜¨ë³´ë”© â†’ ë¶„ë¥˜ â†’ í‚¤ì›Œë“œ ê²€ìƒ‰ â†’ í†µê³„ â†’ ë©”íƒ€ë°ì´í„°**")


# ==========================
# ì‚¬ì´ë“œë°”: ë¶„ë¥˜ íˆìŠ¤í† ë¦¬ ë“±
# ==========================
with st.sidebar:
    st.title("ğŸ“ FlowNote-mvp-ver.3.5")
    st.markdown("---")

    st.header("ğŸ‘¤ ì‚¬ìš©ì ì •ë³´")
    
    if st.session_state.onboarding_step == 3:
        st.success("âœ… ì˜¨ë³´ë”© ì™„ë£Œ")
        st.write(f"ì´ë¦„: {st.session_state.onboarding_name}")
        st.write(f"ì§ì—…: {st.session_state.onboarding_occupation}")
        st.write(f"User ID: {st.session_state.onboarding_user_id[:12]}...")
        st.write("**ì„ íƒí•œ Areas:**")
        for area in st.session_state.selected_areas:
            st.write(f"- {area}")
        
    else:
        st.warning("âš ï¸ ì˜¨ë³´ë”© í•„ìš”")
        st.info("Tab1ì—ì„œ ì˜¨ë³´ë”©ì„ ì™„ë£Œí•˜ì„¸ìš”")

    st.divider()

    # ë¶„ë¥˜ íˆìŠ¤í† ë¦¬
    st.header("ğŸ“Š ë¶„ë¥˜ íˆìŠ¤í† ë¦¬")
    if st.session_state.classification_history:
        st.metric("ì´ ë¶„ë¥˜ íŒŒì¼", len(st.session_state.classification_history))
        with st.expander("ìµœê·¼ ë¶„ë¥˜ ê²°ê³¼", expanded=True):
            for idx, item in enumerate(reversed(st.session_state.classification_history[-5:]), 1):
                st.markdown(f"**{idx}. {item['filename']}**")
                st.caption(f"ì¹´í…Œê³ ë¦¬: {item['category']} ({item['confidence']:.0%})")
                st.caption(f"ì‹œê°„: {item['timestamp']}")
        if st.button("ì´ˆê¸°í™”", key="clear_history"):
            st.session_state.classification_history = []
            st.rerun()
    else:
        st.info("ì•„ì§ ë¶„ë¥˜ëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")


# ==========================
# main (tab1, 2, 3, 4, 5)
# ==========================
tab1, tab2, tab3, tab4, tab5 = st.tabs([
    "ğŸš€ ì˜¨ë³´ë”©",
    "ğŸ“¤ íŒŒì¼ ë¶„ë¥˜",
    "ğŸ” í‚¤ì›Œë“œ ê²€ìƒ‰",
    "ğŸ¯ ë¶„ë¥˜ í†µê³„",
    "ğŸ“Š ë©”íƒ€ë°ì´í„°"
])


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# TAB 1: ì˜¨ë³´ë”©
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# TAB 1: ì˜¨ë³´ë”© (ì™„ì „ ìˆ˜ì • ë²„ì „)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with tab1:
    st.header("ğŸš€ ì˜¨ë³´ë”©: Areas ì¶”ì²œ ë° ì„ íƒ")
    
    # onboarding_step ì´ˆê¸°í™”
    if "onboarding_step" not in st.session_state:
        st.session_state.onboarding_step = 1
    
    
    # ============================================
    # Step 1: ê¸°ë³¸ ì •ë³´ ì…ë ¥
    # ============================================
    if st.session_state.onboarding_step == 1:
        st.subheader("Step 1: ê¸°ë³¸ ì •ë³´ ì…ë ¥")
        st.markdown("ì´ë¦„ê³¼ ì§ì—…ì„ ì…ë ¥í•˜ë©´, GPT-4oê°€ ë‹¹ì‹ ì˜ ì§ì—…ì— ë§ëŠ” **10ê°œì˜ Areas**ë¥¼ ì¶”ì²œí•´ ë“œë¦½ë‹ˆë‹¤.")
        
        with st.form("step1_form"):
            name = st.text_input(
                "ì´ë¦„", 
                value=st.session_state.onboarding_name, 
                placeholder="ì˜ˆ: Jay"
            )
            occupation = st.text_input(
                "ì§ì—…", 
                value=st.session_state.onboarding_occupation, 
                placeholder="ì˜ˆ: ê°œë°œì, ë””ìì´ë„ˆ, êµì‚¬"
            )
            submitted = st.form_submit_button("ë‹¤ìŒ ë‹¨ê³„ â†’", use_container_width=True, type="primary")
            
            if submitted:
                if not name or not occupation:
                    st.error("âš ï¸ ì´ë¦„ê³¼ ì§ì—…ì„ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                else:
                    with st.spinner("GPT-4oê°€ Areasë¥¼ ì¶”ì²œ ì¤‘ì…ë‹ˆë‹¤..."):
                        try:
                            # 1) ì‚¬ìš©ì ì •ë³´ ì €ì¥ ë° user_id ìƒì„±
                            response1 = requests.post(
                                "http://127.0.0.1:8000/api/onboarding/step1",
                                json={"occupation": occupation, "name": name},
                            )
                            
                            if response1.status_code == 200:
                                result1 = response1.json()
                                user_id = result1.get("user_id")
                                
                                if not user_id:
                                    st.error("âŒ ìœ ì € ì•„ì´ë””ë¥¼ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                                else:
                                    # 2) ì˜ì—­ ì¶”ì²œ API í˜¸ì¶œ
                                    response2 = requests.get(
                                        f"http://127.0.0.1:8000/api/onboarding/suggest-areas",
                                        params={"user_id": user_id, "occupation": occupation}
                                    )
                                    
                                    if response2.status_code == 200:
                                        result2 = response2.json()
                                        
                                        # ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
                                        st.session_state.onboarding_name = name
                                        st.session_state.onboarding_occupation = occupation
                                        st.session_state.onboarding_user_id = user_id
                                        st.session_state.suggested_areas = result2.get("suggested_areas", [])
                                        
                                        # Step 2ë¡œ ì´ë™
                                        st.session_state.onboarding_step = 2
                                        st.rerun()
                                    else:
                                        st.error(f"âŒ ì˜ì—­ ì¶”ì²œ API ì‹¤íŒ¨: {response2.status_code}")
                            else:
                                st.error(f"âŒ ì‚¬ìš©ì ì •ë³´ ì €ì¥ API ì‹¤íŒ¨: {response1.status_code}")
                                
                        except Exception as e:
                            st.error(f"âŒ API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
                            st.exception(e)
    
    
    # ============================================
    # Step 2: ê´€ì‹¬ ì˜ì—­ ì„ íƒ
    # ============================================
    elif st.session_state.onboarding_step == 2:
        st.subheader("Step 2: ê´€ì‹¬ ì˜ì—­ ì„ íƒ")
        st.markdown(f"**{st.session_state.onboarding_name}ë‹˜**, GPT-4oê°€ ì¶”ì²œí•œ Areas ì¤‘ **ì •í™•íˆ 5ê°œ**ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
        
        # ì¶”ì²œëœ areas
        suggested = st.session_state.suggested_areas
        
        if len(suggested) < 5:
            st.warning(f"âš ï¸ ì¶”ì²œëœ Areasê°€ 5ê°œ ë¯¸ë§Œì…ë‹ˆë‹¤ ({len(suggested)}ê°œ). GPT-4o ì‘ë‹µì„ í™•ì¸í•˜ì„¸ìš”.")
        
        # ì˜ì—­ ì„ íƒ (multiselect)
        selected = st.multiselect(
            f"ì¶”ì²œëœ Areas ({len(suggested)}ê°œ)",
            options=suggested,
            default=[],
            help="ì •í™•íˆ 5ê°œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”"
        )
        
        # ì„ íƒ ê°œìˆ˜ í‘œì‹œ
        if len(selected) < 5:
            st.info(f"ğŸ“Š í˜„ì¬ ì„ íƒëœ ê°œìˆ˜: {len(selected)}/5 (ì•„ì§ {5 - len(selected)}ê°œ ë” í•„ìš”)")
        elif len(selected) == 5:
            st.success(f"âœ… ì •í™•íˆ 5ê°œë¥¼ ì„ íƒí–ˆìŠµë‹ˆë‹¤!")
        else:
            st.warning(f"âš ï¸ {len(selected)}ê°œë¥¼ ì„ íƒí–ˆìŠµë‹ˆë‹¤. ì •í™•íˆ 5ê°œë§Œ ì„ íƒí•´ì£¼ì„¸ìš”.")
        
        # ğŸ”¥ ë²„íŠ¼ ì„¹ì…˜
        st.divider()
        
        col1, col2 = st.columns([1, 3])
        
        with col1:
            if st.button("â† ì´ì „", use_container_width=True, key="step2_prev"):
                st.session_state.onboarding_step = 1
                st.rerun()
        
        with col2:
            # 5ê°œ ì„ íƒ ì—¬ë¶€ì— ë”°ë¼ ë²„íŠ¼ ìŠ¤íƒ€ì¼ ë³€ê²½
            button_type = "primary" if len(selected) == 5 else "secondary"
            
            if st.button(
                "ì™„ë£Œ â†’", 
                use_container_width=True, 
                type=button_type,
                key="step2_next"
            ):
                # ğŸ”¥ 5ê°œ ì„ íƒ ì—¬ë¶€ í™•ì¸ (ë²„íŠ¼ í´ë¦­ ì‹œ)
                if len(selected) != 5:
                    st.error(f"âš ï¸ ì •í™•íˆ 5ê°œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”! (í˜„ì¬: {len(selected)}ê°œ)")
                    st.stop()  # ì—¬ê¸°ì„œ ì‹¤í–‰ ì¤‘ë‹¨
                
                # ğŸ”¥ user_id í™•ì¸
                if not st.session_state.onboarding_user_id:
                    st.error("âŒ ì‚¬ìš©ì IDê°€ ì—†ìŠµë‹ˆë‹¤. Step 1ë¶€í„° ë‹¤ì‹œ ì‹œì‘í•´ì£¼ì„¸ìš”.")
                    st.session_state.onboarding_step = 1
                    st.rerun()
                
                # 5ê°œ ì„ íƒëœ ê²½ìš°ì—ë§Œ API í˜¸ì¶œ
                with st.spinner("ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ë¥¼ ì €ì¥ ì¤‘ì…ë‹ˆë‹¤..."):
                    try:
                        # ğŸ”¥ user_id í¬í•¨í•œ payload êµ¬ì„±
                        payload = {
                            "user_id": st.session_state.onboarding_user_id,
                            "name": st.session_state.onboarding_name,
                            "occupation": st.session_state.onboarding_occupation,
                            "selected_areas": selected
                        }
                        
                        # ë””ë²„ê¹…ìš© ì¶œë ¥ (ì„ íƒì‚¬í•­)
                        with st.expander("ğŸ” ì „ì†¡ ë°ì´í„° í™•ì¸"):
                            st.json(payload)
                        
                        # API í˜¸ì¶œ: /api/onboarding/save-context
                        response = requests.post(
                            "http://127.0.0.1:8000/api/onboarding/save-context",
                            json=payload
                        )
                        
                        if response.status_code == 200:
                            result = response.json()
                            st.session_state.onboarding_user_id = result.get("user_id", "")
                            st.session_state.selected_areas = selected
                            st.session_state.onboarding_step = 3
                            st.success("âœ… ì˜¨ë³´ë”©ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                            st.balloons()  # ğŸˆ ì¶•í•˜ ì• ë‹ˆë©”ì´ì…˜
                            st.rerun()
                        else:
                            st.error(f"âŒ API ì˜¤ë¥˜: {response.status_code}")
                            with st.expander("ì˜¤ë¥˜ ìƒì„¸ ì •ë³´"):
                                st.code(response.text)
                                
                    except Exception as e:
                        st.error(f"âŒ API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
                        st.exception(e)
            
            # ì•ˆë‚´ ë©”ì‹œì§€
            if len(selected) != 5:
                st.caption("ğŸ’¡ ì •í™•íˆ 5ê°œë¥¼ ì„ íƒí•œ í›„ 'ì™„ë£Œ' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")
    
    
    # ============================================
    # Step 3: ì˜¨ë³´ë”© ì™„ë£Œ
    # ============================================
    elif st.session_state.onboarding_step == 3:
        st.subheader("ğŸ‰ ì˜¨ë³´ë”©ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        
        st.success(f"**{st.session_state.onboarding_name}ë‹˜**ì˜ ì„¤ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # ì‚¬ìš©ì ì •ë³´ í‘œì‹œ
        col1, col2 = st.columns(2)
        
        with col1:
            st.metric("ì´ë¦„", st.session_state.onboarding_name)
            st.metric("ì§ì—…", st.session_state.onboarding_occupation)
        
        with col2:
            st.metric("User ID", st.session_state.onboarding_user_id[:12] + "...")
            st.metric("ì„ íƒ ì˜ì—­", f"{len(st.session_state.selected_areas)}ê°œ")
        
        # ì„ íƒí•œ ì˜ì—­ í‘œì‹œ
        st.divider()
        st.markdown("### ğŸ“‹ ì„ íƒí•œ ê´€ì‹¬ ì˜ì—­")
        
        for i, area in enumerate(st.session_state.selected_areas, 1):
            st.markdown(f"{i}. **{area}**")
        
        # ë‹¤ì‹œí•˜ê¸° ë²„íŠ¼
        st.divider()
        
        if st.button("ğŸ”„ ì˜¨ë³´ë”© ë‹¤ì‹œí•˜ê¸°", use_container_width=True):
            # ëª¨ë“  ì˜¨ë³´ë”© ìƒíƒœ ì´ˆê¸°í™”
            st.session_state.onboarding_step = 1
            st.session_state.onboarding_user_id = None
            st.session_state.onboarding_name = ""
            st.session_state.onboarding_occupation = ""
            st.session_state.suggested_areas = []
            st.session_state.selected_areas = []
            st.rerun()
        
        st.info("ğŸ’¡ ì´ì œ **Tab 2: íŒŒì¼ ë¶„ë¥˜**ë¡œ ì´ë™í•˜ì—¬ ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•´ë³´ì„¸ìš”!")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# TAB 2: íŒŒì¼ ë¶„ë¥˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with tab2:
    st.header("ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ & ìë™ ë¶„ë¥˜")
    
    # âœ… ì˜¨ë³´ë”© ì™„ë£Œ ì—¬ë¶€ í™•ì¸
    onboarding_complete = (
        st.session_state.onboarding_step == 3 and
        st.session_state.onboarding_user_id is not None
    )
    
    if not onboarding_complete:
        st.warning("âš ï¸ ë¨¼ì € ì˜¨ë³´ë”©ì„ ì™„ë£Œí•´ì£¼ì„¸ìš”! (Tab1)")
        st.info("ì˜¨ë³´ë”©ì„ ì™„ë£Œí•˜ë©´ ë‹¹ì‹ ì˜ ë§¥ë½ì— ë§ëŠ” ì •í™•í•œ ë¶„ë¥˜ë¥¼ ì œê³µí•©ë‹ˆë‹¤.")
        st.stop()
    
    # âœ… ì˜¨ë³´ë”© ì •ë³´ í‘œì‹œ
    with st.expander("ğŸ‘¤ í˜„ì¬ ì‚¬ìš©ì ì •ë³´", expanded=False):
        st.write(f"**ì´ë¦„:** {st.session_state.onboarding_name}")
        st.write(f"**ì§ì—…:** {st.session_state.onboarding_occupation}")
        st.write(f"**User ID:** {st.session_state.onboarding_user_id}")
        st.write(f"**ê´€ì‹¬ ì˜ì—­:**")
        for area in st.session_state.selected_areas:
            st.write(f" - {area}")
    
    uploaded_file = st.file_uploader(
        "ë¶„ë¥˜í•  íŒŒì¼ ì—…ë¡œë“œ", type=['pdf', 'txt', 'md'], key="file_uploader_tab2"
    )
    
    if uploaded_file:
        # íŒŒì¼ ì •ë³´ ì„¹ì…˜ - ì „ì²´ ë„ˆë¹„
        st.markdown("### ğŸ“„ íŒŒì¼ ì •ë³´")
        
        col1, col2, col3 = st.columns(3)  # 3ë“±ë¶„ì€ ìœ ì§€í•˜ë˜
        with col1:
            st.metric("íŒŒì¼ëª…", uploaded_file.name)
        with col2:
            st.metric("íŒŒì¼ í¬ê¸°", f"{uploaded_file.size / 1024:.2f} KB")
        with col3:
            st.metric("íŒŒì¼íƒ€ì…", uploaded_file.type.split('/')[-1].upper())

        # êµ¬ë¶„ì„  ì¶”ê°€
        st.divider()
        
        # ë²„íŠ¼ ì¤‘ì•™ ì •ë ¬í•˜ê¸°
        _, col_center, _ = st.columns([1, 1, 1])
        with col_center:
            classify_btn = st.button(
                "ğŸš€ ë¶„ë¥˜ ì‹œì‘",
                key="classify_btn_tab2",
                use_container_width=True,       # ì»¬ëŸ¼ ë„ˆë¹„ì— ë§ì¶¤
                type="primary"
            )
        # ë¶„ë¥˜ ë²„íŠ¼ (API í˜¸ì¶œ ë°©ì‹ìœ¼ë¡œ ë³€ê²½!
        if classify_btn:
            with st.spinner("AI ë¶„ì„ ì¤‘... (ì‚¬ìš©ì ë§¥ë½ ë°˜ì˜)"):
                try:
                    # ============================================================
                    # ğŸ”¥ FastAPI /file ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œ (ì™„ì „ ìˆ˜ì •!)
                    # ============================================================
                    # 1. íŒŒì¼ ì¤€ë¹„
                    file_bytes = uploaded_file.getvalue()
                    files = {
                        "file": (uploaded_file.name, file_bytes, uploaded_file.type)
                    }
                    
                    # 2. ë°ì´í„° ì¤€ë¹„ (form-dataë¡œ ì „ì†¡)
                    data = {
                        "user_id": st.session_state.onboarding_user_id,
                    }
                    
                    # 3. API í˜¸ì¶œ
                    response = requests.post(
                        "http://127.0.0.1:8000/api/classifier/file",
                        files=files,
                        data=data
                    )
                    
                    # 4. ì‘ë‹µ ì²˜ë¦¬
                    if response.status_code == 200:
                        classification_result = response.json()
                        
                        # 5. íˆìŠ¤í† ë¦¬ ì €ì¥
                        history_item = {
                            "filename": uploaded_file.name,
                            "category": classification_result.get('category', 'Unknown'),
                            "confidence": classification_result.get('confidence', 0),
                            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                            "user_id": st.session_state.onboarding_user_id,
                            "context_injected": classification_result.get('context_injected', False)
                        }
                        st.session_state.classification_history.append(history_item)
                        
                        # 6. ê²°ê³¼ í‘œì‹œ
                        st.success("âœ… ë¶„ë¥˜ ì™„ë£Œ!")
                        col1, col2 = st.columns(2)
                        with col1:
                            st.metric("ì¹´í…Œê³ ë¦¬", classification_result.get('category', 'N/A'))
                            st.metric("ì‹ ë¢°ë„", f"{classification_result.get('confidence', 0):.0%}")
                        with col2:
                            st.metric("ë§¥ë½ ë°˜ì˜",
                                "âœ… ë°˜ì˜ë¨" if classification_result.get('context_injected') else "âŒ ë¯¸ë°˜ì˜")
                            keyword_tags = classification_result.get('keyword_tags', [])
                            st.metric("í‚¤ì›Œë“œ ìˆ˜", len(keyword_tags))
                            
                        # 7. ìƒì„¸ ì •ë³´
                        with st.expander("ğŸ“Š ìƒì„¸ ë¶„ë¥˜ ì •ë³´", expanded=True):
                            st.json(classification_result)
                        
                    else:
                        st.error(f"âŒ API ì˜¤ë¥˜: {response.status_code}")
                        st.code(response.text)
                    
                except Exception as e:
                    st.error(f"âŒ ë¶„ë¥˜ ì‹¤íŒ¨: {str(e)}")
                    st.exception(e)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# TAB 3: í‚¤ì›Œë“œ ê²€ìƒ‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

with tab3:
    st.header("ğŸ” í‚¤ì›Œë“œ ê²€ìƒ‰")
    
    uploaded_files = st.file_uploader(
        "ë¬¸ì„œ ì—…ë¡œë“œ (PDF, TXT, MD)",
        type=['pdf', 'txt', 'md'],
        accept_multiple_files=True
    )
    
    if uploaded_files and st.button("ğŸ“„ íŒŒì¼ ì²˜ë¦¬"):
        doc_list = []
        
        with st.status("íŒŒì¼ ì²˜ë¦¬ ì¤‘...", expanded=True) as status:
            for uploaded_file in uploaded_files:
                try:
                    if uploaded_file.type == "application/pdf":
                        content = load_pdf(uploaded_file)
                    else:
                        content = uploaded_file.read().decode('utf-8')
                    
                    doc_list.append({
                        'name': uploaded_file.name,
                        'content': content,
                        'size': uploaded_file.size,
                        'type': uploaded_file.type
                    })
                    
                except Exception as e:
                    st.error(f"âŒ {uploaded_file.name} ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
                    continue
            
            if doc_list:
                st.write("ğŸ“Š í…ìŠ¤íŠ¸ ë¶„ì„ ì¤‘...")
                chunker = TextChunker()
                all_chunks = []
                chunk_metadata = []
                
                for doc in doc_list:
                    chunks = chunker.chunk_text(doc['content'])
                    all_chunks.extend(chunks)
                    for chunk in chunks:
                        chunk_metadata.append({
                            'filename': doc['name'],
                            'file_type': doc['type'],
                            # í•„ìš”í•˜ë‹¤ë©´ ì¶”ê°€ ë©”íƒ€ë°ì´í„°ë„ ë„£ê¸°
                        })
                
                st.write("ğŸ”® ì„ë² ë”© ìƒì„± ì¤‘...")
                embedder = EmbeddingGenerator()
                result = embedder.generate_embeddings(all_chunks)
                
                embeddings_list = result['embeddings']
                embeddings_array = np.array(embeddings_list)
                
                st.write("ğŸ” ê²€ìƒ‰ ì¸ë±ìŠ¤ êµ¬ì¶• ì¤‘...")
                                
                retriever = FAISSRetriever(dimension=embeddings_array.shape[1])
                retriever.add_documents(embeddings_array, [
                    {"content": chunk, "metadata": meta}
                    for chunk, meta in zip(all_chunks, chunk_metadata)
                ])
                
                st.session_state.faiss_retriever = retriever
                
                st.success(f"âœ… {len(doc_list)}ê°œ íŒŒì¼, {len(all_chunks)}ê°œ ì²­í¬ ì²˜ë¦¬ ì™„ë£Œ!")
                
    retriever_exists = st.session_state.get('faiss_retriever') is not None
    if retriever_exists:
        st.divider()
        query = st.text_input("ğŸ” ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
        k = st.slider("ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜", 1, 10, 3)
        search_clicked = st.button("ê²€ìƒ‰")
        if query and search_clicked:
            try:
                results = st.session_state['faiss_retriever'].search(query, k=k)
            except Exception as e:
                st.error(f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                results = []
            
            if 'search_history' not in st.session_state:
                st.session_state['search_history'] = []
            st.session_state['search_history'].append({
                "query": query,
                "results_count": len(results),
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            })
            st.session_state['last_search_results'] = results
            st.session_state['last_search_query'] = query
            
            st.subheader(f"ğŸ“Š ê²€ìƒ‰ ê²°ê³¼ ({len(results)}ê°œ)")
            
            for i, result in enumerate(results, 1):
                meta = result.get('metadata', {})
                filename = meta.get('filename', 'unknown')
                filetype = meta.get('file_type', 'unknown')
                score = result.get('score', 0.0)
                keywords = meta.get('keyword_tags', [])
                confidence = meta.get('confidence_score', None)
                conf_text = f"{confidence:.0%}" if confidence is not None else "-"
                keywords_text = ", ".join(keywords[:5]) if keywords else "-"
                
                with st.expander(f"ê²°ê³¼ #{i} | {filename} | {filetype} | ì ìˆ˜: {score:.4f}"):
                    st.markdown(result.get('content', ''))
                    st.markdown(f"**í‚¤ì›Œë“œ:** {keywords_text}")
                    st.markdown(f"**ì‹ ë¢°ë„:** {conf_text}")
        
        last_results = st.session_state.get('last_search_results')
        last_query = st.session_state.get('last_search_query', '')
        if last_results:
            st.divider()
            export_clicked = st.button("ğŸ“¥ ê²€ìƒ‰ ê²°ê³¼ MDë¡œ ë‚´ë³´ë‚´ê¸°", width='stretch')
            if export_clicked:
                try:
                    exporter = MarkdownExporter()
                    md_content = exporter.export_search_results(query=last_query, results=last_results)
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    filename = f"flownote_search_{timestamp}.md"
                    st.download_button(
                        label="ğŸ’¾ ë‹¤ìš´ë¡œë“œ",
                        data=md_content,
                        file_name=filename,
                        mime="text/markdown",
                        width='stretch'
                    )
                except Exception as e:
                    st.error(f"MD ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨: {e}")
    else:
        st.info("ğŸ“¤ ë¨¼ì € ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ê³  ì²˜ë¦¬í•´ì£¼ì„¸ìš”")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# TAB 4: ë¶„ë¥˜ í†µê³„
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

with tab4:
    st.header("ğŸ¯ ë¶„ë¥˜ í†µê³„")
    if st.session_state.classification_history:
        from collections import Counter
        categories = [item['category'] for item in st.session_state.classification_history]
        category_counts = Counter(categories)
        st.metric("Projects", category_counts.get('Projects', 0))
        st.metric("Areas", category_counts.get('Areas', 0))
        st.metric("Resources", category_counts.get('Resources', 0))
        st.metric("Archives", category_counts.get('Archives', 0))
        confidences = [item['confidence'] for item in st.session_state.classification_history]
        avg_confidence = sum(confidences) / len(confidences) if confidences else 0
        st.metric("í‰ê·  ì‹ ë¢°ë„", f"{avg_confidence:.0%}")
        st.bar_chart(category_counts)
    else:
        st.info("ë¶„ë¥˜ íŒŒì¼ ì—†ìŒ")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# TAB 5: ë©”íƒ€ë°ì´í„°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

with tab5:
    st.header("ğŸ“Š ë©”íƒ€ë°ì´í„° í™•ì¸")
    
    col1, col2 = st.columns([3, 1])
    with col1:
        st.subheader("í˜„ì¬ ì„¸ì…˜ ë¶„ë¥˜ ê²°ê³¼")
    with col2:
        # ì‚¬ìš©ì ID í•„í„°
        user_filter = st.selectbox(
            "ğŸ” ì‚¬ìš©ì í•„í„°",
            options=["ì „ì²´"] + list(set([
                item.get('user_id', 'N/A')[:12] 
                for item in st.session_state.classification_history
            ])),
            key="user_filter"
        )
    
    # 1. í˜„ì¬ ì„¸ì…˜ ë°ì´í„° (st.session_state.classification_history)
    if st.session_state.classification_history:
        st.markdown("### ğŸ“ ì´ë²ˆ ì„¸ì…˜ ë¶„ë¥˜ ëª©ë¡")
        
        # í•„í„°ë§ ë¡œì§ ì ìš©
        filtered_history = st.session_state.classification_history
        
        if user_filter != "ì „ì²´":
            filtered_history = [
                item for item in st.session_state.classification_history
                if item.get('user_id', '').startswith(user_filter)
            ]
        
        session_data = []
        for item in st.session_state.classification_history:
            session_data.append({
                "íŒŒì¼ëª…": item['filename'],
                "ì¹´í…Œê³ ë¦¬": item['category'],
                "ì‹ ë¢°ë„": f"{item['confidence']:.0%}",
                "ì‹œê°„": item['timestamp'],
                "ë§¥ë½": "âœ…" if item.get('context_injected', False) else "âŒ",
                "User ID": item.get('user_id', 'N/A')[:12] + "..."
            })
        
        df_session = pd.DataFrame(session_data)
        st.dataframe(df_session, width='stretch')
        
        # í•„í„°ë§ëœ í†µê³„
        st.divider()
        col1, col2, col3, col4, col5= st.columns(5)
        
        with col1:
            st.metric("í•„í„° ê²°ê³¼", len(filtered_history))
        
        with col2:
            st.metric("ì´ íŒŒì¼", len(st.session_state.classification_history))
        
        with col3:
            if filtered_history:
                avg_conf = sum(item['confidence'] for item in filtered_history) / len(filtered_history)
                st.metric("í‰ê·  ì‹ ë¢°ë„", f"{avg_conf:.0%}")
        
        with col4:
            context_count = sum(1 for item in filtered_history if item.get('context_injected', False))
            st.metric("ë§¥ë½ ë°˜ì˜", f"{context_count}/{len(filtered_history)}")
        
        with col5:
            if st.button("ğŸ—‘ï¸ ì„¸ì…˜ ì´ˆê¸°í™”"):
                st.session_state.classification_history = []
                st.rerun()
    
    else:
        st.info("í˜„ì¬ ì„¸ì…˜ì—ì„œ ë¶„ë¥˜ëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    # 2. DBì— ì €ì¥ëœ ì „ì²´ ë°ì´í„° (ì„ íƒì‚¬í•­)
    st.divider()
    with st.expander("ğŸ—„ï¸ ì „ì²´ DB ë©”íƒ€ë°ì´í„° ë³´ê¸°"):
        try:
            all_classifications = st.session_state.db_extender.get_all_classifications()
            
            if all_classifications:
                df_data = []
                for item in all_classifications:
                    df_data.append({
                        "íŒŒì¼ëª…": item['filename'],
                        "ì¹´í…Œê³ ë¦¬": item['para_category'],
                        "ì‹ ë¢°ë„": f"{item['confidence_score']:.0%}",
                        "í‚¤ì›Œë“œ": item['keyword_tags'][:50] if item['keyword_tags'] else "",
                        "ì¶©ëŒ": "âš ï¸" if item['conflict_flag'] else "âœ…",
                        "Snapshot ID": item['snapshot_id'][:20] if item['snapshot_id'] else ""
                    })
                
                df_all = pd.DataFrame(df_data)
                st.dataframe(df_all, width='stretch')
                st.caption(f"ì´ {len(all_classifications)}ê°œ í•­ëª©")
            else:
                st.info("DBì— ì €ì¥ëœ ë©”íƒ€ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
        
        except Exception as e:
            st.error(f"DB ë¡œë“œ ì‹¤íŒ¨: {e}")


# í•˜ë‹¨ ì •ë³´
st.divider()
st.caption("FlowNote MVP v3.5 | gpt-4o ì„ íƒ ì˜ì—­ í™•ì¥ ì¤‘ | Made with â¤ï¸ by Jay")
