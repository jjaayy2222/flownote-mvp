# streamlit/flownote_ui_v4.py
"""
FlowNote v4.0 - ê°œì„ ëœ ëœë”© í˜ì´ì§€
- Tab1: ìë™ ë¶„ë¥˜ ëœë”© í˜ì´ì§€
- Tab2: í‚¤ì›Œë“œ ê²€ìƒ‰
- Tab3: Overview (í†µê³„)
"""
import os
import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent.parent 
sys.path.insert(0, str(project_root))

import streamlit as st
from dotenv import load_dotenv
import numpy as np
from datetime import datetime

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# Streamlit Secrets ë™ê¸°í™”
try:
    if hasattr(st, 'secrets') and len(st.secrets) > 0:
        for key in ["EMBEDDING_API_KEY", "EMBEDDING_BASE_URL", "EMBEDDING_MODEL",
                    "GPT4O_MINI_API_KEY", "GPT4O_MINI_BASE_URL", "GPT4O_MINI_MODEL"]:
            if key in st.secrets:
                os.environ[key] = st.secrets[key]
except:
    pass

# Backend ì„í¬íŠ¸
from backend.classifier.para_agent_wrapper import run_para_agent_sync
from backend.database.metadata_schema import ClassificationMetadataExtender
from backend.database.connection import DatabaseConnection
from backend.utils import load_pdf
from backend.embedding import EmbeddingGenerator
from backend.chunking import TextChunker
from backend.faiss_search import FAISSRetriever
from backend.metadata import FileMetadata
from backend.search_history import SearchHistory
from backend.export import MarkdownExporter

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="FlowNote",
    page_icon="ğŸ“š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ë‹¤í¬ ê·¸ë ˆì´ í†¤ì˜ ì• í”Œ ìŠ¤íƒ€ì¼ CSS
st.markdown("""
<style>
    /* ì „ì²´ ë°°ê²½ - ë‹¤í¬ ê·¸ë ˆì´ */
    .stApp {
        background: linear-gradient(135deg, #2c3e50 0%, #34495e 100%);
    }
    
    /* í—¤ë” */
    h1, h2, h3 {
        color: #ecf0f1;
        font-weight: 600;
        letter-spacing: -0.5px;
    }
    
    /* ì¹´ë“œ ìŠ¤íƒ€ì¼ - ë¼ì´íŠ¸ ë°°ê²½ */
    .card {
        background: rgba(255, 255, 255, 0.95);
        border-radius: 16px;
        padding: 32px;
        box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);
        margin: 24px 0;
        backdrop-filter: blur(10px);
    }
    
    /* ì—…ë¡œë“œ ì˜ì—­ */
    .upload-area {
        background: white;
        border: 2px dashed #bdc3c7;
        border-radius: 16px;
        padding: 48px;
        text-align: center;
        transition: all 0.3s ease;
    }
    
    .upload-area:hover {
        border-color: #3498db;
        background: #f8f9fa;
    }
    
    /* ë²„íŠ¼ ìŠ¤íƒ€ì¼ */
    .stButton>button {
        border-radius: 12px;
        font-weight: 500;
        padding: 12px 32px;
        border: none;
        transition: all 0.3s ease;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
    }
    
    .stButton>button:hover {
        transform: translateY(-2px);
        box-shadow: 0 8px 16px rgba(102, 126, 234, 0.3);
    }
    
    /* íƒ­ ìŠ¤íƒ€ì¼ */
    .stTabs [data-baseweb="tab-list"] {
        gap: 8px;
        background: rgba(255, 255, 255, 0.1);
        padding: 8px;
        border-radius: 12px;
    }
    
    .stTabs [data-baseweb="tab"] {
        border-radius: 8px;
        padding: 12px 24px;
        color: #ecf0f1;
        font-weight: 500;
    }
    
    .stTabs [data-baseweb="tab"][aria-selected="true"] {
        background: white;
        color: #2c3e50;
    }
    
    /* ë©”íŠ¸ë¦­ ì¹´ë“œ */
    [data-testid="stMetricValue"] {
        font-size: 32px;
        font-weight: 700;
        color: #2c3e50;
    }
    
    /* ë¶„ë¥˜ ê²°ê³¼ ì¹´ë“œ */
    .result-card {
        background: white;
        border-radius: 16px;
        padding: 32px;
        box-shadow: 0 4px 16px rgba(0, 0, 0, 0.1);
        margin: 16px 0;
    }
    
    /* ì¹´í…Œê³ ë¦¬ ë°°ì§€ */
    .category-badge {
        display: inline-block;
        padding: 8px 24px;
        border-radius: 24px;
        font-weight: 600;
        font-size: 18px;
        margin: 16px 0;
    }
    
    .badge-projects { 
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
    }
    .badge-areas { 
        background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
        color: white;
    }
    .badge-resources { 
        background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);
        color: white;
    }
    .badge-archives { 
        background: linear-gradient(135deg, #43e97b 0%, #38f9d7 100%);
        color: white;
    }
    
    /* êµ¬ë¶„ì„  */
    .divider {
        border-top: 2px solid rgba(255, 255, 255, 0.2);
        margin: 32px 0;
    }
    
    /* ì…ë ¥ í•„ë“œ */
    .stTextInput>div>div>input {
        border-radius: 12px;
        border: 2px solid #e5e5e7;
        background: white;
    }
</style>
""", unsafe_allow_html=True)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "classification_history" not in st.session_state:
    st.session_state.classification_history = []

if "db_extender" not in st.session_state:
    st.session_state.db_extender = ClassificationMetadataExtender()

if "faiss_retriever" not in st.session_state:
    st.session_state.faiss_retriever = None

if "file_metadata" not in st.session_state:
    st.session_state.file_metadata = FileMetadata()

if "search_history" not in st.session_state:
    st.session_state.search_history = SearchHistory()

if "last_search_results" not in st.session_state:
    st.session_state.last_search_results = None

if "last_search_query" not in st.session_state:
    st.session_state.last_search_query = None

if "current_result" not in st.session_state:
    st.session_state.current_result = None

if "uploaded_file_key" not in st.session_state:
    st.session_state.uploaded_file_key = 0

# íƒ€ì´í‹€
st.title("ğŸ“š FlowNote")
st.markdown("**AI ê¸°ë°˜ ë¬¸ì„œ ìë™ ë¶„ë¥˜ ì‹œìŠ¤í…œ**")

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.header("ğŸ“Š Overview")
    
    # íŒŒì¼ í†µê³„
    if st.session_state.file_metadata.metadata:
        stats = st.session_state.file_metadata.get_statistics()
        st.metric("ğŸ“ ì „ì²´ íŒŒì¼", stats['total_files'])
        st.metric("ğŸ“¦ ì „ì²´ ì²­í¬", stats['total_chunks'])
        st.metric("ğŸ’¾ ì´ í¬ê¸°", f"{stats['total_size_mb']} MB")
    else:
        st.info("ì•„ì§ ì—…ë¡œë“œëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
    
    st.divider()
    
    # ë¶„ë¥˜ íˆìŠ¤í† ë¦¬
    st.subheader("ğŸ¤– ìµœê·¼ ë¶„ë¥˜")
    if st.session_state.classification_history:
        for item in st.session_state.classification_history[-5:]:
            with st.expander(f"ğŸ“„ {item['filename'][:20]}..."):
                st.write(f"**ì¹´í…Œê³ ë¦¬**: {item['category']}")
                st.write(f"**ì‹ ë¢°ë„**: {item['confidence']:.0%}")
                st.caption(item['timestamp'])
    else:
        st.info("ë¶„ë¥˜ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤")
    
    st.divider()
    
    # ê²€ìƒ‰ íˆìŠ¤í† ë¦¬
    st.subheader("ğŸ” ìµœê·¼ ê²€ìƒ‰")
    history = st.session_state.search_history.get_recent_searches(3)
    if history:
        for item in history:
            st.caption(f"ğŸ” {item['query']}")
            st.caption(f"   {item['results_count']}ê°œ ê²°ê³¼")
    else:
        st.info("ê²€ìƒ‰ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤")

# ë©”ì¸ íƒ­
tab1, tab2, tab3 = st.tabs([
    "ğŸ  ìë™ ë¶„ë¥˜",
    "ğŸ” í‚¤ì›Œë“œ ê²€ìƒ‰",
    "ğŸ“Š Overview"
])

# ============================================================================
# TAB 1: ìë™ ë¶„ë¥˜ ëœë”© í˜ì´ì§€
# ============================================================================
with tab1:
    st.markdown('<div class="card">', unsafe_allow_html=True)
    st.markdown("### ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ & ìë™ ë¶„ë¥˜")
    
    # íŒŒì¼ ì—…ë¡œë”
    uploaded_file = st.file_uploader(
        "ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ë©´ ìë™ìœ¼ë¡œ ë¶„ë¥˜ë©ë‹ˆë‹¤",
        type=['pdf', 'txt', 'md'],
        help="PDF, TXT, MD íŒŒì¼ ì§€ì›",
        key=f"uploader_{st.session_state.uploaded_file_key}"
    )
    
    st.markdown('</div>', unsafe_allow_html=True)
    
    # íŒŒì¼ì´ ì—…ë¡œë“œë˜ë©´ ìë™ ë¶„ë¥˜
    if uploaded_file and st.session_state.current_result is None:
        with st.spinner("ğŸ¤– AIê°€ íŒŒì¼ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            try:
                # íŒŒì¼ ì½ê¸°
                if uploaded_file.type == "application/pdf":
                    text = load_pdf(uploaded_file)
                else:
                    text = uploaded_file.read().decode('utf-8')
                
                # ë©”íƒ€ë°ì´í„° êµ¬ì„±
                metadata = {
                    "filename": uploaded_file.name,
                    "file_size": uploaded_file.size,
                    "file_type": uploaded_file.type,
                    "uploaded_at": datetime.now().isoformat()
                }
                
                # AI ë¶„ë¥˜ (ìƒ˜í”Œ í…ìŠ¤íŠ¸ë§Œ)
                classification_result = run_para_agent_sync(
                    text=text[:2000],
                    metadata=metadata
                )
                
                # DB ì €ì¥
                file_id = st.session_state.db_extender.save_classification_result(
                    result=classification_result,
                    filename=uploaded_file.name
                )
                
                # íˆìŠ¤í† ë¦¬ ì €ì¥
                history_item = {
                    "filename": uploaded_file.name,
                    "category": classification_result.get('category', 'Unknown'),
                    "confidence": classification_result.get('confidence', 0),
                    "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "file_id": file_id
                }
                st.session_state.classification_history.append(history_item)
                st.session_state.current_result = classification_result
                
                st.success("âœ… ë¶„ë¥˜ ì™„ë£Œ!")
                
            except Exception as e:
                st.error(f"âŒ ë¶„ë¥˜ ì‹¤íŒ¨: {str(e)}")
    
    # ë¶„ë¥˜ ê²°ê³¼ í‘œì‹œ
    if st.session_state.current_result:
        result = st.session_state.current_result
        
        st.markdown("---")
        st.markdown('<div class="result-card">', unsafe_allow_html=True)
        
        # ì¹´í…Œê³ ë¦¬ ì•„ì´ì½˜
        category_icons = {
            "Projects": "ğŸš€",
            "Areas": "ğŸ¯",
            "Resources": "ğŸ“š",
            "Archives": "ğŸ“¦"
        }
        
        category = result.get('category', 'Unknown')
        icon = category_icons.get(category, "â“")
        
        # ì¹´í…Œê³ ë¦¬ ë°°ì§€
        badge_class = f"badge-{category.lower()}"
        st.markdown(
            f'<div class="category-badge {badge_class}">{icon} {category}</div>',
            unsafe_allow_html=True
        )
        
        # ì‹ ë¢°ë„
        confidence = result.get('confidence', 0)
        st.progress(confidence)
        st.caption(f"ì‹ ë¢°ë„: {confidence:.0%}")
        
        # ë¶„ë¥˜ ê·¼ê±°
        with st.expander("ğŸ“ ë¶„ë¥˜ ê·¼ê±°", expanded=True):
            st.markdown(result.get('reasoning', 'ì •ë³´ ì—†ìŒ'))
        
        # í‚¤ì›Œë“œ íƒœê·¸
        with st.expander("ğŸ·ï¸ í‚¤ì›Œë“œ íƒœê·¸"):
            tags = result.get('keyword_tags', [])
            if tags:
                st.write(", ".join([f"`{tag}`" for tag in tags[:10]]))
            else:
                st.caption("í‚¤ì›Œë“œ ì—†ìŒ")
        
        st.markdown('</div>', unsafe_allow_html=True)
        
        # êµ¬ë¶„ì„ 
        st.markdown('<div class="divider"></div>', unsafe_allow_html=True)
        
        # ì•¡ì…˜ ë²„íŠ¼
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("ğŸ” í‚¤ì›Œë“œ ê²€ìƒ‰í•˜ê¸°", use_container_width=True, type="primary"):
                st.session_state.current_tab = 2
                st.rerun()
        
        with col2:
            if st.button("ğŸ”„ ë‹¤ë¥¸ íŒŒì¼ ë¶„ë¥˜í•˜ê¸°", use_container_width=True):
                st.session_state.current_result = None
                st.session_state.uploaded_file_key += 1
                st.rerun()

# ============================================================================
# TAB 2: í‚¤ì›Œë“œ ê²€ìƒ‰
# ============================================================================
with tab2:
    st.markdown('<div class="card">', unsafe_allow_html=True)
    st.markdown("### ğŸ” ë¬¸ì„œ ê²€ìƒ‰")
    
    # íŒŒì¼ ì—…ë¡œë“œ (ê²€ìƒ‰ìš©)
    uploaded_files_search = st.file_uploader(
        "ê²€ìƒ‰í•  ë¬¸ì„œ ì—…ë¡œë“œ",
        type=['pdf', 'txt', 'md'],
        accept_multiple_files=True,
        help="ì—¬ëŸ¬ íŒŒì¼ì„ ë™ì‹œì— ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"
    )
    
    if uploaded_files_search and st.button("ğŸ“„ íŒŒì¼ ì²˜ë¦¬"):
        doc_list = []
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # íŒŒì¼ ì½ê¸°
        for i, uploaded_file in enumerate(uploaded_files_search):
            status_text.text(f"ğŸ“„ {uploaded_file.name} ì²˜ë¦¬ ì¤‘...")
            try:
                if uploaded_file.type == "application/pdf":
                    content = load_pdf(uploaded_file)
                else:
                    content = uploaded_file.read().decode('utf-8')
                
                doc_list.append({
                    'name': uploaded_file.name,
                    'content': content,
                    'size': uploaded_file.size,
                    'type': uploaded_file.type
                })
            except Exception as e:
                st.error(f"âŒ {uploaded_file.name}: {str(e)}")
            
            progress_bar.progress((i + 1) / len(uploaded_files_search))
        
        if doc_list:
            status_text.text("ğŸ”® ì„ë² ë”© ìƒì„± ì¤‘...")
            
            # ì²­í‚¹
            chunker = TextChunker()
            all_chunks = []
            chunk_metadata = []
            
            for doc in doc_list:
                chunks = chunker.chunk_text(doc['content'])
                all_chunks.extend(chunks)
                for chunk in chunks:
                    chunk_metadata.append({
                        'filename': doc['name'],
                        'file_type': doc['type']
                    })
            
            # ì„ë² ë”©
            embedder = EmbeddingGenerator()
            result = embedder.generate_embeddings(all_chunks)
            embeddings_array = np.array(result['embeddings'])
            
            # FAISS ì¸ë±ìŠ¤
            documents = []
            for chunk, meta in zip(all_chunks, chunk_metadata):
                documents.append({
                    "content": chunk,
                    "metadata": meta
                })
            
            retriever = FAISSRetriever(dimension=embeddings_array.shape[1])
            retriever.add_documents(embeddings_array, documents)
            st.session_state.faiss_retriever = retriever
            
            # ë©”íƒ€ë°ì´í„° ì €ì¥
            for doc in doc_list:
                count = sum(1 for m in chunk_metadata if m['filename'] == doc['name'])
                st.session_state.file_metadata.add_file(
                    file_name=doc['name'],
                    file_size=doc['size'],
                    chunk_count=count,
                    embedding_dim=embeddings_array.shape[1]
                )
            
            status_text.empty()
            progress_bar.empty()
            st.success(f"âœ… {len(doc_list)}ê°œ íŒŒì¼, {len(all_chunks)}ê°œ ì²­í¬ ì²˜ë¦¬ ì™„ë£Œ!")
    
    st.markdown('</div>', unsafe_allow_html=True)
    
    # ê²€ìƒ‰
    if st.session_state.faiss_retriever:
        st.markdown('<div class="card">', unsafe_allow_html=True)
        
        query = st.text_input(
            "ğŸ” ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”",
            placeholder="ì˜ˆ: FlowNote ì‚¬ìš©ë²•",
            help="ìì—°ì–´ë¡œ ì§ˆë¬¸í•˜ê±°ë‚˜ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”"
        )
        
        col_k, col_btn = st.columns([1, 2])
        with col_k:
            k = st.slider("ê²°ê³¼ ê°œìˆ˜", 1, 10, 3)
        
        with col_btn:
            search_button = st.button("ğŸ” ê²€ìƒ‰", type="primary", use_container_width=True)
        
        if query and search_button:
            with st.spinner("ê²€ìƒ‰ ì¤‘..."):
                results = st.session_state.faiss_retriever.search(query, k=k)
                st.session_state.search_history.add_search(
                    query=query,
                    results_count=len(results)
                )
                st.session_state.last_search_results = results
                st.session_state.last_search_query = query
            
            st.success(f"âœ… {len(results)}ê°œ ê²°ê³¼ ë°œê²¬!")
        
        st.markdown('</div>', unsafe_allow_html=True)
    else:
        st.info("ğŸ’¡ ë¨¼ì € ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ê³  ì²˜ë¦¬í•´ì£¼ì„¸ìš”")
    
    # ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ
    if st.session_state.last_search_results:
        st.divider()
        st.markdown("### ğŸ“Š ê²€ìƒ‰ ê²°ê³¼")
        
        for i, result in enumerate(st.session_state.last_search_results, 1):
            with st.expander(
                f"**ê²°ê³¼ #{i}** | {result['metadata']['filename']} | ìœ ì‚¬ë„: {result['score']:.2%}",
                expanded=(i == 1)
            ):
                st.markdown(result['content'])
                st.caption(f"íŒŒì¼: {result['metadata']['filename']}")
        
        # ê²°ê³¼ ì €ì¥
        col_export, col_clear = st.columns([3, 1])
        with col_export:
            if st.button("ğŸ’¾ ê²€ìƒ‰ ê²°ê³¼ MDë¡œ ì €ì¥", use_container_width=True):
                exporter = MarkdownExporter()
                md_content = exporter.export_search_results(
                    query=st.session_state.last_search_query,
                    results=st.session_state.last_search_results
                )
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"flownote_search_{timestamp}.md"
                st.download_button(
                    label="â¬‡ï¸ ë‹¤ìš´ë¡œë“œ",
                    data=md_content,
                    file_name=filename,
                    mime="text/markdown",
                    use_container_width=True
                )

# ============================================================================
# TAB 3: Overview (í†µê³„)
# ============================================================================
with tab3:
    st.header("ğŸ“Š Overview")
    
    # ìƒë‹¨ KPI
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        total_files = len(st.session_state.classification_history)
        st.metric("ğŸ“ ë¶„ë¥˜ëœ íŒŒì¼", total_files)
    
    with col2:
        if st.session_state.faiss_retriever:
            st.metric("ğŸ” ì¸ë±ìŠ¤ í¬ê¸°", st.session_state.faiss_retriever.size())
        else:
            st.metric("ğŸ” ì¸ë±ìŠ¤ í¬ê¸°", 0)
    
    with col3:
        search_count = len(st.session_state.search_history.get_all_searches())
        st.metric("ğŸ” ì´ ê²€ìƒ‰", search_count)
    
    with col4:
        if st.session_state.classification_history:
            avg_conf = sum(item['confidence'] for item in st.session_state.classification_history) / len(st.session_state.classification_history)
            st.metric("â­ í‰ê·  ì‹ ë¢°ë„", f"{avg_conf:.0%}")
        else:
            st.metric("â­ í‰ê·  ì‹ ë¢°ë„", "0%")
    
    st.divider()
    
    # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
    if st.session_state.classification_history:
        from collections import Counter
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.subheader("ğŸ“Š ì¹´í…Œê³ ë¦¬ ë¶„í¬")
            categories = [item['category'] for item in st.session_state.classification_history]
            category_counts = Counter(categories)
            
            for category, count in category_counts.most_common():
                icon = {"Projects": "ğŸš€", "Areas": "ğŸ¯", "Resources": "ğŸ“š", "Archives": "ğŸ“¦"}.get(category, "â“")
                st.metric(f"{icon} {category}", count)
        
        with col2:
            st.subheader("ğŸ“ˆ ìµœê·¼ í™œë™")
            for item in st.session_state.classification_history[-5:]:
                with st.container():
                    st.markdown(f"**{item['filename']}**")
                    st.caption(f"{item['category']} | {item['timestamp']}")
                    st.divider()
    else:
        st.info("ğŸ“Š ì•„ì§ í†µê³„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. Tab 1ì—ì„œ íŒŒì¼ì„ ë¶„ë¥˜í•´ë³´ì„¸ìš”!")

# í•˜ë‹¨ ì •ë³´
st.divider()
st.caption("FlowNote v4.0 | Made with â¤ï¸ by Jay")
