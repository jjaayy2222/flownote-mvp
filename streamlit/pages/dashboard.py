# frontend/pages/dashboard.py (ìˆ˜ì •)

import sys
from pathlib import Path

# ë£¨íŠ¸ í´ë” ê²½ë¡œ ì¶”ê°€
root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(root))

import streamlit as st
from streamlit_option_menu import option_menu
from backend.dashboard.dashboard_core import MetadataAggregator
from backend.metadata import FileMetadata
from backend.data_manager import DataManager
from backend.search_history import SearchHistory
from backend.database.connection import DatabaseConnection
import csv
import plotly.express as px
import pandas as pd
from datetime import datetime, timedelta
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from st_aggrid import AgGrid


st.set_page_config(page_title="FlowNote Dashboard", layout="wide")

metadata_manager = FileMetadata()
all_files = metadata_manager.get_all_files()

# Step 1: CSS ìŠ¤íƒ€ì¼ë§ ì¶”ê°€
# Step 1: CSS ìŠ¤íƒ€ì¼ë§ ì¶”ê°€ (ë‹¤í¬/ë¼ì´íŠ¸ ëª¨ë“œ ëŒ€ì‘)
st.markdown("""
<style>
    /* ë©”íŠ¸ë¦­ ì¹´ë“œ ìŠ¤íƒ€ì¼ */
    [data-testid="stMetricValue"] {
        font-size: 32px;
        font-weight: bold;
    }
    
    [data-testid="stMetricLabel"] {
        font-size: 14px;
        font-weight: 600;
    }
    
    [data-testid="stMetricDelta"] {
        font-size: 14px;
    }
    
    /* ì„œë¸Œí—¤ë” ìŠ¤íƒ€ì¼ */
    h2, h3 {
        font-weight: 600 !important;
    }
    
    /* divider ìŠ¤íƒ€ì¼ */
    hr {
        border: none;
        border-top: 2px solid #dee2e6;
        margin: 20px 0;
    }
    
    /* íƒ­ ìŠ¤íƒ€ì¼ - ê¸°ë³¸(ë¼ì´íŠ¸ ëª¨ë“œ) */
    .stTabs [data-baseweb="tab-list"] {
        gap: 8px;
    }
    
    .stTabs [data-baseweb="tab"] {
        border-radius: 8px 8px 0 0;
        padding: 10px 20px;
        font-weight: 600;
        transition: all 0.3s ease;
    }
    
    /* ë¼ì´íŠ¸ ëª¨ë“œ íƒ­ ìŠ¤íƒ€ì¼ */
    @media (prefers-color-scheme: light) {
        .stTabs [data-baseweb="tab"] {
            background-color: #f8f9fa;
            color: #2c3e50;
        }
        
        .stTabs [aria-selected="true"] {
            background-color: #3498db;
            color: white !important;
        }
        
        .stTabs [data-baseweb="tab"]:hover {
            background-color: #e9ecef;
            color: #2c3e50;
        }
        
        .stTabs [aria-selected="true"]:hover {
            background-color: #2980b9;
            color: white !important;
        }
    }
    
    /* ë‹¤í¬ ëª¨ë“œ íƒ­ ìŠ¤íƒ€ì¼ */
    @media (prefers-color-scheme: dark) {
        .stTabs [data-baseweb="tab"] {
            background-color: #262730;
            color: #fafafa;
        }
        
        .stTabs [aria-selected="true"] {
            background-color: #3498db;
            color: white !important;
        }
        
        .stTabs [data-baseweb="tab"]:hover {
            background-color: #31333f;
            color: #fafafa;
        }
        
        .stTabs [aria-selected="true"]:hover {
            background-color: #2980b9;
            color: white !important;
        }
    }
</style>
""", unsafe_allow_html=True)


# =====================================
# ğŸ“Š ì‹¤ì œ ë°ì´í„° ë¡œë“œ
# =====================================
@st.cache_data(ttl=60)  # 60ì´ˆ ìºì‹œ (1ë¶„ë§ˆë‹¤ ê°±ì‹ )
def load_dashboard_data():
    """
    ëŒ€ì‹œë³´ë“œ ë°ì´í„° ë¡œë“œ
    Returns:
        dict: ì „ì²´ íŒŒì¼ ìˆ˜, ì´ ê²€ìƒ‰ ìˆ˜, ë¶„ë¥˜ìœ¨, í‰ê·  ì¤‘ìš”ë„
    """
    try:
        # 1ï¸âƒ£ FileMetadataì—ì„œ ì „ì²´ íŒŒì¼ ìˆ˜ ê°€ì ¸ì˜¤ê¸°
        metadata_manager = FileMetadata()
        all_files = metadata_manager.get_all_files()
        total_files = len(all_files)
        
        # 2ï¸âƒ£ classification_log.csvì—ì„œ ë¶„ë¥˜ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        data_manager = DataManager()
        classifications_csv_path = data_manager.classifications_csv
        
        total_searches = 0
        completed_count = 0
        confidence_sum = 0
        confidence_count = 0
        
                # CSV íŒŒì¼ ì½ê¸°
        if classifications_csv_path.exists():
            with open(classifications_csv_path, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    total_searches += 1
                    
                    # ë¶„ë¥˜ ì™„ë£Œ ì—¬ë¶€ í™•ì¸
                    if row.get('user_selected'):
                        completed_count += 1
                    
                    # confidence í‰ê·  ê³„ì‚°
                    try:
                        confidence = float(row.get('confidence', 0))
                        if confidence > 0:
                            confidence_sum += confidence
                            confidence_count += 1
                    except:
                        pass
        # 3ï¸âƒ£ ê³„ì‚°
        classification_rate = (completed_count / total_searches * 100) if total_searches > 0 else 0
        avg_confidence = (confidence_sum / confidence_count) if confidence_count > 0 else 0
        
        # 4ï¸âƒ£ delta ê³„ì‚° (ì´ì „ ê°’ê³¼ ë¹„êµ - ì—¬ê¸°ì„œëŠ” ì„ì‹œë¡œ +10 ì„¤ì •)
        prev_total_files = total_files - 12  # ì„ì‹œ
        prev_total_searches = total_searches - 8  # ì„ì‹œ
        
        delta_files = total_files - prev_total_files
        delta_searches_pct = ((total_searches - prev_total_searches) / prev_total_searches * 100) if prev_total_searches > 0 else 0
        
        return {
            "total_files": total_files,
            "delta_files": delta_files,
            "total_searches": total_searches,
            "delta_searches_pct": delta_searches_pct,
            "classification_rate": classification_rate,
            "avg_confidence": avg_confidence
        }
    except Exception as e:
        print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
        return {
            "total_files": 0,
            "delta_files": 0,
            "total_searches": 0,
            "delta_searches_pct": 0,
            "classification_rate": 0,
            "avg_confidence": 0
        }

# ë°ì´í„° ë¡œë“œ
dashboard_data = load_dashboard_data()

agg = MetadataAggregator()

@st.cache_data(ttl=60)
def load_para_distribution():
    """
    PARA ë¶„í¬ ë°ì´í„° ë¡œë“œ
    Returns:
        pd.DataFrame: PARA ì¹´í…Œê³ ë¦¬ë³„ íŒŒì¼ ê°œìˆ˜
    """
    try:
        data_manager = DataManager()
        classifications_csv_path = data_manager.classifications_csv
        
        para_counts = {"Projects": 0, "Areas": 0, "Resources": 0, "Archives": 0}
        
        if classifications_csv_path.exists():
            with open(classifications_csv_path, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    para_category = row.get('user_selected', '').strip()
                    if para_category in para_counts:
                        para_counts[para_category] += 1
        
        # DataFrame ìƒì„±
        df = pd.DataFrame(list(para_counts.items()), columns=['PARA', 'Count'])
        return df
    
    except Exception as e:
        print(f"âŒ PARA ë¶„í¬ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return pd.DataFrame({"PARA": ["Projects", "Areas", "Resources", "Archives"], "Count": [0, 0, 0, 0]})


@st.cache_data(ttl=60)
def load_search_trend():
    """
    ìµœê·¼ 7ì¼ê°„ ê²€ìƒ‰ íŠ¸ë Œë“œ ë°ì´í„° ë¡œë“œ
    Returns:
        pd.DataFrame: ë‚ ì§œë³„ ê²€ìƒ‰ íšŸìˆ˜
    """
    try:
        data_manager = DataManager()
        classifications_csv_path = data_manager.classifications_csv
        
        # ë‚ ì§œë³„ ê²€ìƒ‰ íšŸìˆ˜ ì§‘ê³„
        daily_counts = {}
        
        if classifications_csv_path.exists():
            with open(classifications_csv_path, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    timestamp = row.get('timestamp', '')
                    if timestamp:
                        try:
                            # íƒ€ì„ìŠ¤íƒ¬í”„ íŒŒì‹± (ì˜ˆ: "20251110_044530_829" â†’ "2025-11-10")
                            date_str = timestamp.split('_')[0]  # "20251110"
                            date_obj = datetime.strptime(date_str, "%Y%m%d")
                            date_key = date_obj.strftime("%Y-%m-%d")
                            daily_counts[date_key] = daily_counts.get(date_key, 0) + 1
                        except:
                            pass
        
        # ìµœê·¼ 7ì¼ ë°ì´í„°ë§Œ í•„í„°ë§
        today = datetime.now()
        last_7_days = [(today - timedelta(days=i)).strftime("%Y-%m-%d") for i in range(6, -1, -1)]
        
        trend_data = []
        for date in last_7_days:
            trend_data.append({"ë‚ ì§œ": date, "ê²€ìƒ‰ íšŸìˆ˜": daily_counts.get(date, 0)})
        
        df = pd.DataFrame(trend_data)
        return df
    
    except Exception as e:
        print(f"âŒ ê²€ìƒ‰ íŠ¸ë Œë“œ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return pd.DataFrame({"ë‚ ì§œ": [], "ê²€ìƒ‰ íšŸìˆ˜": []})


@st.cache_data(ttl=60)
def load_stats_data():
    """
    í†µê³„ ë°ì´í„°ë¥¼ CSVì—ì„œ ë¡œë“œí•˜ì—¬ ì§‘ê³„
    Returns:
        dict: í†µê³„ê°’ë“¤ (ì˜ˆ: ì „ì²´ íŒŒì¼, ë¶„ë¥˜ ì™„ë£Œ ìˆ˜ ë“±)
    """
    try:
        data_manager = DataManager()
        classifications_csv_path = data_manager.classifications_csv
        
        total_files = 0
        classified_files = 0
        confidence_scores = []
        
        if classifications_csv_path.exists():
            with open(classifications_csv_path, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    total_files += 1
                    if row.get('user_selected'):
                        classified_files += 1
                    try:
                        conf = float(row.get('confidence', 0))
                        confidence_scores.append(conf)
                    except:
                        pass
        
        classification_rate = (classified_files / total_files * 100) if total_files else 0
        avg_confidence = sum(confidence_scores) / len(confidence_scores) if confidence_scores else 0
        
        return {
            "total_files": total_files,
            "classified_files": classified_files,
            "classification_rate": classification_rate,
            "avg_confidence": avg_confidence
        }
    except Exception as e:
        print(f"âŒ í†µê³„ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {
            "total_files": 0,
            "classified_files": 0,
            "classification_rate": 0,
            "avg_confidence": 0
        }


@st.cache_data(ttl=60)
def load_recent_activities(limit: int = 10):
    """
    ìµœê·¼ ë¶„ë¥˜ í™œë™ ë¡œê·¸ë¥¼ CSVì—ì„œ ìµœê·¼ limitê°œ ì½ì–´ ë°˜í™˜
    """
    try:
        data_manager = DataManager()
        classifications_csv_path = data_manager.classifications_csv
        
        logs = []
        if classifications_csv_path.exists():
            with open(classifications_csv_path, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                all_rows = list(reader)
                # ìµœì‹ ìˆœìœ¼ë¡œ ê°€ì¥ ìµœê·¼ limitê°œ ê°€ì ¸ì˜¤ê¸°
                recent_rows = all_rows[-limit:]
                # í•„ìš”ì‹œ ì—­ìˆœìœ¼ë¡œ ì¤„ ìˆ˜ë„ ìˆìŒ
                for row in reversed(recent_rows):
                    logs.append({
                        "timestamp": row.get('timestamp', 'N/A'),
                        "title": row.get('title', 'ì œëª© ì—†ìŒ'),
                        "user_selected": row.get('user_selected', 'ì„ íƒ ì—†ìŒ'),
                        "confidence": row.get('confidence', '0')
                    })
        return logs
    except Exception as e:
        print(f"âŒ ìµœê·¼ í™œë™ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return []


@st.cache_data(ttl=60)
def load_file_list():
    from backend.metadata import FileMetadata
    metadata_manager = FileMetadata()
    files_dict = metadata_manager.get_all_files()
    files_list = [v for v in files_dict.values()]
    return pd.DataFrame(files_list)




@st.cache_data(ttl=60)
def build_file_tree():
    """
    íŒŒì¼ ê²½ë¡œë¥¼ ê³„ì¸µêµ¬ì¡°ë¡œ ë³€í™˜í•˜ì—¬ íŠ¸ë¦¬ ìƒì„±
    Returns:
        dict: ê³„ì¸µ êµ¬ì¡°ë¡œ íŒŒì¼ ì •ë³´ë¥¼ ë‹´ì€ íŠ¸ë¦¬
    """
    from backend.metadata import FileMetadata
    
    metadata_manager = FileMetadata()
    files_dict = metadata_manager.get_all_files()
    
    tree = {}
    for file_id, info in files_dict.items():
        filename = info.get('file_name', '')
        
        # ê²½ë¡œ ì—†ì´ íŒŒì¼ëª…ë§Œ ìˆëŠ” ê²½ìš° rootì— ë°”ë¡œ ì €ì¥
        if '/' not in filename and '\\' not in filename:
            tree[filename] = info
            continue
        
        # ê²½ë¡œ í¬í•¨ íŒŒì¼ì€ ê³„ì¸µ êµ¬ì¡°ë¡œ ì €ì¥
        parts = filename.replace('\\', '/').split('/')
        current = tree
        
        # í´ë” ê²½ë¡œ íƒìƒ‰
        for part in parts[:-1]:
            if part not in current:
                current[part] = {}
            elif not isinstance(current[part], dict):
                # ì¶©ëŒ ë°©ì§€: íŒŒì¼ê³¼ í´ë” ì´ë¦„ì´ ê°™ì„ ê²½ìš°
                current[part] = {"__file__": current[part]}
            current = current[part]
        
        # ë§ˆì§€ë§‰ íŒŒì¼ëª… ì €ì¥
        current[parts[-1]] = info
    
    return tree



@st.cache_data(ttl=60)
def load_recent_logs(n=10):
    data_manager = DataManager()
    classifications_csv_path = data_manager.classifications_csv
    records = []
    if classifications_csv_path.exists():
        df = pd.read_csv(classifications_csv_path)
        # ìµœê·¼ nê°œ ë¡œê·¸ë§Œ
        records = df.sort_values('timestamp', ascending=False).head(n)
    return records


# ==============================
# ìƒë‹¨: KPI ë©”íŠ¸ë¦­ (ì‹¤ì œ ë°ì´í„°)
# ==============================

st.header("ğŸ“Š FlowNote Dashboard")

st.divider()

col1, col2, col3, col4 = st.columns(4)

# ğŸ“ ì „ì²´ íŒŒì¼
with col1:
    st.markdown("**ğŸ“ ì „ì²´ íŒŒì¼**")
    metric_col1, metric_col2 = st.columns([3, 2], gap="small")
    
    with metric_col1:
        st.markdown(f"<h3 style='margin: 0; line-height: 1.2;'>{dashboard_data['total_files']}</h3>", 
                    unsafe_allow_html=True)
    
    with metric_col2:
        delta_val = dashboard_data['delta_files']
        if delta_val > 0:
            st.markdown(f"<div style='padding-top: 20px;'><span style='color: #09ab3b; font-size: 16px; font-weight: 600;'>â–² {delta_val:+d}ê°œ</span></div>", 
                        unsafe_allow_html=True)
        elif delta_val < 0:
            st.markdown(f"<div style='padding-top: 20px;'><span style='color: #ff4b4b; font-size: 16px; font-weight: 600;'>â–¼ {abs(delta_val)}ê°œ</span></div>", 
                        unsafe_allow_html=True)
        else:
            st.markdown(f"<div style='padding-top: 20px;'><span style='color: #808495; font-size: 16px; font-weight: 600;'>â€• 0ê°œ</span></div>", 
                        unsafe_allow_html=True)

# ğŸ” ì´ ê²€ìƒ‰
with col2:
    st.markdown("**ğŸ” ì´ ê²€ìƒ‰**")
    metric_col1, metric_col2 = st.columns([3, 2], gap="small")
    
    with metric_col1:
        st.markdown(f"<h3 style='margin: 0; line-height: 1.2;'>{dashboard_data['total_searches']}</h3>", 
                    unsafe_allow_html=True)
    
    with metric_col2:
        delta_val = dashboard_data['delta_searches_pct']
        if delta_val > 0:
            st.markdown(f"<div style='padding-top: 20px;'><span style='color: #09ab3b; font-size: 16px; font-weight: 600;'>â–² {delta_val:+.1f}%</span></div>", 
                        unsafe_allow_html=True)
        elif delta_val < 0:
            st.markdown(f"<div style='padding-top: 20px;'><span style='color: #ff4b4b; font-size: 16px; font-weight: 600;'>â–¼ {abs(delta_val):.1f}%</span></div>", 
                        unsafe_allow_html=True)
        else:
            st.markdown(f"<div style='padding-top: 20px;'><span style='color: #808495; font-size: 16px; font-weight: 600;'>â€• 0.0%</span></div>", 
                        unsafe_allow_html=True)

# ğŸ“Š ë¶„ë¥˜ìœ¨
with col3:
    st.markdown("**ğŸ“Š ë¶„ë¥˜ìœ¨**")
    metric_col1, metric_col2 = st.columns([3, 2], gap="small")
    
    with metric_col1:
        st.markdown(f"<h3 style='margin: 0; line-height: 1.2;'>{dashboard_data['classification_rate']:.1f}%</h3>", 
                    unsafe_allow_html=True)
    
    with metric_col2:
        # ì„ì‹œ ê°’ (ë‚˜ì¤‘ì— ì´ì „ ì£¼ì™€ ë¹„êµ)
        delta_val = 5.0
        if delta_val > 0:
            st.markdown(f"<div style='padding-top: 20px;'><span style='color: #09ab3b; font-size: 16px; font-weight: 600;'>â–² {delta_val:+.1f}%</span></div>", 
                        unsafe_allow_html=True)
        elif delta_val < 0:
            st.markdown(f"<div style='padding-top: 20px;'><span style='color: #ff4b4b; font-size: 16px; font-weight: 600;'>â–¼ {abs(delta_val):.1f}%</span></div>", 
                        unsafe_allow_html=True)
        else:
            st.markdown(f"<div style='padding-top: 20px;'><span style='color: #808495; font-size: 16px; font-weight: 600;'>â€• 0.0%</span></div>", 
                        unsafe_allow_html=True)

# â­ í‰ê·  ì‹ ë¢°ë„
with col4:
    st.markdown("**â­ í‰ê·  ì‹ ë¢°ë„**")
    metric_col1, metric_col2 = st.columns([3, 2], gap="small")
    
    with metric_col1:
        st.markdown(f"<h3 style='margin: 0; line-height: 1.2;'>{dashboard_data['avg_confidence']:.2f}</h3>", 
                    unsafe_allow_html=True)
    
    with metric_col2:
        # ì„ì‹œ ê°’
        delta_val = 0.05
        if delta_val > 0:
            st.markdown(f"<div style='padding-top: 20px;'><span style='color: #09ab3b; font-size: 16px; font-weight: 600;'>â–² {delta_val:+.2f}</span></div>", 
                        unsafe_allow_html=True)
        elif delta_val < 0:
            st.markdown(f"<div style='padding-top: 20px;'><span style='color: #ff4b4b; font-size: 16px; font-weight: 600;'>â–¼ {abs(delta_val):.2f}</span></div>", 
                        unsafe_allow_html=True)
        else:
            st.markdown(f"<div style='padding-top: 20px;'><span style='color: #808495; font-size: 16px; font-weight: 600;'>â€• 0.00</span></div>", 
                        unsafe_allow_html=True)

#################################
# ì¤‘ê°„: í‚¤ì›Œë“œ í´ë¼ìš°ë“œ
#################################

st.divider()

@st.cache_data(ttl=60)
def load_keyword_freq():
    # ì˜ˆì‹œ: í‚¤ì›Œë“œì™€ ë“±ì¥ ë¹ˆë„ ë”•ì…”ë„ˆë¦¬ ë¦¬í„´
    return {
        'Python': 50,
        'Streamlit': 35,
        'Keyword': 20,
        'Cloud': 18,
        'Dashboard': 15,
        'PARA': 10,
        'Files': 8,
        'Classification': 5,
    }

st.subheader("ğŸ” í‚¤ì›Œë“œ í´ë¼ìš°ë“œ")
keyword_freq = load_keyword_freq()
wc = WordCloud(width=400, height=200, background_color='white').generate_from_frequencies(keyword_freq)

fig, ax = plt.subplots(figsize=(8, 4))
ax.imshow(wc, interpolation='bilinear')
ax.axis('off')
st.pyplot(fig)



# ==============================
# ì¤‘ì•™ ì»¬ëŸ¼ - 2ê°œ
# ==============================

st.divider()

col_build_file_tree, col_table = st.columns([1, 1])

with col_build_file_tree:
    st.subheader("ğŸ—ï¸ íŒŒì¼ íŠ¸ë¦¬")

    # íŒŒì¼ íŠ¸ë¦¬ ë Œë”ë§ìš© ì¬ê·€ í•¨ìˆ˜
    def render_file_tree(tree, indent=0, max_display=7):
        """
        íŠ¸ë¦¬ êµ¬ì¡°ë¥¼ ì¬ê·€ì ìœ¼ë¡œ Streamlitì— ë Œë”ë§ (ìµœëŒ€ 7ê°œê¹Œì§€ë§Œ í‘œì‹œ)
        Args:
            tree (dict): íŒŒì¼ íŠ¸ë¦¬ êµ¬ì¡°
            indent (int): ë“¤ì—¬ì“°ê¸° ë ˆë²¨
            max_display (int): ìµœëŒ€ í‘œì‹œ ê°œìˆ˜
        """
        count = 0
        remaining_items = []
        
        for key, value in tree.items():
            if count < max_display:
                # í´ë”ì¸ ê²½ìš°
                if isinstance(value, dict) and 'file_name' not in value:
                    st.markdown("&nbsp;" * indent * 4 + f"ğŸ“ **{key}**")
                    render_file_tree(value, indent + 1, max_display=999)  # í•˜ìœ„ í•­ëª©ì€ ì œí•œ ì—†ìŒ
                # íŒŒì¼ì¸ ê²½ìš°
                else:
                    st.markdown("&nbsp;" * indent * 4 + f"ğŸ“„ {key}")
                count += 1
            else:
                remaining_items.append((key, value))
        
        # ë‚˜ë¨¸ì§€ í•­ëª©ì´ ìˆìœ¼ë©´ expanderë¡œ í‘œì‹œ
        if remaining_items:
            with st.expander(f"... ì™¸ {len(remaining_items)}ê°œ ë” ë³´ê¸°"):
                for key, value in remaining_items:
                    if isinstance(value, dict) and 'file_name' not in value:
                        st.markdown("&nbsp;" * indent * 4 + f"ğŸ“ **{key}**")
                        render_file_tree(value, indent + 1, max_display=999)
                    else:
                        st.markdown("&nbsp;" * indent * 4 + f"ğŸ“„ {key}")

    # íŒŒì¼ íŠ¸ë¦¬ë¥¼ ì‹¤ì œë¡œ í™”ë©´ì— í‘œì‹œ
    file_tree = build_file_tree()
    
    if file_tree:
        render_file_tree(file_tree, max_display=7)
    else:
        st.info("ë¶ˆëŸ¬ì˜¨ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")




with col_table:
    st.subheader("ğŸ“‹ íŒŒì¼ ëª©ë¡")
    df_files = load_file_list()
    AgGrid(df_files)




# ==============================
# í•˜ë‹¨ íƒ­
# ==============================
st.divider()

tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“ˆ ê²€ìƒ‰ íŠ¸ë Œë“œ", "ğŸ“Š PARA ë¶„í¬", "ğŸ”¥ ìµœê·¼ í™œë™", "âš™ï¸ ì„¤ì •"])

with tab1:
    st.subheader("ğŸ“ˆ ìµœê·¼ 7ì¼ ê²€ìƒ‰ íŠ¸ë Œë“œ")
    
    # ê²€ìƒ‰ íŠ¸ë Œë“œ ë°ì´í„° ë¡œë“œ
    trend_df = load_search_trend()
    
    if not trend_df.empty:
        # Plotly ë¼ì¸ ì°¨íŠ¸ ìƒì„±
        fig = px.line(
            trend_df,
            x='ë‚ ì§œ',
            y='ê²€ìƒ‰ íšŸìˆ˜',
            markers=True,
            labels={'ê²€ìƒ‰ íšŸìˆ˜': 'ê²€ìƒ‰ íšŸìˆ˜', 'ë‚ ì§œ': 'ë‚ ì§œ'}
        )
        
        # ì°¨íŠ¸ ë ˆì´ì•„ì›ƒ ì„¤ì •
        fig.update_traces(
            line_color='#3498db',
            line_width=3,
            marker=dict(size=8, color='#3498db')
        )
        
        fig.update_layout(
            height=400,
            margin=dict(l=40, r=40, t=40, b=40),
            xaxis_title="ë‚ ì§œ",
            yaxis_title="ê²€ìƒ‰ íšŸìˆ˜",
            hovermode='x unified'
        )
        
        st.plotly_chart(fig, width='stretch')
        
        # í†µê³„ ì •ë³´ í‘œì‹œ
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ì´ ê²€ìƒ‰", f"{trend_df['ê²€ìƒ‰ íšŸìˆ˜'].sum()}íšŒ")
        with col2:
            st.metric("ì¼í‰ê· ", f"{trend_df['ê²€ìƒ‰ íšŸìˆ˜'].mean():.1f}íšŒ")
        with col3:
            st.metric("ìµœëŒ€", f"{trend_df['ê²€ìƒ‰ íšŸìˆ˜'].max()}íšŒ")
    else:
        st.info("ê²€ìƒ‰ íŠ¸ë Œë“œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

with tab2:
    st.subheader("ğŸ“Š PARA ë¶„í¬")
    
    # PARA ë¶„í¬ ë°ì´í„° ë¡œë“œ
    para_df = load_para_distribution()
    
    # Plotly ë°” ì°¨íŠ¸ ìƒì„±
    fig = px.bar(
        para_df,
        x='PARA',
        y='Count',
        text='Count',
        color='PARA',
        color_discrete_map={
            'Projects': '#e74c3c',      # ë¹¨ê°•
            'Areas': '#3498db',         # íŒŒë‘
            'Resources': '#2ecc71',     # ì´ˆë¡
            'Archives': '#95a5a6'       # íšŒìƒ‰
        },
        labels={'Count': 'íŒŒì¼ ê°œìˆ˜', 'PARA': 'PARA ì¹´í…Œê³ ë¦¬'}
    )
    
    # ì°¨íŠ¸ ë ˆì´ì•„ì›ƒ ì„¤ì •
    fig.update_traces(textposition='outside')
    fig.update_layout(
        showlegend=False,
        height=300,
        margin=dict(l=20, r=20, t=20, b=20),
        xaxis_title="",
        yaxis_title="íŒŒì¼ ê°œìˆ˜"
    )
    
    st.plotly_chart(fig, width='stretch')

with tab3:
    st.subheader("ğŸ”¥ ìµœê·¼ í™œë™ ë¡œê·¸")
    recent_logs = load_recent_activities(limit=10)
    if recent_logs:
        for log in recent_logs:
            st.write(f"- â° {log['timestamp']} | ğŸ“„ {log['title']} | âœ… ì„ íƒ: {log['user_selected']} | ğŸ¯ ì‹ ë¢°ë„: {log['confidence']}")
    else:
        st.info("ìµœê·¼ í™œë™ ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤.")


# tab4 ì„¤ì • íƒ­ ë‚´ìš© (dashboard.pyì˜ with tab4: ë¶€ë¶„ì„ ëŒ€ì²´)
with tab4:
    st.subheader("âš™ï¸ ëŒ€ì‹œë³´ë“œ ì„¤ì •")
    
    # ë‘ ê°œì˜ ì»¬ëŸ¼ìœ¼ë¡œ ë‚˜ëˆ„ê¸° (gap ì¶”ê°€)
    settings_col1, settings_col2 = st.columns(2, gap="large")
    
    # ===== ì™¼ìª½ ì»¬ëŸ¼: ë°ì´í„° ê´€ë¦¬ =====
    with settings_col1:
        st.markdown("### ğŸ“Š ë°ì´í„° ê´€ë¦¬")
        
        # ìºì‹œ ìƒˆë¡œê³ ì¹¨
        if st.button("ğŸ”„ ìºì‹œ ìƒˆë¡œê³ ì¹¨", width='stretch'):
            st.cache_data.clear()
            st.success("âœ… ìºì‹œê°€ ì„±ê³µì ìœ¼ë¡œ ìƒˆë¡œê³ ì¹¨ë˜ì—ˆìŠµë‹ˆë‹¤!")
            st.rerun()
        
        st.markdown("---")
        
        # ë°ì´í„° ë‚´ë³´ë‚´ê¸°
        st.markdown("#### ğŸ“¤ ë°ì´í„° ë‚´ë³´ë‚´ê¸°")
        export_format = st.selectbox(
            "ë‚´ë³´ë‚´ê¸° í˜•ì‹",
            ["CSV", "JSON", "Excel"],
            key="export_format"
        )
        
        if st.button("ğŸ’¾ ë¶„ë¥˜ ë°ì´í„° ë‚´ë³´ë‚´ê¸°", width='stretch'):
            try:
                data_manager = DataManager()
                classifications_csv_path = data_manager.classifications_csv
                
                if classifications_csv_path.exists():
                    if export_format == "CSV":
                        with open(classifications_csv_path, 'r', encoding='utf-8') as f:
                            csv_data = f.read()
                        st.download_button(
                            label="â¬‡ï¸ CSV ë‹¤ìš´ë¡œë“œ",
                            data=csv_data,
                            file_name=f"classifications_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                            mime="text/csv",
                            width='stretch'
                        )
                    elif export_format == "JSON":
                        import json
                        with open(classifications_csv_path, 'r', encoding='utf-8') as f:
                            reader = csv.DictReader(f)
                            data = list(reader)
                        json_data = json.dumps(data, ensure_ascii=False, indent=2)
                        st.download_button(
                            label="â¬‡ï¸ JSON ë‹¤ìš´ë¡œë“œ",
                            data=json_data,
                            file_name=f"classifications_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                            mime="application/json",
                            width='stretch'
                        )
                else:
                    st.warning("âš ï¸ ë‚´ë³´ë‚¼ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            except Exception as e:
                st.error(f"âŒ ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨: {e}")
        
        st.markdown("---")
    
        # ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” (ìœ„í—˜í•œ ì‘ì—…ì´ë¯€ë¡œ í™•ì¸ ì ˆì°¨ ì¶”ê°€)
        st.markdown("#### âš ï¸ ìœ„í—˜ êµ¬ì—­")
        with st.expander("ğŸ—‘ï¸ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”", expanded=False):
            st.warning("âš ï¸ ì´ ì‘ì—…ì€ ëª¨ë“  ë¶„ë¥˜ ë°ì´í„°ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤. ë³µêµ¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
            
            confirm_text = st.text_input(
                "ì´ˆê¸°í™”í•˜ë ¤ë©´ 'DELETE'ë¥¼ ì…ë ¥í•˜ì„¸ìš”:",
                key="confirm_delete"
            )
            
            if st.button("ğŸ—‘ï¸ ì˜êµ¬ ì‚­ì œ", type="primary", width='stretch'):
                if confirm_text == "DELETE":
                    try:
                        data_manager = DataManager()
                        classifications_csv_path = data_manager.classifications_csv
                        
                        # ë°±ì—… ìƒì„±
                        if classifications_csv_path.exists():
                            backup_path = classifications_csv_path.parent / f"backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
                            import shutil
                            shutil.copy(classifications_csv_path, backup_path)
                            st.info(f"â„¹ï¸ ë°±ì—… ìƒì„±: {backup_path.name}")
                        
                        # íŒŒì¼ ì´ˆê¸°í™” (í—¤ë”ë§Œ ë‚¨ê¹€)
                        with open(classifications_csv_path, 'w', encoding='utf-8') as f:
                            f.write("timestamp,title,query,selected_category,user_selected,confidence,feedback\n")
                        
                        st.success("âœ… ë°ì´í„°ë² ì´ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
                        st.cache_data.clear()
                        st.rerun()
                    except Exception as e:
                        st.error(f"âŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                else:
                    st.error("âŒ 'DELETE'ë¥¼ ì •í™•íˆ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    
    # ===== ì˜¤ë¥¸ìª½ ì»¬ëŸ¼: í‘œì‹œ ì„¤ì • ë° ì‹œìŠ¤í…œ ì •ë³´ =====
    with settings_col2:
        st.markdown("### ğŸ¨ í‘œì‹œ ì„¤ì •")
        
        # ëŒ€ì‹œë³´ë“œ ìƒˆë¡œê³ ì¹¨ ì£¼ê¸°
        refresh_interval = st.select_slider(
            "ëŒ€ì‹œë³´ë“œ ìƒˆë¡œê³ ì¹¨ ì£¼ê¸° (ì´ˆ)",
            options=[30, 60, 120, 300, 600],
            value=60,
            key="refresh_interval"
        )
        st.info(f"â„¹ï¸ í˜„ì¬ ìºì‹œ TTL: {refresh_interval}ì´ˆ")
        
        # ë°ì´í„° í‘œì‹œ ë²”ìœ„
        data_range = st.radio(
            "ë°ì´í„° í‘œì‹œ ë²”ìœ„",
            ["ìµœê·¼ 7ì¼", "ìµœê·¼ 30ì¼", "ìµœê·¼ 90ì¼", "ì „ì²´"],
            index=0,
            key="data_range"
        )
        
        st.markdown("---")
        
        # ì°¨íŠ¸ ìƒ‰ìƒ í…Œë§ˆ
        st.markdown("#### ğŸ¨ ì°¨íŠ¸ ìƒ‰ìƒ í…Œë§ˆ")
        color_theme = st.selectbox(
            "ìƒ‰ìƒ í…Œë§ˆ ì„ íƒ",
            ["ê¸°ë³¸ (íŒŒë‘/ë¹¨ê°•/ì´ˆë¡)", "íŒŒìŠ¤í…”", "ë‹¤í¬ ëª¨ë“œ", "ëª¨ë…¸í¬ë¡¬"],
            key="color_theme"
        )
        
        if color_theme != "ê¸°ë³¸ (íŒŒë‘/ë¹¨ê°•/ì´ˆë¡)":
            st.info(f"â„¹ï¸ '{color_theme}' í…Œë§ˆê°€ ë‹¤ìŒ ìƒˆë¡œê³ ì¹¨ì— ì ìš©ë©ë‹ˆë‹¤.")
    
    # ===== êµ¬ë¶„ì„  =====
    st.divider()
    
    # ===== í•˜ë‹¨: ì‹œìŠ¤í…œ ì •ë³´ì™€ ë²„ì „ ì •ë³´ë¥¼ 3ë‹¨ìœ¼ë¡œ ë‚˜ëˆ„ê¸° (ì¤‘ì•™ ì„¸ë¡œ êµ¬ë¶„ì„  ì¶”ê°€) =====
    col_system_info, col_divider, col_version_info = st.columns([5, 0.5, 5])
    
    with col_system_info:
        # ì‹œìŠ¤í…œ ì •ë³´
        st.markdown("### ğŸ’» ì‹œìŠ¤í…œ ì •ë³´")
        
        try:
            data_manager = DataManager()
            classifications_csv_path = data_manager.classifications_csv
            
            # íŒŒì¼ í¬ê¸°
            if classifications_csv_path.exists():
                file_size = classifications_csv_path.stat().st_size
                file_size_mb = file_size / (1024 * 1024)
                
                # ë§ˆì§€ë§‰ ìˆ˜ì • ì‹œê°„
                last_modified = datetime.fromtimestamp(classifications_csv_path.stat().st_mtime)
                
                # ë ˆì½”ë“œ ìˆ˜
                with open(classifications_csv_path, 'r', encoding='utf-8') as f:
                    record_count = sum(1 for _ in f) - 1  # í—¤ë” ì œì™¸
                
                # ì •ë³´ í‘œì‹œ
                info_col1, info_col2 = st.columns(2)
                
                with info_col1:
                    st.metric("ğŸ“ ë°ì´í„°ë² ì´ìŠ¤ í¬ê¸°", f"{file_size_mb:.2f} MB")
                    st.metric("ğŸ“Š ì´ ë ˆì½”ë“œ ìˆ˜", f"{record_count:,}ê°œ")
                
                with info_col2:
                    st.metric("ğŸ• ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸", last_modified.strftime("%Y-%m-%d"))
                    st.metric("â±ï¸ ì‹œê°„", last_modified.strftime("%H:%M:%S"))
                
                # ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ
                if file_size_mb < 10:
                    status = "ğŸŸ¢ ì •ìƒ"
                    status_color = "green"
                elif file_size_mb < 50:
                    status = "ğŸŸ¡ ì£¼ì˜"
                    status_color = "orange"
                else:
                    status = "ğŸ”´ ê²½ê³  (ìµœì í™” í•„ìš”)"
                    status_color = "red"
                
                st.markdown(f"**ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ:** :{status_color}[{status}]")
                
            else:
                st.warning("âš ï¸ ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            st.error(f"âŒ ì‹œìŠ¤í…œ ì •ë³´ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    # ì¤‘ì•™ ì„¸ë¡œ êµ¬ë¶„ì„ 
    with col_divider:
        st.markdown(
            """
            <div style="
                height: 100%;
                min-height: 300px;
                border-left: 2px solid #dee2e6;
                margin: 0 auto;
            "></div>
            """,
            unsafe_allow_html=True
        )
    
    with col_version_info:
        # ë²„ì „ ì •ë³´
        st.markdown("### ğŸ“¦ ë²„ì „ ì •ë³´")
        st.text("FlowNote Dashboard v3.5.0")
        st.text("Streamlit " + st.__version__)
        st.text(f"Python {sys.version.split()[0]}")