# steamlit/app_integrated.py
"""
FlowNote í†µí•© UI - íŒŒì¼ ì—…ë¡œë“œ â†’ LangChain ë¶„ë¥˜ â†’ ë©”íƒ€ë°ì´í„° í‘œì‹œ
"""
import os
import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€ (ì¤‘ìš”!!!)
project_root = Path(__file__).parent.parent 
sys.path.insert(0, str(project_root))

# ë‘ ë²ˆì§¸: Streamlit + í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
import streamlit as st
from dotenv import load_dotenv

# ë¡œì»¬ì—ì„œëŠ” .env ë¡œë“œ
load_dotenv()

# ì„¸ ë²ˆì©¨: ë°°í¬ í™˜ê²½ì—ì„œëŠ” Streamlit Secrets ë¡œë“œ
# ë°°í¬ì—ì„œëŠ” Streamlit Secrets â†’ í™˜ê²½ë³€ìˆ˜ ë™ê¸°í™”
# (ë¡œì»¬ì—ì„œëŠ” st.secrets ì ‘ê·¼í•˜ì§€ ì•ŠìŒ)
try:
    if hasattr(st, 'secrets') and len(st.secrets) > 0:
        for key in ["EMBEDDING_API_KEY", "EMBEDDING_BASE_URL", "EMBEDDING_MODEL",
                    "EMBEDDING_LARGE_API_KEY", "EMBEDDING_LARGE_BASE_URL", "EMBEDDING_LARGE_MODEL",
                    "GPT4O_API_KEY", "GPT4O_BASE_URL", "GPT4O_MODEL",
                    "GPT4O_MINI_API_KEY", "GPT4O_MINI_BASE_URL", "GPT4O_MINI_MODEL",
                    "GPT41_API_KEY", "GPT41_BASE_URL", "GPT41_MODEL"]:
            if key in st.secrets:
                os.environ[key] = st.secrets[key]
except:
    # Secrets íŒŒì¼ ì—†ìŒ = ë¡œì»¬ ê°œë°œ í™˜ê²½
    # .envì—ì„œ ë¡œë“œëœ ë³€ìˆ˜ ì‚¬ìš©
    pass


from datetime import datetime
import json

# ë„¤ ë²ˆì©¨: ë‹¤ìŒ ì„í¬íŠ¸
from backend.classifier.para_agent_wrapper import run_para_agent_sync
from backend.database.metadata_schema import ClassificationMetadataExtender
from backend.database.connection import DatabaseConnection
from backend.utils import load_pdf

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="FlowNote í†µí•© í…ŒìŠ¤íŠ¸",
    page_icon="ğŸ“š",
    layout="wide"
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "classification_history" not in st.session_state:
    st.session_state.classification_history = []

if "db_extender" not in st.session_state:
    st.session_state.db_extender = ClassificationMetadataExtender()

# íƒ€ì´í‹€
st.title("ğŸ“š FlowNote í†µí•© í…ŒìŠ¤íŠ¸ UI")
st.markdown("**íŒŒì¼ ì—…ë¡œë“œ â†’ LangChain ë¶„ë¥˜ â†’ ë©”íƒ€ë°ì´í„° í™•ì¸**")

# ì‚¬ì´ë“œë°” - ë¶„ë¥˜ íˆìŠ¤í† ë¦¬
with st.sidebar:
    st.header("ğŸ“Š ë¶„ë¥˜ íˆìŠ¤í† ë¦¬")
    
    if st.session_state.classification_history:
        st.metric("ì´ ë¶„ë¥˜ íŒŒì¼", len(st.session_state.classification_history))
        
        with st.expander("ğŸ—‚ï¸ ìµœê·¼ ë¶„ë¥˜ ê²°ê³¼", expanded=True):
            for idx, item in enumerate(reversed(st.session_state.classification_history[-5:]), 1):
                st.markdown(f"**{idx}. {item['filename']}**")
                st.caption(f"ì¹´í…Œê³ ë¦¬: {item['category']} ({item['confidence']:.0%})")
                st.caption(f"ì‹œê°„: {item['timestamp']}")
                st.divider()
        
        if st.button("ğŸ—‘ï¸ íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”", width='stretch'):
            st.session_state.classification_history = []
            st.rerun()
    else:
        st.info("ì•„ì§ ë¶„ë¥˜ëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")

# ë©”ì¸ ì˜ì—­
tab1, tab2, tab3 = st.tabs([
    "ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ & ë¶„ë¥˜",                # ê¸°ì¡´
    "ğŸ“Š ë©”íƒ€ë°ì´í„° í™•ì¸",                   # ê¸°ì¡´
    "ğŸ¯ ë¶„ë¥˜ í†µê³„",                       # ê¸°ì¡´
    ])

# ============================================================================
# TAB 1: íŒŒì¼ ì—…ë¡œë“œ & ë¶„ë¥˜
# ============================================================================
with tab1:
    st.header("ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ & ìë™ ë¶„ë¥˜")
    
    uploaded_file = st.file_uploader(
        "ë¶„ë¥˜í•  íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”",
        type=['pdf', 'txt', 'md'],
        help="PDF, TXT, MD íŒŒì¼ì„ ì§€ì›í•©ë‹ˆë‹¤"
    )
    
    if uploaded_file:
        # íŒŒì¼ ì •ë³´ í‘œì‹œ
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("íŒŒì¼ëª…", uploaded_file.name)
        with col2:
            st.metric("íŒŒì¼ í¬ê¸°", f"{uploaded_file.size / 1024:.2f} KB")
        with col3:
            st.metric("íŒŒì¼ íƒ€ì…", uploaded_file.type.split('/')[-1].upper())
        
        # ë¶„ë¥˜ ë²„íŠ¼
        if st.button("ğŸš€ ë¶„ë¥˜ ì‹œì‘", type="primary", width='stretch'):
            with st.spinner("ğŸ¤– AIê°€ íŒŒì¼ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                try:
                    # 1. íŒŒì¼ ì½ê¸°
                    if uploaded_file.type == "application/pdf":
                        text = load_pdf(uploaded_file)
                    else:
                        text = uploaded_file.read().decode('utf-8')
                    
                    # 2. ë©”íƒ€ë°ì´í„° êµ¬ì„±
                    metadata = {
                        "filename": uploaded_file.name,
                        "file_size": uploaded_file.size,
                        "file_type": uploaded_file.type,
                        "uploaded_at": datetime.now().isoformat()
                    }
                    
                    # 3. LangChain + LangGraph ê¸°ë°˜ ë¶„ë¥˜
                    classification_result = run_para_agent_sync(
                        text=text[:2000],       # ì²˜ìŒ 2000ìë§Œ ì‚¬ìš©
                        metadata=metadata
                    )
                    
                    # 4. ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
                    file_id = st.session_state.db_extender.save_classification_result(
                        result=classification_result,
                        filename=uploaded_file.name
                    )
                    
                    # 5. íˆìŠ¤í† ë¦¬ ì €ì¥
                    history_item = {
                        "filename": uploaded_file.name,
                        "category": classification_result.get('category', 'Unknown'),
                        "confidence": classification_result.get('confidence', 0),
                        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                        "file_id": file_id
                    }
                    st.session_state.classification_history.append(history_item)
                    
                    st.success("âœ… ë¶„ë¥˜ ì™„ë£Œ!")
                    
                    # 6. ê²°ê³¼ í‘œì‹œ
                    st.markdown("---")
                    st.subheader("ğŸ“Š ë¶„ë¥˜ ê²°ê³¼")
                    
                    # ì¹´í…Œê³ ë¦¬ ì•„ì´ì½˜
                    category_icons = {
                        "Projects": "ğŸš€",
                        "Areas": "ğŸ¯",
                        "Resources": "ğŸ“š",
                        "Archives": "ğŸ“¦"
                    }
                    
                    category = classification_result.get('category', 'Unknown')
                    icon = category_icons.get(category, "â“")
                    
                    # ê²°ê³¼ ì¹´ë“œ
                    col1, col2 = st.columns([2, 1])
                    
                    with col1:
                        st.markdown(f"### {icon} {category}")
                        st.progress(classification_result.get('confidence', 0))
                        st.caption(f"ì‹ ë¢°ë„: {classification_result.get('confidence', 0):.0%}")
                    
                    with col2:
                        if classification_result.get('conflict_detected', False):
                            st.warning("âš ï¸ ì¶©ëŒ ê°ì§€ë¨")
                        else:
                            st.success("âœ… ëª…í™•í•œ ë¶„ë¥˜")
                        
                        if classification_result.get('requires_review', False):
                            st.info("ğŸ‘€ ê²€í†  í•„ìš”")
                    
                    # ìƒì„¸ ì •ë³´
                    with st.expander("ğŸ“ ë¶„ë¥˜ ê·¼ê±°", expanded=True):
                        st.markdown(classification_result.get('reasoning', 'ì •ë³´ ì—†ìŒ'))
                    
                    with st.expander("ğŸ”‘ í‚¤ì›Œë“œ íƒœê·¸"):
                        tags = classification_result.get('keyword_tags', [])
                        if tags:
                            st.write(", ".join([f"`{tag}`" for tag in tags[:10]]))
                        else:
                            st.caption("í‚¤ì›Œë“œ ì—†ìŒ")
                    
                    # ë©”íƒ€ë°ì´í„° í‘œì‹œ
                    with st.expander("ğŸ“‹ ë©”íƒ€ë°ì´í„°"):
                        st.json({
                            "filename": uploaded_file.name,
                            "file_size_kb": f"{uploaded_file.size / 1024:.2f}",
                            "file_type": uploaded_file.type,
                            "classified_at": datetime.now().isoformat(),
                            "file_id": file_id
                        })
                    
                except Exception as e:
                    st.error(f"âŒ ë¶„ë¥˜ ì‹¤íŒ¨: {str(e)}")
                    st.exception(e)

# ============================================================================
# TAB 2: ë©”íƒ€ë°ì´í„° í™•ì¸
# ============================================================================
with tab2:
    st.header("ğŸ“Š ì €ì¥ëœ ë©”íƒ€ë°ì´í„° í™•ì¸")
    
    # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ëª¨ë“  ë¶„ë¥˜ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
    try:
        all_classifications = st.session_state.db_extender.get_all_classifications()
        
        if all_classifications:
            st.metric("ì €ì¥ëœ ë¶„ë¥˜ ê²°ê³¼", len(all_classifications))
            
            # ë°ì´í„°í”„ë ˆì„ í‘œì‹œ
            import pandas as pd
            
            df_data = []
            for item in all_classifications:
                df_data.append({
                    "íŒŒì¼ëª…": item['filename'],
                    "ì¹´í…Œê³ ë¦¬": item['para_category'],
                    "ì‹ ë¢°ë„": f"{item['confidence_score']:.0%}",
                    "í‚¤ì›Œë“œ": item['keyword_tags'][:50] if item['keyword_tags'] else "",
                    "ì¶©ëŒ": "âš ï¸" if item['conflict_flag'] else "âœ…",
                    "Snapshot ID": item['snapshot_id'][:20] if item['snapshot_id'] else ""
                })
            
            df = pd.DataFrame(df_data)
            st.dataframe(df, width='stretch')
            
            # ìƒì„¸ ë³´ê¸°
            st.subheader("ğŸ” ìƒì„¸ ì •ë³´")
            selected_file = st.selectbox(
                "íŒŒì¼ ì„ íƒ",
                options=[item['filename'] for item in all_classifications]
            )
            
            if selected_file:
                selected_item = next(
                    (item for item in all_classifications if item['filename'] == selected_file),
                    None
                )
                
                if selected_item:
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.markdown("**ê¸°ë³¸ ì •ë³´**")
                        st.write(f"íŒŒì¼ëª…: {selected_item['filename']}")
                        st.write(f"ì¹´í…Œê³ ë¦¬: {selected_item['para_category']}")
                        st.write(f"ì‹ ë¢°ë„: {selected_item['confidence_score']:.0%}")
                    
                    with col2:
                        st.markdown("**ë¶„ë¥˜ ìƒíƒœ**")
                        st.write(f"ì¶©ëŒ ê°ì§€: {'ì˜ˆ' if selected_item['conflict_flag'] else 'ì•„ë‹ˆì˜¤'}")
                        st.write(f"í•´ê²° ë°©ë²•: {selected_item['resolution_method'][:50]}")
                    
                    st.markdown("**í‚¤ì›Œë“œ íƒœê·¸**")
                    st.code(selected_item['keyword_tags'] if selected_item['keyword_tags'] else "ì—†ìŒ")
        else:
            st.info("ì €ì¥ëœ ë©”íƒ€ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. TAB 1ì—ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    
    except Exception as e:
        st.error(f"ë©”íƒ€ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")

# ============================================================================
# TAB 3: ë¶„ë¥˜ í†µê³„
# ============================================================================
with tab3:
    st.header("ğŸ¯ ë¶„ë¥˜ í†µê³„")
    
    if st.session_state.classification_history:
        # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
        from collections import Counter
        
        categories = [item['category'] for item in st.session_state.classification_history]
        category_counts = Counter(categories)
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ğŸš€ Projects", category_counts.get('Projects', 0))
        with col2:
            st.metric("ğŸ¯ Areas", category_counts.get('Areas', 0))
        with col3:
            st.metric("ğŸ“š Resources", category_counts.get('Resources', 0))
        with col4:
            st.metric("ğŸ“¦ Archives", category_counts.get('Archives', 0))
        
        # ì‹ ë¢°ë„ í†µê³„
        st.subheader("ğŸ“Š ì‹ ë¢°ë„ ë¶„í¬")
        confidences = [item['confidence'] for item in st.session_state.classification_history]
        avg_confidence = sum(confidences) / len(confidences) if confidences else 0
        
        st.metric("í‰ê·  ì‹ ë¢°ë„", f"{avg_confidence:.0%}")
        
        # ì°¨íŠ¸ í‘œì‹œ (ê°„ë‹¨í•œ ë§‰ëŒ€ ê·¸ë˜í”„)
        st.bar_chart(category_counts)
        
    else:
        st.info("ë¶„ë¥˜ëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. TAB 1ì—ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")

# í•˜ë‹¨ ì •ë³´
st.divider()
st.caption("FlowNote MVP v3.1 | LangChain + LangGraph í†µí•© | Made with â¤ï¸ by Jay")
