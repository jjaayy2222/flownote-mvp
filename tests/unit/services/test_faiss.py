# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# tests/test_faiss.py 
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

"""
FAISS ê²€ìƒ‰ í†µí•© í…ŒìŠ¤íŠ¸
"""

import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€ (ìƒìœ„ í´ë”)
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

import numpy as np
from typing import List, Dict, Any
import json
import re

from backend.chunking import TextChunker
from backend.embedding import EmbeddingGenerator
from backend.faiss_search import FAISSRetriever
from backend.utils import count_tokens, estimate_cost

def test_search_pipeline():
    """ì „ì²´ ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸"""
    
    # 1. Retriever ì´ˆê¸°í™”
    retriever = FAISSRetriever()
    
    print("=" * 50)
    print("FlowNote ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    # 2. ìƒ˜í”Œ ë¬¸ì„œ
    document = """
    FlowNoteëŠ” AI ëŒ€í™”ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ì €ì¥í•˜ê³  ê²€ìƒ‰í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤.
    ì‚¬ìš©ìëŠ” Markdown íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    
    ì£¼ìš” ê¸°ëŠ¥:
    1. íŒŒì¼ ì—…ë¡œë“œ
    2. ìë™ ì²­í‚¹
    3. ë²¡í„° ì„ë² ë”©
    4. FAISS ê²€ìƒ‰
    5. ê²°ê³¼ ìš”ì•½
    
    ê¸°ìˆ  ìŠ¤íƒ:
    - Python 3.11
    - Streamlit
    - OpenAI API
    - FAISS
    """ * 2
    
    # 3. ì²­í‚¹
    print("\n" + "=" * 50)
    print("1. ì²­í‚¹")
    print("=" * 50)
    
    chunker= TextChunker(chunk_size=200, chunk_overlap=50)
    
    chunks= chunker.chunk_text(document)

    print(f"âœ… ì²­í¬ ìˆ˜: {len(chunks)}")
    print(f"âœ… ì²« ë²ˆì§¸ ì²­í¬ ê¸¸ì´: {len(chunks[0])}")
    print(f"\nì²« ë²ˆì§¸ ì²­í¬ ë¯¸ë¦¬ë³´ê¸°:")
    print(f"{chunks[0][:100]}...")
    
    # ì²­í¬ ê²°ê³¼ = ë¬¸ì„œë¡œ ë³€í™˜í•˜ê¸°
    chunk_results: List[Dict[str, Any]] = []

    # ë”•ì…”ë„ˆë¦¬ ìƒì„± ë°˜ë³µë¬¸: 'content', 'metadata', 'chunk_id' í‚¤ë¥¼ í¬í•¨
    for i, chunk_content in enumerate(chunks):
        # ğŸ’¥ FAISS ê²€ìƒ‰ê¸°(faiss_search.py)ê°€ ê¸°ëŒ€í•˜ëŠ” êµ¬ì¡°ë¡œ ìƒì„±í•˜ê¸°
        chunk_dict = {
            "chunk_id": i,
            "content": chunk_content, # Key Error í•´ê²° 1: 'content' í‚¤ ì‚¬ìš©
            "metadata": {}            # Key Error í•´ê²° 2: 'metadata' í‚¤ (ë¹ˆ ë”•ì…”ë„ˆë¦¬) ì¶”ê°€
        }
        chunk_results.append(chunk_dict)
    
    # 3. ê²°ê³¼ ì¶œë ¥ (í™•ì¸ìš©)
    print("=" * 50)
    print(f"âœ… ì´ {len(chunk_results)}ê°œì˜ ì²­í¬ ë”•ì…”ë„ˆë¦¬ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print("=" * 50)
    
    if chunk_results:
        print("ë°˜ë³µë¬¸ìœ¼ë¡œ ìƒì„±ëœ ì „ì²´ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ (FAISS êµ¬ì¡° í†µì¼):")
        # json.dumpsë¥¼ ì‚¬ìš©í•˜ì—¬ ë”•ì…”ë„ˆë¦¬ êµ¬ì¡°ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥
        print(json.dumps(chunk_results, indent=4, ensure_ascii=False))

    print("=" * 50)
    print("ğŸ‰ FAISS ê²€ìƒ‰ê¸° ìš”êµ¬ ì‚¬í•­ì— ë§ê²Œ êµ¬ì¡°ê°€ í†µì¼ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    # 3. ê²°ê³¼ ì¶œë ¥ (í™•ì¸ìš©)
    print("=" * 50)
    print(f"âœ… ì´ {len(chunk_results)}ê°œì˜ ë‹¨ìˆœ ì²­í¬ ë”•ì…”ë„ˆë¦¬ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print("=" * 50)
    
    if chunk_results:
        print("ë°˜ë³µë¬¸ìœ¼ë¡œ ìƒì„±ëœ ì „ì²´ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ (ë‹¨ìˆœ êµ¬ì¡°):")
        # json.dumpsë¥¼ ì‚¬ìš©í•˜ì—¬ ë”•ì…”ë„ˆë¦¬ êµ¬ì¡°ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥
        print(json.dumps(chunk_results, indent=4, ensure_ascii=False))

    print("=" * 50)
    print("ğŸ‰ ë‹¨ìˆœ êµ¬ì¡°ì˜ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ í™•ì¸ ê°€ëŠ¥")
    
    
    documents = chunk_results    
    
    # 4. ì„ë² ë”©
    print("\n" + "=" * 50)
    print("2. ì„ë² ë”©")
    print("=" * 50)
    
    embedding_generator = EmbeddingGenerator()
    
    texts = [chunk[1] for chunk in chunks]
    #embeddings, tokens, cost = generator.generate_embeddings(texts)
    
    result = embedding_generator.generate_embeddings(texts)
    embeddings = result["embeddings"] 
    
    if result['embeddings']:
        print(f"\nâœ… ì„ë² ë”© ì„±ê³µ!")
        print(f"  - ì„ë² ë”© ê°œìˆ˜: {len(result['embeddings'])}")
        print(f"  - ë²¡í„° ì°¨ì›: {len(result['embeddings'][0])}")
        print(f"  - ì²­í¬ ìˆ˜: {len(embeddings)}")
        print(f"  - í† í° ìˆ˜: {result['tokens']}")
        print(f"  - ì˜ˆìƒ ë¹„ìš©: ${result['cost']:.6f}")
    else:
        print("âŒ ì„ë² ë”© ì‹¤íŒ¨")
    
    # 5. FAISS ì¸ë±ìŠ¤ ìƒì„±
    print("\n" + "=" * 50)
    print("3. FAISS ì¸ë±ìŠ¤")
    print("=" * 50)
    
    # NumPy ë°°ì—´ë¡œ ë³€í™˜ (FAISSê°€ ê¸°ëŒ€í•˜ëŠ” í˜•íƒœ)
    embeddings_np = np.array(result['embeddings'], dtype=np.float32)
    
    # 6. ë¬¸ì„œ ì¶”ê°€
    retriever.add_documents(embeddings_np, documents)
    
    print(f"\nâœ… FAISS ì¸ë±ìŠ¤ ì¶”ê°€ ì™„ë£Œ")
    print(f"    - ì´ ë¬¸ì„œ ìˆ˜: {len(documents)}")
    print(f"    - ì¸ë±ìŠ¤ í¬ê¸°: {retriever.size()}")
    
    # 6. ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    print("\n" + "=" * 50)
    print("4. ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    # ê²€ìƒ‰ì–´
    query = "Pythonìœ¼ë¡œ ì–´ë–»ê²Œ ê°œë°œí•˜ë‚˜ìš”?"
    print(f"\nê²€ìƒ‰ì–´: {query}")
    
    # ì¿¼ë¦¬ ê²€ìƒ‰
    results = retriever.search(query, k=2)
    
    print(f"\nê²€ìƒ‰ ê²°ê³¼ ({len(results)}ê°œ):")
    print("-" * 50)
    for i, result in enumerate(results, 1):
        print(f"\n{i}ìœ„:")
        print(f"    - ìœ ì‚¬ë„: {result['score']:.4f}")
        print(f"    - ë‚´ìš©: {result['content']}")
        print(f"    - ì¶œì²˜: {result['metadata']}")
    
    print("\n" + "=" * 50)


if __name__ == "__main__":
    test_search_pipeline()



"""result

    ==================================================
    FlowNote ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
    ==================================================

    ==================================================
    1. ì²­í‚¹
    ==================================================
    âœ… ì²­í¬ ìˆ˜: 4

    ==================================================
    2. ì„ë² ë”©
    ==================================================
    ğŸ“Š ì„ë² ë”© ìƒì„± ì¤‘... (4ê°œ ì²­í¬)
    âœ… ì„ë² ë”© ì™„ë£Œ!
        - ì²­í¬ ìˆ˜: 4
        - í† í° ìˆ˜: 367
        - ì˜ˆìƒ ë¹„ìš©: $0.000007
        - ë²¡í„° ì°¨ì›: 1536
    âœ… ì„ë² ë”© ì™„ë£Œ!
        - í† í°: 367
        - ë¹„ìš©: $0.000007

    ==================================================
    3. FAISS ì¸ë±ìŠ¤
    ==================================================
    âœ… ë¬¸ì„œ ì¶”ê°€ ì™„ë£Œ!
        - ì´ ë¬¸ì„œ ìˆ˜: 4
        - ì¸ë±ìŠ¤ í¬ê¸°: 4

    ==================================================
    4. ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    ==================================================

    ê²€ìƒ‰ì–´: Pythonìœ¼ë¡œ ì–´ë–»ê²Œ ê°œë°œí•˜ë‚˜ìš”?

    ê²€ìƒ‰ ê²°ê³¼ (3ê°œ):

    1ìœ„:
        - ìœ ì‚¬ë„: 0.4065
        - íŒŒì¼: test.md
        - í…ìŠ¤íŠ¸: 
            - Python 3.11
            - Streamlit
            - OpenAI API
            - FAISS
            ...

    2ìœ„:
    - ìœ ì‚¬ë„: 0.3951
    - íŒŒì¼: test.md
    - í…ìŠ¤íŠ¸:  4. FAISS ê²€ìƒ‰
        5. ê²°ê³¼ ìš”ì•½
        
        ê¸°ìˆ  ìŠ¤íƒ:
        - Python 3.11
        - Streamlit
        - OpenAI API
        - F...

    3ìœ„:
    - ìœ ì‚¬ë„: 0.3902
    - íŒŒì¼: test.md
    - í…ìŠ¤íŠ¸: ë‹ˆë‹¤.
        ì‚¬ìš©ìëŠ” Markdown íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        
        ì£¼ìš” ê¸°ëŠ¥:
        1. íŒŒì¼ ì—…ë¡œë“œ
        2. ìë™ ì²­í‚¹
        3. ë²¡...

    ==================================================
    5. í†µê³„
    ==================================================
    - ì´ ë¬¸ì„œ: 4
    - ì¸ë±ìŠ¤ í¬ê¸°: 4
    - ë²¡í„° ì°¨ì›: 1536

    ==================================================
    ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼!
    ==================================================

"""