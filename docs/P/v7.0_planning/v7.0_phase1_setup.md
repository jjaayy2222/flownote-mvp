# v7.0 Phase 1: ì„¤ì • ë° êµ¬í˜„ ê°€ì´ë“œ

## ğŸ›  ì‚¬ì „ ì¤€ë¹„

### 1. ì˜ì¡´ì„± ì„¤ì¹˜
LangGraphì™€ ìµœì‹  LangChain íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.

```bash
# langgraph í•µì‹¬ ë¼ì´ë¸ŒëŸ¬ë¦¬
pip install langgraph langchain-openai langchain-core

# (ì„ íƒì‚¬í•­) ì‹œê°í™” ë° ë””ë²„ê¹… ë„êµ¬
pip install langsmith
```

### 2. í™˜ê²½ ë³€ìˆ˜ (.env)
LangSmith(ë””ë²„ê¹… ë„êµ¬) ì‚¬ìš© ì‹œ í‚¤ ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤ (ì„ íƒ ì‚¬í•­).

```env
# LangSmith ì„¤ì • (ì„ íƒì‚¬í•­ì´ì§€ë§Œ ì—ì´ì „íŠ¸ ê°œë°œ ì‹œ ê¶Œì¥)
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=lsv2_...
```

---

## ğŸ“‚ íŒŒì¼ êµ¬ì¡° ë³€ê²½

v7.0ì„ ìœ„í•´ `backend` ë””ë ‰í† ë¦¬ êµ¬ì¡°ë¥¼ í™•ì¥í•©ë‹ˆë‹¤.

```
backend/
â”œâ”€â”€ agent/                  # [ì‹ ê·œ] AI ì—ì´ì „íŠ¸ í•µì‹¬ ë¡œì§
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ graph.py            # StateGraph ì •ì˜
â”‚   â”œâ”€â”€ nodes.py            # ê°œë³„ ë…¸ë“œ í•¨ìˆ˜ (Analyze, Classify...)
â”‚   â”œâ”€â”€ state.py            # TypedDict State ìŠ¤í‚¤ë§ˆ
â”‚   â””â”€â”€ prompts.py          # ì—ì´ì „íŠ¸ ì „ìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
â”‚
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ classifier_service.py # [íê¸° ì˜ˆì • â†’ ë˜í¼] ì—ì´ì „íŠ¸ í˜¸ì¶œ
â”‚   â””â”€â”€ ...
```

---

## ğŸš€ êµ¬í˜„ ë‹¨ê³„ (1ì¼ì°¨)

### Step 1: State ì •ì˜ (`agent/state.py`)
ì—ì´ì „íŠ¸ê°€ ê³µìœ í•  ë°ì´í„° êµ¬ì¡°ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.

> **ì°¸ê³ **: AgentStateì˜ ì •ì‹ ì •ì˜ëŠ” [`v7.0_phase1_design.md`](./v7.0_phase1_design.md#state-ìŠ¤í‚¤ë§ˆ-ë°ì´í„°-êµ¬ì¡°)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.

```python
from typing import TypedDict, List, Optional

class AgentState(TypedDict):
    # ì…ë ¥
    file_content: str
    file_name: str
    
    # ë‚´ë¶€ ì²˜ë¦¬
    extracted_keywords: List[str]
    retrieved_context: str
    retry_count: int
    
    # ì¶œë ¥
    classification_result: Optional[dict]
    confidence_score: float
    reasoning: str
```

**ì£¼ìš” í•„ë“œ ì„¤ëª…**:
- `file_content`, `file_name`: ë¶„ë¥˜ ëŒ€ìƒ íŒŒì¼ ì •ë³´
- `extracted_keywords`: InputAnalysis ë…¸ë“œì—ì„œ ì¶”ì¶œí•œ í‚¤ì›Œë“œ
- `retrieved_context`: ContextRetrieval ë…¸ë“œì—ì„œ ê°€ì ¸ì˜¨ ë§¥ë½ ì •ë³´
- `retry_count`: ì¬ì‹œë„ íšŸìˆ˜ (ë¬´í•œ ë£¨í”„ ë°©ì§€)
- `classification_result`: ìµœì¢… ë¶„ë¥˜ ê²°ê³¼
- `confidence_score`: ë¶„ë¥˜ ì‹ ë¢°ë„ (0.0 ~ 1.0)
- `reasoning`: LLMì˜ ì¶”ë¡  ê³¼ì •

### Step 2: ë…¸ë“œ êµ¬í˜„ (`agent/nodes.py`)
ê° ë‹¨ê³„ë³„ ë¡œì§ì„ í•¨ìˆ˜ë¡œ êµ¬í˜„í•©ë‹ˆë‹¤.

```python
from backend.agent.state import AgentState

def analyze_node(state: AgentState) -> dict:
    """ì…ë ¥ ë¶„ì„: í‚¤ì›Œë“œ ì¶”ì¶œ"""
    keywords = extract_keywords(state["file_content"])
    return {"extracted_keywords": keywords}

def retrieve_node(state: AgentState) -> dict:
    """ë§¥ë½ ê²€ìƒ‰: ìœ ì‚¬ ë¬¸ì„œ ì°¸ì¡°"""
    context = search_similar_docs(state["extracted_keywords"])
    return {"retrieved_context": context}

def classify_node(state: AgentState) -> dict:
    """ë¶„ë¥˜ ìˆ˜í–‰: PARA ì¹´í…Œê³ ë¦¬ ê²°ì •"""
    result = llm.invoke(...)
    return {
        "classification_result": result.category,
        "confidence_score": result.confidence,
        "reasoning": result.reasoning
    }

def validate_node(state: AgentState) -> dict:
    """ê²€ì¦: ì‹ ë¢°ë„ ê²€ì‚¬"""
    # ê²€ì¦ ë¡œì§ (State ë³€ê²½ ì—†ìŒ)
    return {}

def reflect_node(state: AgentState) -> dict:
    """íšŒê³ : ì¬ì‹œë„ ì¤€ë¹„"""
    return {"retry_count": state["retry_count"] + 1}

def should_retry(state: AgentState) -> str:
    """ì¡°ê±´ í•¨ìˆ˜: ì¬ì‹œë„ ì—¬ë¶€ ê²°ì •"""
    if state["confidence_score"] >= 0.7:
        return "end"
    if state["retry_count"] >= 3:
        return "end"
    return "retry"
```

### Step 3: ê·¸ë˜í”„ êµ¬ì¶• (`agent/graph.py`)
ì •ì˜ëœ ë…¸ë“œë“¤ì„ ì—°ê²°í•©ë‹ˆë‹¤.

```python
from langgraph.graph import StateGraph

def create_workflow():
    workflow = StateGraph(AgentState)
    # ... (ë…¸ë“œ ë° ì—£ì§€ ì¶”ê°€)
    return workflow.compile()
```

### Step 4: API í†µí•© (`api/endpoints/classify.py`)
ê¸°ì¡´ ì—”ë“œí¬ì¸íŠ¸ì—ì„œ `classifier_service` ëŒ€ì‹  `agent`ë¥¼ í˜¸ì¶œí•˜ë„ë¡ ìˆ˜ì •í•©ë‹ˆë‹¤.

```python
# ì´ì „
result = await classifier_service.classify(text)

# ì´í›„
from backend.agent.graph import create_workflow

app = create_workflow()
result = await app.ainvoke({
    # ì…ë ¥ í•„ë“œ
    "file_content": text,
    "file_name": filename,
    
    # ì´ˆê¸°í™” í•„ìš” í•„ë“œ (í•„ìˆ˜)
    "retry_count": 0,       # ì¬ì‹œë„ ì¹´ìš´í„° ì´ˆê¸°í™”
    "extracted_keywords": [],
    "retrieved_context": None, # ì´ˆê¸°ê°’: None
    "classification_result": None,
    "confidence_score": 0.0,
    "reasoning": None          # ì´ˆê¸°ê°’: None
})
final_category = result["classification_result"]
```

---

## âš ï¸ ì£¼ìš” ê³ ë ¤ì‚¬í•­

1.  **ì§€ì—°ì‹œê°„**: ì—ì´ì „íŠ¸ ë£¨í”„ê°€ ëŒë©´ ì‘ë‹µ ì‹œê°„ì´ ê¸¸ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    - â†’ **ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ** ë„ì…ì„ ê³ ë ¤í•˜ê±°ë‚˜, ì‚¬ìš©ìì—ê²Œ "ë¶„ì„ ì¤‘..." ìƒíƒœë¥¼ ëª…í™•íˆ ë³´ì—¬ì£¼ëŠ” UI/UX ê°œì„ ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
2.  **ë¹„ìš©**: ë‹¤ë‹¨ê³„ LLM í˜¸ì¶œë¡œ í† í° ì‚¬ìš©ëŸ‰ì´ ì¦ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    - â†’ `InputAnalysis` ë‹¨ê³„ì—ì„œëŠ” **gpt-4o-mini** ê°™ì€ ê²½ëŸ‰ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì„¸ìš”.
    - â†’ ìµœì¢… `Classification` ë‹¨ê³„ì—ì„œë§Œ **gpt-4o**ë¥¼ ì‚¬ìš©í•˜ëŠ” í•˜ì´ë¸Œë¦¬ë“œ ì „ëµì„ ì¶”ì²œí•©ë‹ˆë‹¤.
3.  **í´ë°±**: ì—ì´ì „íŠ¸ê°€ ì‹¤íŒ¨í•˜ê±°ë‚˜ ë£¨í”„ê°€ ë„ˆë¬´ ê¸¸ì–´ì§ˆ ê²½ìš°(ìµœëŒ€ ì¬ì‹œë„ ì´ˆê³¼), ê¸°ë³¸ ê·œì¹™ ê¸°ë°˜ ë¶„ë¥˜(Rule-based)ë¡œ ë„˜ì–´ê°€ë„ë¡ ì•ˆì „ì¥ì¹˜ë¥¼ ë§ˆë ¨í•˜ì„¸ìš”.
